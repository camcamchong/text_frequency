text
International Forum of Educational Technology & Society A K-6 Computational Thinking Curriculum Framework Implications for Teacher Knowledge Author(s) Charoula Angeli Joke Voogt Andrew Fluck Mary Webb Margaret Cox Joyce Malyn-Smith and Jason Zagami Source Journal of Educational Technology & Society  Vol 19 No 3 (July 2016) pp 47-57 Published by International Forum of Educational Technology & Society Stable URL https//wwwjstororg/stable/102307/jeductechsoci19347 REFERENCES Linked references are available on JSTOR for this article https//wwwjstororg/stable/102307/jeductechsoci19347?seq=1&cid=pdfreference#references_tab_contents You may need to log in to JSTOR to access the linked references JSTOR is a not-for-profit service that helps scholars researchers and students discover use and build upon a wide range of content in a trusted digital archive We use information technology and tools to increase productivity and facilitate new forms of scholarship For more information about JSTOR please contact support@jstororg Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use available at https//aboutjstororg/terms International Forum of Educational Technology & Society is collaborating with JSTOR to digitize preserve and extend access to Journal of Educational Technology & Society This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt Angeli C Voogt J Fluck A Webb M Cox M Malyn-Smith J & Zagami J (2016) A K-6 Computational Thinking Curriculum Framework Implications for Teacher Knowledge Educational Technology & Society 19 (3) 47–57 47 ISSN 1436-4522 (online) and 1176-3647 (print) This article of the Journal of Educational Technology & Society is available under Creative Commons CC-BY-ND-NC 30 license (https//creativecommonsorg/licenses/by-nc-nd/30/) For further queries please contact Journal Editors at ets-editors@ifetsinfo A K-6 Computational Thinking Curriculum Framework Implications for Teacher Knowledge Charoula Angeli1  Joke Voogt2  Andrew Fluck3  Mary Webb4  Margaret Cox4  Joyce Malyn-Smith5 and Jason Zagami6 1University of Cyprus Cyprus // 2University of Amsterdam The Netherlands // 3University of Tasmania Australia // 4King’s College London UK // 5Education Development Center USA // 6Griffith University Australia // cangeli@ucyaccy // JMVoogt@uvanl // AndrewFluck@utaseduau // marywebb@kclacuk // mjcox@kclacuk // jmsmith@edcorg // jzagami@griffitheduau Corresponding author ABSTRACT Adding computer science as a separate school subject to the core K-6 curriculum is a complex issue with educational challenges The authors herein address two of these challenges (1) the design of the curriculum based on a generic computational thinking framework and (2) the knowledge teachers need to teach the curriculum The first issue is discussed within a perspective of designing an authentic computational thinking curriculum with a focus on real-world problems The second issue is addressed within the framework of technological pedagogical content knowledge explicating in detail the body of knowledge that teachers need to have to be able to teach computational thinking in a K-6 environment An example of how these ideas can be applied in practice is also given While it is recognized there is a lack of adequate empirical evidence in terms of the effectiveness of the frameworks proposed herein it is expected that our knowledge and research base will dramatically increase over the next several years as more countries around the world add computer science as a separate school subject to their K-6 curriculum Keywords Computational thinking curriculum Pedagogical content knowledge Technological pedagogical content knowledge Teacher preparation K-6 Introduction In a world in which digital technology plays an important role in carrying out essential daily-life tasks it is imperative individuals have the education knowledge and skills to critically understand the technological systems they use as well as to be able to troubleshoot and problem solve when things go wrong (Wing 2006; Czerkawski 2015; National Research Council 2010) Czerkawski (2015) argues the knowledge that individuals need to have in order to competently respond to the challenges of the 21st century goes beyond the acquisition of mere skills with immediate application to knowledge with long-term value that will enable them to understand the basics of computer structures and practices In essence the society needs citizens who understand the true affordances of computers in terms of what they can and cannot do so they themselves become effective authors/creators of computational tools Wing (2006) broadened the idea of computation and proposed that computational thinking should be considered as a basic skill taught across the curriculum She defined computational thinking as the thought process of formulating and solving problems with the use of computers According to Wing (2006) the teaching of computational thinking as a basic skill across the school curriculum will enable K-12 students to learn abstract algorithmic and logical thinking and be prepared to solve complex and open-ended problems How do we then prepare our students to develop the knowledge they need to survive and effectively cope with the technological challenges of the 21st century? As many educators strongly argued this educational goal can be achieved by integrating computer science as a distinct discipline and a school subject in the K-12 curriculum (Barr & Stephenson 2011; Fluck Webb Cox Angeli Malyn-Smith Voogt & Zagami 2016; Goode Chapman & Margolis 2012; Hazzan Lapidot & Ragonis 2011; Tucker Deek Jones McCowan Stephenson & Verno 2003) Fluck et al (2016) stated that there is a strong case for integrating computer science in the K-12 curriculum with arguments from both the educational and economic sectors Succinctly the educational case asserts that computer science (a) develops and promotes a unique way of thinking about problems namely computational thinking that uses the power of logic algorithm abstraction and precision; (b) empowers individuals to create new artifacts and to move from being consumers of technology to producers of technology; and (c) redefines the way learners think about other disciplines and this can have a major impact on teaching practices such as for example interdisciplinary teaching in school The economic case stresses the critical shortage of applicants in IT-related jobs especially in Europe This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 48 while at the same time the European Commission predicts that major European countries such as UK will need an additional 500000 IT professionals by 2015 (Husing & Korte 2010) Adding computer science as a separate school subject to the core K-12 curriculum is however a complex issue that involves many legislative administrative political and educational challenges The latter are the focal point of this paper In particular there are two major educational challenges related to (a) what computer science content to teach across different educational levels and (b) what body of knowledge do teachers need to have to be able to teach the computer science curriculum Over the years a variety of computer science curricula representing different views about what is important to teach in computer science and when have been proposed in the literature and or enacted in different countries such as UK USA Austria Germany Mongolia Israel Greece Cyprus and recently Australia Well-known efforts in the United States are amongst others the Computer Science Principles Exploring Computer Science Beauty and Joy of Computing Project Lead the Way (PLTW) and Codeorg Computer Science Principles is part of a larger national effort in the United States namely the CS 10K Project that aims to develop effective high school computing curricula enacted in 10000 high schools taught by 10000 well-prepared teachers by 2016 Computer Science Principles constitutes a framework of standards from which high school computer science courses can be built (Astrachan & Briggs 2012) The framework is specified through a set of six Computational Thinking Practices (ie connecting computing developing computational artifacts analyzing problems and artifacts abstracting communicating and collaborating) and a set of seven Big Ideas of computer science (ie creativity abstraction data and information algorithms programming Internet and global impact) and has been adopted by several high schools in the United States for developing computer science courses such as the Beauty and Joy of Computing Codeorg and PLTW (Astrachan & Briggs 2012; desJardins 2015) The Beauty and Joy of Computing course focuses on the Big Ideas of computing and its main objective is to expose students to the beauty and joy of programming by engaging them in meaningful projects using the Snap programming language Similarly Codeorg is a high school course with lessons and programming projects around the seven Big Ideas of computing as well whereas the PLTW uses Python as its primary programming environment to expose students to different computational thinking projects Analogously in various other countries similar initiatives have also been undertaken for introducing computer science to high school students (van Diepen Perrenet & Zwaneveld 2011; Micheuz 2008; Furber 2012) Undoubtedly during the last two decades a lot of work has been done by the computer science education community in promoting computer science as a school subject in secondary education Unfortunately the same conclusion cannot be reached about the status of computer science in the elementary school curriculum (grades K-6 approximately from 6 to 12 years old) A number of computer science education researchers have written about their concerns in regards to teaching computer science in K-6 (eg Armoni 2012) These concerns are primarily linked to the incompatibility between abstraction an essential process in computer science and children’s weakness to understand abstraction because of their very young age Armoni (2012) explained that abstraction is an inherent component of computer science that is always encapsulated during the process of thinking about and automating a solution to a problem From a Piagetian perspective children before the age of seven cannot really understand concrete logic whereas children between seven and eleven years old can solve problems that apply to concrete objects but not problems that apply to abstract concepts or phenomena Conversely Gibson (2012) argued that high school is too late for exposing students to computer science for the first time and stated that early exposure during kindergarten is necessary In his research Gibson (2012) found that young children can think abstractly when concrete reference systems are used to situate their thinking Recently there has been much impetus in bringing computer science experiences to elementary school children (Kumar 2014) Kumar (2014) wrote about the proliferation of app development startup companies that have targeted “early childhood computing education as the next emerging frontier” (p 52) and about formal deliberative initiatives for developing computer science curricula for K-6 students Succinctly we acknowledge the effort by Prottsman (2014) who reported on the development of the Thinkersmith curriculum in 2011 which introduced a stand-alone set of unplugged activities for K-8 specifically designed to provide students with strong computer science foundations without using computers Lessons in this curriculum such as Binary Baubles used materials found in games and crafts to teach authentic computer science concepts In 2013 Codeorg expanded on what ThinkerSmith created and offered a 20-hour unplugged curriculum for grades K-8 After the wide adoption of this curriculum in 2015 Codeorg developed further the existing 20-hour unplugged curriculum which now includes This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 49 more than 55 lessons CS Unplugged another unplugged computer science (CS) approach proposed by Bell Witten Fellows Adams and McKenzie (2015) is a collection of activities that teach computational thinking through engaging games and puzzles that use cards string crayons and lots of physical movement Students learn about binary numbers and algorithms without using computer programming Clearly early computing education is now at the forefront and studies toward this line of research are urgently needed in order to develop an informed body of knowledge about learning and teaching computer science in K-6 Accordingly the authors propose a curriculum framework with a focus on promoting computational thinking skills for ages 6 to 12 While computational thinking is just one element of computer science albeit an important one (Fluck et al 2016) the authors suggest a curriculum for K-6 with an explicit focus on computational thinking before covering more theoretical and applied concepts of computer science in secondary education Particularly this study sought to address the following questions (a) what computational thinking skills should a curriculum promote in K-6? and (b) what knowledge do teachers need to have to be able to teach a computational thinking curriculum in K-6? A definition of computational thinking While the concept of computational thinking in education can be traced back to the work of Seymour Papert (Papert 1980) Wing’s (2006) article has rekindled the interest for promoting computational thinking in K-12 Other efforts aiming at developing a definition for computational thinking include among others the National Academy of Sciences workshop (National Research Council 2010) the initiative undertaken by Furber (2012) and workshops organized by the Computer Science Teachers Association (CSTA) and the International Society for Technology in Education (ISTE) Succinctly the 2010 National Research Council’s report differentiated computational thinking from computer literacy computer programming and computer applications (ie games) and broadened the term to include core concepts from the discipline of computer science such as abstraction decomposition pattern generalization visualization problem-solving and algorithmic thinking Similarly Furber (2012) offered a concise definition of computational thinking as “the process of recognizing aspects of computation in the world that surrounds us and applying tools and techniques from computer science to understand and reason about both natural and artificial systems and processes” (p 29) CSTA and ISTE in collaboration with leaders from higher education industry and K-12 education developed an operational definition of computational thinking as a problem-solving process that includes but is not limited to the following elements (a) Formulating problems in a way that enables us to use a computer and other tools to help solve them; (b) Logically organizing and analyzing data; (c) Representing data through abstractions such as models and simulations; (d) Automating solutions through algorithmic thinking (ie a series of ordered steps); (e) Identifying analyzing and implementing possible solutions with the goal of achieving the most efficient and effective combination of steps and resources; and (f) Generalizing and transferring this problem-solving process to a wide variety of problems Despite the fact that currently there is not one unanimous definition of computational thinking it seems fair to conclude that based on the literature reviewed in this study researchers have come to accept that computational thinking is a thought process that utilizes the elements of abstraction generalization decomposition algorithmic thinking and debugging (detection and correction of errors) Abstraction is the skill of removing characteristics or attributes from an object or an entity in order to reduce it to a set of fundamental characteristics (Wing 2011) While abstraction reduces complexity by hiding irrelevant detail generalization reduces complexity by replacing multiple entities that perform similar functions with a single construct (Thalheim 2000) Abstraction and generalization are often used together as abstracts are generalized through parameterization to provide greater utility Decomposition is the skill of breaking complex problems into simpler ones (National Research Council 2010) Algorithmic thinking is a problem-solving skill related to devising a step-by-step solution to a problem and differs from coding (ie the technical skills required to use a programming language) (Selby 2014) Additionally algorithmic notions of sequencing (ie planning an algorithm which involves putting actions in the correct sequence) and algorithmic notions of flow of control (ie the order in which individual instructions or steps in an algorithm are evaluated) are This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 50 also considered important elements of computational thinking (Selby 2014) Debugging is the skill to recognize when actions do not correspond to instructions and the skill to fix errors (Selby 2014) Table 1 shows the elements of computational thinking as these have been discussed and defined in this section Accordingly this conceptual framework is the one that was adopted for developing the computational thinking curriculum framework for K-6 presented in the next section Table 1 The elements of computational thinking Element Definition 1 Abstraction The skill to decide what information about an entity/object to keep and what to ignore (Wing 2011) 2 Generalization The skill to formulate a solution in generic terms so that it can be applied to different problems (Selby 2014) 3 Decomposition The skill to break a complex problem into smaller parts that are easier to understand and solve (National Research Council 2010; Wing 2011) 4 Algorithms a Sequencing b Flow of control The skill to devise a step-by-step set of operations/actions of how to go about solving a problem (Selby 2014) The skill to put actions in the correct sequence (Selby 2014) The order in which instructions/actions are executed (Selby 2014) 5 Debugging The skill to identify remove and fix errors (Selby 2014) A computational thinking curriculum framework for K-6 Based on the five computational thinking skills shown in Table 1 a computational thinking curriculum framework is developed and presented in Table 2 Table 2 shows indicators of competence for all five computational thinking skills namely abstraction generalization decomposition algorithmic thinking and debugging in a progression from simple to complex across the educational levels of K-2 3-4 and 5-6 Succinctly the framework aims at engaging children in thinking and problem solving by developing a solution to a problem automating the solution through algorithmic thinking and generalizing this solution to new problems when common patterns are identified or recognized In essence the framework aims at introducing students of a very young age to the thinking processes of computational thinking so they become competent to learn more advanced theoretical and practical topics of computer science in secondary education In addition the framework targets the development of all five computational thinking skills across all K-6 levels albeit at different levels of competence through the use of examples and tasks that are within the reach of children either with or without external support (external reference systems) It is noted that the boundaries specified for each level may possibly vary from school to school and from classroom to classroom By the same token it is also expected that refinements to the curriculum framework will be ongoing once data become available from pilot offerings of different curricula aligned with the proposed framework in diverse contexts Table 2 A computational thinking curriculum framework for K-6 Skill Grade level (age level) K-2 (ages 6 to 8) 3-4 (ages 9 to 10) 5-6 (ages 11 to 12) Abstraction  With the use of external reference systems create a model/representation to solve a problem (ie using specific directional language - forward left turn right turn back - and turns of a given degree (90 180 270 360) children create a path and write instructions to enable others to follow the path or children design a mat based on a story and have their Bee-Bot  Create a model/representation to solve a problem (ie create an object and assign properties to it during an activity of digital game design and creation)  Create a new model/representation to solve a problem (ie create a simulation using Scratch) This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 51 follow the path from the narrative) Generalization  Identify common patterns between older and newer problem-solving tasks and use sequences of instructions previously employed to solve a new problem (ie use a sequence of instructions from an older path to program the BeeBot to follow a new path that includes the older path)  Remix and reuse (by extending if needed) resources that were previously created  Remix and reuse (by extending if needed) resources that were previously created Decomposition  Break a complex task into a series of simpler subtasks (ie break a longer path into a series of smaller paths that the Bee-Bot can follow)  Break a complex task into simpler subtasks  Develop a solution by assembling together collections of smaller parts  Break a complex task into simpler subtasks  Develop a solution by assembling together collections of smaller parts Algorithmic thinking  Define a series of steps for a solution  Put instructions in the correct sequence  Define a series of steps for a solution  Put instructions in the correct sequence  Repeat the sequence several times (iteration)  Define a series of steps for a solution  Put instructions in the correct sequence  Repeat the sequence several times (iteration)  Make decisions based on conditions  Store retrieve and update variables  Formulate mathematical and logical expressions Debugging  Recognize when instructions do not correspond to actions  Remove and fix errors  Recognize when instructions do not correspond to actions  Remove and fix errors  Recognize when instructions do not correspond to actions  Remove and fix errors Note model/representation = can be conceptual mathematical mechanical textual graphical etc Curriculum design issues A focus on a holistic design approach The framework presented in Table 2 constitutes a general framework that can be used to develop various computational thinking programs courses or modules in K-6 The curriculum framework is conceptualized in a generic form to allow teachers the freedom and agency to adapt and customize the framework as they see fit for their own classrooms and students According to van den Akker (2010) this enactment perspective where teachers create their own curriculum realities is increasingly replacing the fidelity perspective on implementation where teachers faithfully follow curricular prescriptions from external sources Accordingly this trend “puts even more emphasis on teachers as key people in curriculum change” (van den Akker 2010 p 185) underlining the utmost importance of relevant teacher preparation In view of that the authors herein propose the holistic design approach as one method that teachers can use to enact the computational thinking framework proposed in this paper A holistic design approach attempts to “deal with complexity without losing sight of the separate elements and the interconnections between those elements” (van Merriënboer & Kirschner 2007 p 6) It is the opposite of an atomistic design where complex contents and tasks are reduced to simpler elements promoting this way content compartmentalization and fragmentation Compartmentalization and fragmentation support the separation of a whole This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 52 into small distinct and often isolated parts For example teachers teach children to think computationally by teaching them abstraction then decomposition followed by generalization algorithmic thinking and debugging It is doubtful if in the end children will have the opportunity to practice the whole complex skill (computational thinking in this case) in its entirety and doubtful if they will ever learn to think computationally On the other hand a holistic design approach aims at eliminating compartmentalization and fragmentation by focusing on whole complex and authentic learning tasks without losing sight of the individual elements that make up the complex whole Thus with this approach if implemented correctly by the teacher children learn to think computationally to solve a problem and also learn all other constituent and interconnected pieces of knowledge (theoretical and or practical) that are directly related with the computational thinking task We support the holistic design approach for teaching computational thinking and emphasize here two design steps in the process namely (a) the design of problemsolving tasks with a focus on real-life issues and (b) the sequencing of problem-solving tasks from simple to complex We do acknowledge that more design steps exist in the literature With regard to the first design step it is argued that the sources of the computational thinking curriculum ought to be problems issues and concerns directly related to life itself A curriculum of this kind will result in usable knowledge - that is knowledge that can be applied directly in the context of real life problems and concerns at hand - and not in inert knowledge (Voogt Fisser Good Mishra & Yadav 2015; Webb Fluck Cox Angeli-Valanides Malyn-Smith Voogt & Zagami 2015) Educational researchers have found that a curriculum that is focused on problem solving around real-world problems can result in greater intellectual curiosity motivation improved attitude toward schooling and higher achievement in college (Wolf & Brandt 1998) Consequently a curriculum designed around real-life problems can be a way to make computational thinking relevant to students’ lives and thus a way to keep them interested in the subject matter Ultimately this may end up in increasing substantially the number of students who will eventually pursue computer science as their major field of study later in college From an implementation point of view a curriculum designed around real-life problems demands a wider range of content simply because authentic real-world problems are usually multidisciplinary in nature As a consequence a curriculum from this perspective poses new demands on teaching often requiring close collaboration among teachers with different content expertise It should be noted that real-life problem-solving tasks constitute challenging design endeavors and a curriculum designer may approach the design process through the means of rapid prototyping before designing an entire educational program course or module With regard to the sequencing of the problem-solving tasks a sequence from simple whole tasks to more complex whole tasks is recommended It is made clear that each problem-solving task irrespective of complexity engages the learner in whole-task problem-solving experiences In the context of computational thinking this means that each learning task simple or complex confronts the learner with all or almost all of the constituent computational thinking skills for a real-life computational thinking experience All tasks are meaningful authentic and relevant to children’s life A sequence of tasks constitutes the backbone of the computational thinking curriculum It is also evident that children may need guidance and support as they start working on more challenging tasks Support may be provided in the form of external reference systems to help students gradually develop abstractions Students may also need guidance with the problem-solving process itself The knowledge that teachers need to teach the curriculum As Gal-Ezer and Stephenson (2010) stated having a curriculum is important but preparing teachers to teach the curriculum is also critical Amongst computer science teacher educators the framework of pedagogical content knowledge (PCK) has been highly regarded as an appropriate framework for defining the knowledge teachers need to have to be able to teach computer science (eg Hubwieser Magenheim Mühling & Ruf 2013; Saeli 2012) Succinctly PCK refers to a body of knowledge which is highly context sensitive cannot be conceptualized in isolation from teachers’ classroom and teaching experiences and is beyond and above a simple synthesis of knowledge of subject matter and pedagogy (Shulman 1986; Shulman 1987) PCK is an amalgam of knowledge that “embodies the aspects of content most germane to its teachability” (Shulman 1986 p 9) and refers to the transformation of content into forms that are understandable to learners According to van Driel and Berry (2012) having a good PCK means that teachers have several representations of the most commonly taught topics within a certain subject The more representations teachers have at their disposal and the better they recognize learning difficulties the more effectively they can deploy their PCK (van Driel & Berry 2012) This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 53 Within the domain of computer science a number of computer science education researchers attempted to define PCK for computer science either in general ways (Hubwieser et al 2013; Saeli Perrenet Jochems & Zwaneveld 2011; Stephenson Gal-Ezer Haberman & Verno 2005) or more specific ways (Saeli 2012) Saeli et al (2011) concentrated on the teaching of programming in secondary education and provided a general conceptualization of PCK for the domain of programming in terms of its constituent elements (ie what to teach about computer programming how to teach programming and what are learners’ difficulties in programming) In a following study Saeli (2012) was able to provide a more specific conceptualization of PCK for the domain of programming in the context of secondary education which included details about each constituent knowledge base In terms of the content to be taught she mentioned loops data structures arrays problem-solving skills decomposition parameters and algorithms amongst others Regarding teachers’ pedagogical knowledge she mentioned offering a simple programming language to better facilitate students’ effort to learn the syntax of the language and choosing several worthy problems to solve Lastly she identified learners’ difficulties about different programming concepts such as loops arrays variables and general problem-solving skills In the early 2000s though a number of educational researchers undertook systematic efforts for extending and enriching the concept of PCK by adding Technology Knowledge as another essential category of teachers’ knowledge base (Angeli & Valanides 2005; Koehler & Mishra 2008; Niess 2005) From this perspective the introduction of Technology Knowledge in the existing framework of PCK successfully expanded PCK to TPCK - that is Technological Pedagogical Content Knowledge (Angeli & Valanides 2005; Angeli & Valanides 2009; Koehler & Mishra 2008; Niess 2005) A conceptualization of the framework of TPCK is proposed by Angeli and Valanides (2005; 2009) as shown in Figure 1 According to Figure 1 TPCK is conceptualized as a unique body of knowledge that is formed by the contribution of five distinct knowledge bases namely content knowledge pedagogical knowledge knowledge of learners knowledge of the educational context and technology knowledge (Angeli & Valanides 2005; Angeli & Valanides 2009) This body of knowledge grows when teachers are engaged systematically in useful educational practices either in their own classrooms or teacher professional development programs Figure 1 Technological Pedagogical Content Knowledge (adopted from Angeli & Valanides 2005) TPCK is an important body of knowledge for the field of computer science because technology is at the center of the computer science domain either as a means in itself (ie to learn to use the technology as a goal) or as a means for achieving or teaching something else (ie to use technology in order to solve a problem or to teach a computer science concept) For the purposes of this study the authors provide a conceptualization of TPCK for the construct of computational thinking as it is defined in Table 1 in order to better explain what teachers need to know to be able to teach a computational thinking course aligned with the framework proposed in Table 2 This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 54 Analytically content knowledge (CK) is defined as knowledge about computational thinking (CKCT ) This includes knowledge and understanding about the skills of abstraction (including modeling) denoted as CKCT(A)  generalization denoted as CKCT(G)  decomposition designated as CKCT(D) algorithmic thinking designated as CK CT(Algo)  and debugging denoted as CK CT(Debug)  CK CT(Algo) includes knowledge of several computational thinking concepts such as data processing information sequencing loops parallel processing events conditions operators variables and dataflow of control Learner knowledge for computational thinking (LKCT ) includes knowledge about learners’ difficulties in (a) developing abstractions that are beyond of any particular programming language or tool denoted as LK CT(A)  (b) generalizing from one solution to another by identifying common patterns denoted as LKCT(G)  (c) decomposing complex problems to simpler ones designated as LKCT(D)  (d) thinking algorithmically to solve a problem (including difficulties in understanding relevant concepts such as sequencing loops flow of control conditions etc) denoted as LK CT(Algo)  and (e) debugging denoted as LKCT(Debug) Pedagogical knowledge for computational thinking (PKCT ) includes the general pedagogical knowledge applicable to all other content domains (ie the use of questions to promote understanding use of examples explanation demonstration) in addition to knowledge about subject-specific pedagogical practices pertinent to computational thinking PKCT is defined in terms of the following teaching tactics (a) model how to problem solve or think about a problem in iterative and incremental ways (b) present or explain a solution to a problem in terms of a series of steps (c) model decision making based on conditions (d) do something based on (and expanding) what others or you have done (reuse and remix) (e) show how a complex problem can be decomposed into simpler problems and develop a solution in increments (f) show how to design a model before writing a computer program for solving the problem and (g) try things out as you go and make revisions based on what happens Technology knowledge for computational thinking (TKCT ) includes knowledge and skills about how to (a) operate/use a variety of technologies (b) invent new technologies/tools (c) solve a task using technical processes methods and tools and (d) learn and adapt to new technologies Context knowledge for computational thinking (CXCT ) is defined from the point of view explicated by PorrasHernández and Salinas-Amescua (2013) who proposed to regard context knowledge along two important dimensions namely (a) scope (macro mezzo and micro level context) and (b) actor (students’ and teachers’ inner and external context) Macro context is defined by social political technological and economic conditions at a global level that influence the value and worth of adding computer science and computational thinking to the school curriculum Mezzo context is defined by the social cultural political organizational and economic conditions settled in the local community and the educational institution about the value of computational thinking in children’s lives Finally micro context is the level that deals with in-class conditions for learning (eg available resources for computational thinking available technologies norms and policies beliefs expectations teachers’ and students’ goals about computational thinking) In addition Porras-Hernández and Salinas-Amescua (2013) argued that in order to comprehend teachers’ uses of technology it is important to consider teachers’ and students’ (actors’) unique characteristics as they are brought in the context as separate objects of knowledge with internal (eg students’ needs preferences misconceptions learning difficulties prior knowledge teachers’ self-efficacy pedagogical beliefs) and external contexts (eg ethnicity culture community and socioeconomic background) Lastly TPCK for computational thinking (TPCKCT ) is defined as knowing how to (1) Identify a range of creative and authentic computational thinking projects; (2) Identify a range of technologies with an appropriate set of affordances in terms of providing the necessary technological means for practicing/teaching the whole range of computational thinking skills with each project; and (3) Use the affordances of technology to transform CKCT and PKCT using representations that make the overall computational thinking experience comprehensible for all learners This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 55 The question that naturally arises at this point is “What form should teacher preparation take so that teachers develop their TPCKCT competencies adequately?” In the next section we provide preliminary research evidence from a teacher education course on preparing teachers how to teach computational thinking Teacher preparation in developing TPCK competencies for computational thinking In the fall of 2015 fifteen elementary school teachers pursuing a master’s degree in instructional technology were enrolled in a course on learning how to teach computational thinking in their K-6 classrooms All teachers were unfamiliar with computational thinking and had no prior experiences with computer programming The teachers participated in 13 three-hour weekly meetings The participants were engaged in hands-on design activities with the Scratch computer programming environment The learning-by-design approach which has been shown to be effective in contemporary teacher development studies (McKenney Kali Markauskaite & Voogt 2015) was used in the course to engage teachers in designing models of different problem situations before constructing computer programs for solving the problems The course instructor initially engaged the teachers in authentic problem solving by asking them to think about the city/town they were living and identify ways of how people’s lives in those places could be improved The teachers explained their thinking about possible improvements and then the instructor asked them to think about how computers could be used for solving some of the problems they identified A brainstorming activity resulted in ten different ideas that constituted the real-life tasks that the course instructor used to teach the teachers about computational thinking The ten tasks were sequenced from simple to complex based on the involvedness of the solution For each problem teachers were taught how to create a model first before writing a computer program for solving the problem Creating a model proved to be extremely difficult for the teachers and often times they asked their instructor for help Early attempts in creating models resulted in models containing lots of unnecessary information but gradually teachers with the help of the course instructor learned that models are abstractions of something free from inessential detail The teachers were taught how to create models through a process that was explicitly taught to them and involved identification of the important entities of the model their characteristics (parameters in the model) and relationships either quantitative or qualitative between the parameters of the entities The teachers showed commitment in developing the best models they could possibly create and often times they exhibited lots of creative ideas of how to make them better In regards to teaching teachers computer programming the course instructor used systematically the following pedagogical strategies (a) decide what sprites are needed for your project (b) decide what scripts are needed for your project (c) organize the scripts in meaningful ways for you and others (d) develop some code try it out then develop some more (e) test and debug and (f) build or extend on existing projects or ideas During the programming tasks computational concepts such as data processing information sequencing loops parallel processing events conditions operators variables and dataflow of control were explicitly explained and illustrated with lots of programming examples Teachers had no difficulties with understanding programming concepts even though they found the concepts of variables and conditional logic more challenging than the others Concluding remarks In conclusion the authors in this paper presented a computational thinking curriculum framework for designing a curriculum for K-6 an area of research that is still in its infancy described design guidelines for enacting the curriculum framework and defined TPCKCT as the body of knowledge that teachers need to have to be able to teach the curriculum in K-6 In addition the authors provided an example of a teacher preparation course that was specifically designed to promote teachers’ TPCKCT  It is recognized that more empirical evidence in the form of rich educational cases is needed in terms of further investigating the effectiveness of the frameworks proposed herein in a variety of contexts It is expected that with the gradual adoption of computer science as a distinct school subject in the K-6 curriculum of countries around the world our knowledge and research base regarding the issues discussed in this paper will dramatically expand over the next several years This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 56 References Angeli C & Valanides N (2005) Preservice teachers as ICT designers An Instructional design model based on an expanded view of pedagogical content knowledge Journal of Computer-Assisted Learning 21(4) 292-302 Angeli C & Valanides N (2009) Epistemological and methodological issues for the conceptualization development and assessment of ICT-TPCK Advances in technological pedagogical content knowledge (TPCK) Computers & Education 52 154- 168 Armoni M (2012) Teaching CS in kindergarten How early can the pipeline begin? ACM Inroads 3(4) 18-19 Astrachan O & Briggs A (2012) The CS principles project ACM Inroads 3(2) 38-42 Barr V & Stephenson C (2011) Bringing computational thinking to K-12 What is involved and what is the role of the computer science education community? ACM Inroads 2(1) 48-54 Bell T C Witten I H Fellows M R Adams R & McKenzie J (2015) CS Unplugged An Enrichment and extension programme for primary-aged students Retrieved from http//csunpluggedorg/wpcontent/uploads/2015/03/CSUnplugged_OS_2015_v31pdf Czerkawski B (2015) Computational thinking in virtual learning environments In Proceedings of E-Learn World Conference on E-Learning in Corporate Government Healthcare and Higher Education 2015 (pp 993-997) Chesapeake VA Association for the Advancement of Computing in Education (AACE) desJardins M (2015) Creating AP® CS principles Let many flowers bloom ACM Inroads 6(4) 60-66 Fluck A Webb M Cox M Angeli C Malyn-Smith J Voogt J & Zagami J (2016) Arguing for computer science in the school curriculum Educational Technology and Society 19(3) 38-46 Furber S (2012) Shut down or restart? The way forward for computing in UK schools London UK The Royal Society Gal-Ezer J & Stephenson C (2010) Computer science teacher preparation is critical ACM Inroads 1(1) 61-66 Gibson J P (2012 July) Teaching graph algorithms to children of all ages In Proceedings of the 17th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education (ITiCSE’12) (pp 34–39) New York NY ACM Goode J Chapman G & Margolis J (2012) Beyond curriculum The Exploring computer science program ACM Inroads 3(2) 47-53 Hazzan O Lapidot T & Ragonis N (2011) Guide to teaching computer science An Activity-based approach London UK Springer Hubwieser P Magenheim J Mühling A & Ruf A (2013 August) Towards a conceptualization of pedagogical content knowledge for computer science In Proceedings of the ninth annual international ACM conference on International computing education research (pp 1-8) New York NY ACM Husing T & Korte W B (2010) Evaluation of the implementation of the Communication of the European Commission E-skills for the 21st century Bonn Germany Empirica Retrieved from http//hdlvocededuau/10707/323186 Koehler M J & Mishra P (2008) Introducing TPCK In AACTE Committee on Innovation and Technology (Eds) Handbook of Technological Pedagogical Content Knowledge (TPCK) for educators (pp 3–29) New York NY Routledge Kumar D (2014) Digital playgrounds for early computing education ACM Inroads 5(1) 20-21 McKenney S Kali Y Markauskaite L & Voogt J (2015) Teacher design knowledge for technology enhanced learning An Ecological framework for investigating assets and needs Instructional science 43(2) 181-202 Micheuz P (2008) Some findings on informatics education in Austrian academic secondary schools Informatics in Education 7(2) 221-236 National Research Council (2010) Committee for the workshops on computational thinking Report of a workshop on the scope and nature of computational thinking Washington DC National Academy Press doi1017226/12840 Niess M L (2005) Preparing teachers to teach science and mathematics with technology Developing a technology pedagogical content knowledge Teaching and Teacher Education 21 509–523 Papert S (1980) Mindstorms Children computers and powerful ideas New York NY Basic Books Inc This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 57 Porras-Hernández L H & Salinas-Amescua B (2013) Strengthening TPACK A Broader notion of context and the use of teacher's narratives to reveal knowledge construction Journal of Educational Computing Research 48(2) 223-244 Prottsman K (2014) Computer science for the elementary classroom ACM Inroads 5(4) 60-63 Saeli M (2012) Teaching programming for secondary school A Pedagogical content knowledge based approach (Unpublished doctoral dissertation) Technische Universiteit Eindhoven Netherlands Saeli M Perrenet J Jochems W M & Zwaneveld B (2011) Teaching programming in secondary school A Pedagogical content knowledge perspective Informatics in Education 10(1) 73-88 Selby C C (2014) How can the teaching of programming be used to enhance computational thinking skills? (Unpublished doctoral dissertation) University of Southampton Southampton UK Shulman L S (1986) Those who understand Knowledge growth in teaching Educational Researcher 15 4–14 Shulman L S (1987) Knowledge and teaching Foundations of the new reform Harvard Educational Review 57 1-23 Stephenson C Gal-Ezer J Haberman B & Verno A (2005) The New educational imperative Improving high school computer science education New York NY Computer Science Teachers Association (CSTA) Thalheim B (2000) Fundamentals of entity-relationship modeling New York NY Springer Tucker A B Deek F Jones J McCowan D Stephenson C & Verno A (2003) A Model curriculum for K-12 computer science New York NY ACM/Computer Science Teachers Association van Diepen N Perrenet J & Zwaneveld B (2011) Which way with informatics in high schools in the Netherlands? The Dutch dilemma Informatics in Education 10(1) 123-148 van Driel J H & Berry A (2012) Teacher professional development focusing on pedagogical content knowledge Educational Researcher 41(1) 26-28 van den Akker J (2010) Building bridges How research may improve curriculum policies and classroom practices In Beyond Lisbon 2010 Perspectives from research and development for education policy in Europe (pp 177-195) Aarau Switzerland CIDREE van Merriënboer J V & Kirschner P A (2007) Ten steps to complex learning A Systematic approach to four-component instructional design Mahwah NJ Lawrence Erlbaum Voogt J Fisser P Good J Mishra P & Yadav A (2015) Computational thinking in compulsory education Towards an agenda for research and practice Education and Information Technologies 20(4) 715-728 Webb M Fluck A Cox M Angeli-Valanides C Malyn-Smith J Voogt J & Zagami J (2015) Curriculum Advancing understanding of the roles of computer science/informatics in the curriculum In K-W Lai (Ed) EDUsummIT 2015 Summary Report (pp 60-68) Retrieved from http//wwwcurtineduau/edusummit/local/docs/edusummit2015-ebookpdf Wing J (2006) Computational thinking Communications of the ACM 49(3) 33-35 Wing J M (2011 March) Computational thinking Retrieved from https//cstaacmorg/Curriculum/sub/CurrFiles/WingCTPrezpdf Wolf P & Brandt R (1998) What do we know from brain research? Educational Leadership 56(3) 8-13 This content downloaded from 1422317828 on Wed 29 Jan 2020 211021 UTC All use subject to htt 
A Systematic Mapping Study on Assessing Computational Thinking Abilities Ana Liz Souto O de Araujo Software Practices Laboratory Federal University of Campina Grande Departament of Exact Sciences Federal University of Para ́ıba Para ́ıba Brazil analiz@copinufcgedubr Wilkerson L Andrade Software Practices Laboratory Federal University of Campina Grande Para ́ıba Brazil wilkerson@computacaoufcgedubr Dalton D Serey Guerrero Software Practices Laboratory Federal University of Campina Grande Para ́ıba Brazil dalton@computacaoufcgedubr Abstract—Several initiatives have been created to promote Computational Thinking (CT) abilities in students There are multiple approaches of assessing CT and wide abilities and skills involved However the evidence on how to assess CT has not yet been systematically grouped or reviewed The goal of our study is to identify and classify approaches to promote CT and the different ways of assessing CT abilities To achieve this goal a systematic mapping study was planned and executed The results reveal that (i) programming courses are the most common pedagogical approaches to promote CT for K-12 students; (ii) multiple skills are involved in CT but solving problems algo- rithms and abstraction are most common abilities assessed; and (iii) codes and multi-choice questionnaires are the most common artifacts for assessing CT abilities This study points out to the fact that there are open questions for exploring and developing new researches for promoting and assessing CT abilities I INTRODUCTION According to Wing in her seminal paper on the subject computational thinking is about developing “fundamental not rote skills” for problem solving She mentioned among others the ability to think recursively use abstraction and decomposition when dealing with complex tasks and to use heuristics to reason about possible solutions [1] Thinking like a computer scientist requires being able to think in multiple levels of abstraction Since then several researchers have focused on defining the core set of skills that characterize computational thinking (CT) According to Hu CT represents a cognitive process and hence it should be seen as a hybrid paradigm that accommodates different thinking models such as logical algorithmic analytic mathematical engineering and creative thinking [2] As a con- sequence several different abilities and skills are associated with CT For instance while analysis and generalization are frequently employed in discussions of general problem solving skills abilities like designing systems programming comput- ers as well as being able to apply concepts of automation and modeling are more frequently employed in discussions of general computer science concepts [3] Most research results related to CT skills and abilities can be found in recent academic literatures Some studies have focused on the relation of CT and teaching in K-12 Grover et al presented environments and tools that foster CT and how they interact with Computing Education in K12 [4] Voogt et al presented a historical review of CT concepts and gathered examples of how CT is taught They also discussed the position of CT in the K-12 curriculum [5] Taking a different perspective Selby and Woollard have recently proposed a definition of CT and the main skills involved [3] based on a study of the most frequently terms and skills associated to CT [3] A related but different field of investigation focuses on how to assess CT skills and abilities In the report of the Workshop on Pedagogical Aspects of Computational Thinking from 2011 the National Research Council cites three reasons for assessing computational thinking abilities (i) to judge the curriculum and related materials and pedagogy (ii) to judge the individual’s progress and (iii) to manage instructor training and support [6] However while a significant amount of research has been developed on skills the discussion on their assessment is still in its infancy In this study we focus on the approaches used by researchers and teachers to observe and assess the development of CT abilities in students As far as we know there is no system- atic review of the scientific literature on the subject of CT assessment We identified and classified proposed approaches to promote CT and the different ways used to assess abilities within those approaches More concretely the study aimed at (i) characterizing the state of the art of research on assessing CT abilities in education (ii) identifying and classifying the different approaches and artifacts used to assess CT abilities in various educational levels and (iii) discussing the results based on approaches artifacts and abilities assessed To achieve this goal we planned and executed a systematic mapping study based on the guidelines established by Petersen et al for such studies [7] The rest of this paper is organized as follows In Section II we briefly discuss related work In Section III we present our research methodology and the research questions that guided the study In Section IV we present the data collected along the study In Section V we present and discuss the results achieved Finally in Section VI we present our conclusions 978-1-5090-1790-4/16/$3100 ©2016 IEEE II RELATED WORK To the best of our knowledge there are no literature reviews about assessing CT abilities The existing studies about CT involve definition skills and role of CT in K-12 [4] [5] [3] These studies are important because they show an overview of essential aspects of CT and indicate the abilities that should be promoted and assessed The systematic review presented by Barcelos et al consid- ered studies that describe and evaluate approaches to integrate CT and mathematics [8] A wide variety of mathematical topics are developed with emphasis on Algebra Calculus and higher-order thinking skills Programming is the main ap- proach followed by robotics and spreadsheets Mathematical model is not related to CT according to this study Another systematic review identified tools used for promoting CT [9] Scratch1 is the most common tool for promoting CT followed by App Inventor2 and Alice 3 Both systematic reviews are interested in promoting CT with mathematics or tools but they do not show interest in how to assess the development of CT in those context The literature review presented by Lye and Koh focused on teaching CT through programming [10] The computational concept (ie concepts that programmer use) is widely explored in promoting CT through programming The authors pro- pose that more intervention studies focused on computational practices and computational perspectives could be conducted for the promotion of CT In addition they propose that a constructionism-based problem-solving learning environment with information processing scaffolding and reflection activ- ities could be designed to foster computational practices and computational perspectives The authors do not reveal how to assess the proposed approach III RESEARCH METHODOLOGY This section details the methodology used for executing this systematic mapping study The objective of a mapping study is to categorize several primary studies frequently providing a visual summary of results In addition clusters and research gaps are evidenced allowing the identification of possible open problems for future works [7] In a mapping study papers are categorized based on re- search questions aiming at providing a visual summary of the field This methodology has been increasingly used in Software Engineering by Petersen et al [7] Because of this we chose the protocol defined by Petersen et al and applied it to the Computer and Education field As every mapping study has a clear protocol to guide each step and outcome of the protocol is detailed in the rest of this section A Research Questions There are multiple approaches for promoting and assessing CT along with several involved abilities So the following 1 https//scratchmitedu/ 2 http//appinventormitedu/explore/ 3http//wwwaliceorg/ research questions (RQ) were defined in order to guide this systematic mapping study • RQ1 - What are the pedagogical approaches for promot- ing CT and for which kind of audience? The purpose is to elicit what kind of schemes/activities the researchers apply to promote the acquisition of CT skills and for which audience (students’ grade) these studies have been carried out • RQ2 - What are the skills assessed in CT? The aim is to bring forth which abilities or skills are assessed by the pedagogical approach In this work skill and ability are considered as synonyms • RQ3 - What are the instruments or artifacts for assessing CT abilities? The objective is to identify which instruments or artifacts are used in order to measure the CT abilities in each pedagogical approach B Conduct Search After defining the research questions a strategy was de- signed to select the related papers The following steps were adopted 1) Analyze the terms to be used in the search string in order to answer the research questions; 2) Decide what the central idea in Computational Thinking and assess abilities is; 3) Choose synonyms of “assessing” in the context of edu- cation; 4) Test each synonym of “assessing” in search analyze results in each digital library and select the synonyms; 5) Use Boolean OR to connect the selected assessing synonyms; 6) Link “Computational Thinking” using Boolean AND; 7) Execute pilot tests to gauge the search string As a result the following search string was obtained “Computational Thinking” AND (assess OR analyze OR evaluation OR measure OR validation) Six digital libraries were chosen to conduct the research ACM ERIC IEEEXplore ScienceDirect (Elsevier) Springer and Scopus These digital libraries were chosen because they are the main publication vehicles of Computer Science and Education Table I presents the summary of the search returned by each digital library The studies were collected based on a title/abstract search Thus in this step the outcome was all papers selected in the initial search C Papers Screening All inclusion and exclusion criteria applied in this mapping study are described below The defined inclusion criteria are 1) Studies that are about assessing some ability or skill in the context of CT; 2) Studies in any kind of educational level/grade; TABLE I SUMMARY OF PRIMARY SEARCH RESULTS Digital Library/Database name ACM ERIC IEEEXplore ScienceDirect Scopus Springer Total Search Results 69 11 57 12 224 115 488 3) Studies reported in workshop OR conference OR jour- nal The defined exclusion criteria are 1) Studies that do not introduce how to assess or measure CT abilities or skills; 2) Studies that do not introduce “analysis” or “validation” of CT abilities ie papers that analyzed or validated the approach instead of CT abilities; 3) Studies that are not in the education context; 4) Studies that are in Computational Biology; 5) Secondary studies short papers and chapter of book The selection process was conducted in two steps In the first stage the title and abstract of all papers selected in the first search were read In this step duplicated papers secondary studies and short papers were removed 51 studies were judged as potentially relevant after this point In the second step all papers were read and the inclusion and exclusion criteria were applied Most studies were excluded because they did not demonstrate how to assess or measure CT abilities Accordingly in this last step 27 studies were selected as relevant to our goals To avoid search bias all stages were discussed by the three authors The outcome of this step was all studies selected to answer the research questions based on the inclusion and exclusion criteria IV RESULTS This section details the result of our mapping study The research was conducted from September 2015 to April 2016 First of all the general results extracted directly from the headers of the papers are presented such as countries where the research has been done publication vehicle (journal or conference) and studies distribution by year of publication Then the remaining sections answers each research question defined in Section III A General results 1) Countries distribution Fig 1 shows the countries distri- bution where each research has been done The United States is the leading country where approaches of assessing CT abilities have been investigated (16 studies) After that South Africa Italy and UK have 2 studies and other countries such as Brazil China Germany Hungary India Israel New Zealand Romania Singapore and South Korea have only 1 study The United States is the leading country in number of publi- cation A possible explanation is the presence of the Computer Fig 2 Publication vehicle distribution Science Teacher Association (CSTA) Computational Thinking Task Force CSTA Computational Thinking Task Force4 is responsible for current developments in CT and dissemination of teaching and learning resources related to CT 2) Publication vehicle Fig 2 presents the publication vehi- cle adopted by the selected studies Publication in conferences are the most frequent type with 70% (19 studies from 27) Journals appear with 30% (8 studies from 27) 3) Publication years Fig 3 presents the studies distribu- tion by year of publication We do not delimit time to conduct the research but the term “Computational Thinking” earned new signification in 2006 by Jannette Wing [1] However no work before 2006 was found The first selected study is from 2009 (1 study) In 2010 2011 and 2012 few studies were reported about assessing CT abilities (3 1 and 3 studies respectively) From 2013 there was an increase in the number of studies 5 studies in 2013 6 studies in 2014 7 studies in 2015 and 1 study in 2016 (until April 2016) 4 https//cstaacmorg/Curriculum/sub/CompThinkinghtml Fig 1 Countries distribution Fig 3 Studies distribution by year of publication TABLE III COURSES FOR PROMOTING CT Course Content Reference Frequency Scratch [11] [31] [20] [23] 4 Computational Thinking [12] [13] 2 App Inventor [18] [20] 2 Alice [17] 1 AgentClub [19] 1 Game design (Kodu) [37] 1 Computer Literacy Course [16] 1 Web design [14] 1 Introductory programming [20] 1 Multidisciplinary collaboration class [22] 1 Fig 4 Studies distribution by research approaches TABLE II PEDAGOGICAL APPROACHES FOR PROMOTING CT 4) Classification of research approaches The studies also were classified based on the research approaches The research approaches chosen by Petersen et al [7] were the following validation research evaluation research solution proposal experience papers philosophical papers and opinion paper (for definitions see [7]) Fig 4 shows the result of studies distribution by research approaches Philosophical papers and opinion papers were not found in the selected studies B RQ1 What are the pedagogical approaches for promoting CT and for which kind of audience? Table II presents four approaches applied to promote CT course test framework and tool In this mapping study the term course includes courses in general regardless of the duration Moreover the term course includes workshops modules or regular classes Test includes studies that only applied exams Framework is a model with the intention of measuring CT abilities At last tool comprises game digital ink and platform (online interactive platform that offers several activities to foster and evaluate CT abilities) From this point of view course was the leading pedagogical approach for promoting CT (13 studies) Tests were the second most common (6 studies) followed by frameworks (5 studies) and tools (3 studies) Since course was the most popular pedagogical approach Table III presents a classification by course content Program- ming course was the most common pedagogical approach (9 studies) Scratch was the most common programming environ- ment [11] [20] [23] [31] followed by App Inventor [18] [20] Two courses were specific about Computational Thinking [12] [13] The remainder included other programming environ- ments as Alice and AgentClub [17] [19] a game design course with Kodu [37] a computer literacy course with spreadsheets [16] a web design course [14] an introductory programming course with multiple languages [20] and a multidisciplinary collaboration class [22] Fig 5 Audience In addition this mapping study aimed at knowing for which kind of audience (students’ grade) these studies have been carried out Fig 5 grouped the students’ grade K-12 students were the leading audience (15 studies) followed by undergraduate students (8 studies) The undergraduates are Computer Science students and non-Computer Science students Kindergarten has one study Teachers and pre-service teachers have two studies C RQ2 What are the skills assessed in CT? The aim is to elicit which abilities or skills are assessed by the selected approaches The measured skills and abilities were identified but each study has adopted many different groups of abilities Table IV shows the skills and abilities assessed by each pedagogical approaches The most common abilities are emphasized in bold problem solving algorithms abstractions and decomposition For the best visualization of the frequency of abilities Fig 6 shows a word clouds from Table IV Fig 6 Word clouds of skills and abilities assessed in CT Approach Reference Frequency Course [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] 13 Test [24] [25] [26] [27] [28] [29] 6 Framework [30] [31] [32] [33] [34] 5 Tool [35] [15] [36] 3 TABLE IV SKILLS AND ABILITIES ASSESSED IN CT Skills / Abilities Reference Frequency Algorithm [17] [22] [23] [13] [12] [31] [30] [24] [26] [27] [28] [15] [36] [35] 14 Abstraction [17] [14] [22] [13] [12] [31] [30] [26] [18] 9 Programming [23] [11] 2 Logical thinking [22] [12] 2 Data representation [23] [13] [31] 3 Data collection data analysis [13] 1 Modeling [17] [15] 2 Decomposition [13] [12] [11] [31] 4 Procedures [13] [31] [20] 3 Automation [13] 1 Parallelization [13] [31] [20] 3 Simulation [13] [15] 2 Debugging [12] [15] 2 Sequences loops and conditionals [11] [33] [20] 3 Computational concepts computational practices and computational perspectives [32] [34] 2 Sensors [33] [18] [20] 3 Processes and transformations models and abstractions patterns and algorithms tools and resources inference and logic evaluations and improvements [30] [26] 2 Condicionals [11] 1 Recall [16] 1 Synchronize [21] 1 Troubleshooting [19] [37] 2 Computer Science fundamental concepts and computational literacy [25] [36] 2 Screen Interface events data persistence data sharing lists public web services accelerometer location awareness [18] 1 Parameters functions recursion event screen interface [20] 1 D RQ3 What are the instruments or artifacts for assessing CT abilities? The aim is to present the instruments or artifacts used in order to measure CT abilities Table V shows the instruments or artifacts classified based on approaches Questionnaire is classified in different types multiple-choice open-ended surveys and interviews In a multiple-choice questionnaire the student need to choose the only one correct alternative In an open-ended questionnaire the student need to write or draw the correct answer In a survey there is no right or wrong answer just the students opinion in a multiple- choice questionnaire Finally in a interview the student speaks answers to questions but there is not necessarily right or wrong answer Multiple-choice questionnaire is the most common artifact for assessing CT abilities in eleven studies [24] [11] [25] [26] [27] [37] [23] [28] [34] [36] Code is the second in ten studies [31] [32] [17] [18] [33] [19] [20] [21] [23] [34] followed by responses in nine studies [35] [14] [26] [16] [28] [29] [36] Survey interviews open-ended questionnaires lesson plan video journals and design scenarios are other instruments for assessing CT abilities Fig 7 shows only the frequency of instruments and artifacts The number of instruments is more than number of selected studies because each study can use more than one instrument for assessing CT abilities Fig 8 combines the results of instruments and research approaches in bubble plot Fig 7 Instruments and artifacts used to asses CT Video Survey Response Questionnaire Lesson plan Interview Game Design Scenarios Code Bubble plot of intruments and research approach Research 3 5 8 3 11 41 32 1 43 1 1 1 1 1 1 Fig 8 Instruments and research approaches bubble plot Instrument Evaluation Research Experience Papers Solution Proposal Validation Research TABLE V INSTRUMENTS AND ARTIFACTS USED TO ASSESS CT CATEGORIZED BY APPROACH practice CT abilities while avoiding the syntax hurdle as- sociated with text-based programming languages Moreover they are appointed to be pedagogically appropriate to K-12 students Computational Thinking is not an alternative to learn how to program However many studies argue that the CT can be initiated through programming Many other studies judge that programming is a good approach to promote CT but few of them worry about how to assess the development of CT individual’s progress and learning difficulties Programming can promote other abilities that may or may not be considered by CT for instance testing debugging looking for optimal solutions Because of that the concept of CT and the involved abilities should be discussed in the context of programming courses specifically for non-computer science students 2) Computational Thinking workshops Computational Thinking workshops have been designed to target both teach- ers [13] and pre-service [12] teachers In one study pre-service teachers participated in a one-week module of CT (two 50- minute classes) during the educational psychology course The module aims at demonstrating probabilistic reasoning algo- rithmic thinking heuristics hypothesis testing and problem solving The assessment was conducted based on a survey and three open-end questions for (i) explaining the concept of CT (ii) knowing whether CT can be integrated into the classroom and (iii) whether CT it is related to other disciplines In another study teachers participated in a three days workshop that showed them the correlation between their taught subjects and CT They were stimulated to use CT examples to teach in their respective classrooms The lesson plan done after the workshop were assessed in order to measure the teacher’s ability to synthesize the CT core concepts The courses differ about purpose time duration content and type of assessment In the first course the pre-service teachers were analyzed whether they had understood the content and whether they had intended to apply CT in future classroom The content involved multiple abilities beyond Computational Thinking but programming was not involved In the second course teachers were assessed for the ability to connect the CT practices in their own subjects An evaluation rubric was created to assess whether teachers effectively had used the computational thinking core concepts in their lesson plans In this case the teachers had a programming experience with Scratch and Alice 3) Other courses The options to promote CT without programming courses were game design courses web de- sign courses computer literacy courses and multidisciplinary collaboration classes All these courses are distinguished by purpose content audience and assessed abilities These ap- proaches were not programming courses but they were related to them and they were dependent on computers No course promotes CT without computers C Abilities Problem solving is involved in all papers except for one [18] Therefore problem solving is considered as the core of Approach Instrument or artifact Reference Course Code [17] [18] [19] [20] [21] [23] Responses [14] [16] Lesson plan [13] Survey [22] Multiple-choice questionnaire (PISA) [37] Survey and open-ended questionnaire [12] Survey and multiple-choice questionnaire [11] Framework Code (Scratch) [31] Code (Scratch) interviews and design scenarios [32] Code (Robotic) video and responses [33] Code and questionnaire [34] Game [30] Test Multiple-choice [24] [25] [26] [27] [28] Responses [26] [28] [29] Tool Survey (game) [15] Questionnaire response game (platform) [36] Responses (digital ink) [35] V DISCUSSION This section discusses the data presented in Section IV regarding the concept of CT pedagogical approaches assessed abilities instruments and artifacts Finally the threats to validity are presented A The concept of Computational Thinking The concept of CT can influence the abilities assessment Once understanding the concept of CT the abilities can be elicited and appropriate instruments can be selected to assess theses abilities The definitions found in literature are broad making it difficult to find a systematic classification In addition some studies propose new definitions instead of an- alyzing existing ones Other studies propose activities without exposing their vision about CT Thus a large interpretation on CT is seen in the selected studies Regarding theoretical references most studies refer to Wing’s seminal papers Only 5 from 27 studies do not refer to Wing’s precursors papers These studies were published in 2014 and 2015 Although Wing’s seminal papers have strong influence on literature more recent studies are proposing new terms and abilities B Pedagogical approaches 1) Programming courses Programming courses are the most common intervention to promote CT Visual program- ming environments are broadly employed such as Scratch App Inventor Alice and AgentClub [11] [31] [20] [23] [18] [20] [17] [19] Although these environments are attractive they seem to be limited to solve programming problems make digital storytelling and game design In spite of that they are feasible to introduce students to software programming because of the visual programming language This technical feature allows students to learn programming concepts and Computational Thinking In addition other abilities collabo- rate to solve problems In the mapping study two papers treat troubleshooting instead of problem solving [19] [37] In these papers troubleshooting can be seen in the most common types of problem solving which usually possess a single fault state have known solutions rely most efficiently on experience- based rules for diagnosing and require learners to make judgments about the nature of the problem Considering this definition troubleshooting can fit into a context of CT Algorithm is directly related to 20 studies and indirectly to 3 (from 27) in this mapping study Thereby algorithmic thinking has been pointed out as one of the most fundamental abilities related to solving problems Designing an algorithm is a way of producing a solution through a set of steps Defining and following those steps help us to achieve a solution to a problem For this reason algorithmic thinking can be considered essential in CT Wing in her seminal paper argued that the essence of CT is abstraction [38] For the author an algorithm can be seen as abstraction of a step-by-step procedure for taking input and producing some desired output Moreover thinking abstractly involves identifying the heart of the problem and visualize different levels of details to help to solve it Abstraction also helps to simplify complex problems and decomposes complex tasks Abstraction is related with algorithm and problem- solving Therefore abstraction can be considered essential in CT as well Computer Science Teachers Association (CSTA) points out the following set of nine CT abilities to K-12 students data collection data analysis data representation problem decomposition abstraction algorithms and procedures au- tomation parallelization and simulation [39] These abilities are explored in [13] CSTA argues the role of CT in K-12 is “a problem solving methodology that can be automated transferred and applied across subjects” [39] CSTA also designed the CT Teacher Resources and the CT leadership toolkit to help teachers to apply CT in their classes So these nine CT abilities can be appropriate to K-12 education The CSTA’s study already highlighted that CT is not an alternative to learn programming but CT can be incited through programming Some papers considered conditional loop procedures parameters functions recursion and event as CT abilities Those terms have correlation to programming but the CT abilities in the context of programming needs to be more discussed In another paper Mobile Computational Thinking (MCT) is the term used to refer the programming aspects of CT plus mobile programming aspects designed for MIT App Inventor [18] The rubric of assessment MCT includes screen interfaces events component abstraction data persistence data sharing lists public web services accelerom- eter orientation sensors and location awareness Although those abilities are very specific to mobile programming they are considered part of CT abilities The most wide set of abilities appeared in [26] [30] They elicited (i) processes and transformations (ii) models and abstractions (iii) patterns and algorithms (iv) tools and resources (v) inference and logic (vi) evaluations and im- provements This set of abilities is wide to encompass CT and can involve activities with and without technology for development and assessing of CT D Instruments and artifacts for assessing CT Since programming courses were the most common ap- proaches to promote CT code is already expected as one of the most common artifact for assessing CT abilities In addition four frameworks use code to measure CT The problem in using code to measure development of CT is to limit the assessment to just a checklist ie the presence or absense of some programming structure In accordance to Lye and Koh [10] computational practices and computational perspectives should be included in the context of programming and computational thinking Moreover to measure CT abilities based on code should be more discussed Questionnaires (multiple-choise and open-ended question- naires) also were common instrument for assessing CT Ques- tionnaires such as pre-test and post-test applied before and after courses have advantages and limitations In most of these cases it is not possible to analyze the impact of specific activities offered during the course as highlighted [37] In the context of programming course pre-assessment programming tasks could frustrate students who did not have previous knowledge about programming These students could have a negative impact on their attitudes towards future activities as highlighted [19] Multiple-choice questionnaires were one of the most com- mon type of questionnaire Multiple-choice questionnaires have the advantage of being quicker to reproduce and compile the results These questionnaires are simpler to summarize for statistical analysis The challenge is to elaborate an appropriate test in order to measure cognitive processes Some studies elaborate its own questionnaires Other studies use a known test to measure students’ problem-solving skills as PISA (Program for International Student Assessment) [37] On the other hand responses to exercises also were used for assessing CT abilities Responses to exercises have the possi- bility to understand the specific role of individual activities and their impact on students’ skills [35] Content analysis allows us to make inferences about the reasoning that student appear to have been using and gain further insight into students thought processes Moreover content analysis can identify the students’ mistakes when they do some exercises during a course or an experiment as in [14] Besides it can help to understand the range of errors and identify potential patterns for further investigations and propose a solution for it Test is the traditional instrument for assessment However the concern is about the planning and content of this instru- ment The teacher can underestimated the difficulty of the test or plan their test based on previous experience not considering appropriate pedagogical foundations for the audience In the context of CT there is not consolidated test to apply for measuring CT However this is already expected once the concept of CT and essential abilities are not well defined in literature Considering tools this mapping study identified three re- sults one game one digital ink and one platform [15] [35] [36] The game was not tested in a real environment The digital ink has been undergoing validation process to verify its adequacy as an assessment tool for CT The platform is a prototype with the purpose of collaboratively assess students by exercises (multiple-choice and open-ended questionnaires game puzzle) So all of them need to be tested for empirical evidences of how the students react and how they could be assessed in practice The use of games can be a strategic pedagogical approach to foster CT Educational games have the benefits to provide fun and help students to learn about subjects or assist them in learning a certain skill while they play Games can be designed to assess abilities that teacher would like to train and measure as [15] Tools can be projected in order to capture more informa- tion about students’ performance during the activity Specific digital tools can act as an entry mechanism and store data from each subject This data may be retrieved and processed for future analysis concerning different parameters Such tools can be a way to assess not only the final result but also the development process The digital ink proposed in [35] is an example of this tool Platforms also can be designed to capture more data about the students’ performance Moreover platforms can help teachers with automated assessment and repository of questions/tasks as [36] E Threats to Validity This mapping study has some threats to validity The result may not only be affected by the limitation of the automated search engines of each digital library but also by to human factors during the screening of papers and data extraction steps So the search could not identify all relevant studies or extract all relevant information It was limited to peer-reviewed conference papers and journal articles available This study considers neither book chapters nor short papers VI CONCLUSION AND FUTURE WORKS This research has reinforced in our minds that there is a broad and varied interpretation of CT concepts and conse- quently of the approaches used to promote it While these different interpretations are not irreconcilable they do enforce different views that lead to significantly different assessment approaches However we were able to identify the most commonly used approaches General problem solving in particular is considered in the vast majority of studies (96%) and direct pro- gramming courses are the most popular pedagogical approach used to promote CT for K-12 students (62%) (RQ1) Within programming courses visual programming environments are broadly employed — in particular tools like Scratch and App Inventor are currently at least very popular These pedagog- ical approaches however are rather limited to programming problem solving digital storytelling and game design The study also revealed that a broad range of different CT skills and abilities are promoted by researchers and teachers and as a consequence several artifacts metrics and dimensions are used in assessment The abilities assessed in each artifact varies depending on the researcher’s conceptualization of CT Solving problems developing algorithms and applying abstraction are the most common abilities assessed among the studies identified (RQ2) Coding and multi-choice ques- tionnaires are the leading artifacts for assessing CT abilities (RQ3) While the artifacts are the same the method used to actually assess the code produced as well as the answers to questionnaires may vary according to the pedagogical approach the purpose of the evaluation and finally to the interpretation of the core concepts of CT The subjective nature of the definition of CT concepts skills and abilitites also has a major influence on the set of pedagogical approaches and assessment methods Despite that and confirming our expectations programming courses are the most popular pedagogical approaches However this seems to be a consequence of the fact that most studies are either performed by computer scientists or within the context of promoting Computer Science itself There are however different approaches that are not based on programming In fact such alternatives are justified and desirable Since Wing’s seminal paper most researchers accept that CT is about “conceptualizing not programming” Thus finding ways to promote CT without the need to explicitly depend on teaching computer programming be it within visual frameworks or not is an important contribution to help promote CT more effectively Unfortunately we still need to further propose and investigate alternatives The broad definition of CT also collaborates to actively encourage it to different audiences kindergarten K-12 under- graduate students and teachers This introduces further chal- lenges with respect to assessment For each audience different pedagogical approaches artifacts and assessing methods are necessary In particular a major concern is that teachers have to master both the pedagogical approach as well as methods to assess the development of their students Finally we must comment on the methodological aspects of the papers considered in this study Perhaps because the subject is difficult and complex most studies presented simply cannot be replicated Either because there is no clear presentation of the conditions under which the study occurs or because there is no precise characterization of the methods used to assess and evaluate the results We know these studies are difficult and perhaps impossible to make them fully replica- ble but we believe the whole community of researchers could benefit from a more careful description of the study design procedures and assessment methods as well as the general conditions necessary to conduct a similar study We believe that the CT research area needs to improve on the research methods adopted to better support claims on the relevance and effectiveness of CT REFERENCES [1] J M Wing “Computational thinking” Communications of the ACM vol 49 no 3 pp 33–35 2006 [2] CHu“Computationalthinkingwhatitmightmeanandwhatwemight do about it” in Proceedings of the 16th annual joint conference on Innovation and technology in computer science education ACM 2011 pp 223–227 [3] C Selby and J Woollard “Computational thinking the developing definition” 2013 [Accessed January 20 2016] [Online] Available http//eprintssotonacuk/356481/ [4] S Grover and R Pea “Computational thinking in k–12 a review of the state of the field” Educational Researcher vol 42 no 1 pp 38–43 2013 [5] J Voogt P Fisser J Good P Mishra and A Yadav “Computational thinking in compulsory education Towards an agenda for research and practice” Education and Information Technologies vol 20 no 4 pp 715–728 2015 [6] N R Council Report of a Workshop on the Pedagogical Aspects of Computational Thinking Washington DC The National Academies Press 2011 [Accessed January 15 2016] [Online] Available http//wwwnapedu/catalog/13170/report-of-a-workshop-on- the-pedagogical-aspects-of-computational-thinking [7] K Petersen R Feldt S Mujtaba and M Mattsson “Systematic map- ping studies in software engineering” in 12th international conference on evaluation and assessment in software engineering vol 17 no 1 sn 2008 pp 1–10 [8] TBarcelosRMun ̃ozRVAcevedoandIFSilveira“Relac ̧o ̃esentre o pensamento computacional e a matema ́tica uma revisa ̃o sistema ́tica da literatura” in Anais dos Workshops do Congresso Brasileiro de Informa ́tica na Educac ̧a ̃o vol 4 no 1 2015 p 1369 [9] J Bombasar A Raabe E M de Miranda and R Santiago “Ferramen- tas para o ensino-aprendizagem do pensamento computacional onde esta ́ alan turing?” in Anais do Simpo ́sio Brasileiro de Informa ́tica na Educac ̧a ̃o vol 26 no 1 2015 p 81 [10] S Y Lye and J H L Koh “Review on teaching and learning of computational thinking through programming What is next for k-12?” Computers in Human Behavior vol 41 pp 51–61 2014 [11] S Grover S Cooper and R Pea “Assessing computational learning in k-12” in Proceedings of the 2014 Conference on Innovation ; Technology in Computer Science Education ser ITiCSE ’14 New York NY USA ACM 2014 pp 57–62 [12] A Yadav C Mayfield N Zhou S Hambrusch and J T Korb “Compu- tational thinking in elementary and secondary teacher education” ACM Transactions on Computing Education (TOCE) vol 14 no 1 p 5 2014 [13] H Bort and D Brylow “Cs4impact measuring computational thinking concepts present in cs4hs participant lesson plans” in Proceeding of the 44th ACM technical symposium on Computer science education ACM 2013 pp 427–432 [14] C S Miller L Perkovic ́ and A Settle “File references trees and com- putational thinking” in Proceedings of the fifteenth annual conference on Innovation and technology in computer science education ACM 2010 pp 132–136 [15] C Kazimoglu M Kiernan L Bacon and L MacKinnon “Learning programming at the computational thinking level via digital game-play” Procedia Computer Science vol 9 pp 522–531 2012 [16] K-C Yeh Y Xie and F Ke “Teaching computational thinking to non-computing majors using spreadsheet functions” in Frontiers in Education Conference (FIE) 2011 IEEE 2011 pp F3J–1 [17] L Werner J Denner S Campe and D C Kawamoto “The fairy performance assessment measuring computational thinking in middle school” in Proceedings of the 43rd ACM technical symposium on Computer Science Education ACM 2012 pp 215–220 [18] M Sherman and F Martin “The assessment of mobile computational thinking” Journal of Computing Sciences in Colleges vol 30 no 6 pp 53–59 2015 [19] DCWebb“Troubleshootingassessmentanauthenticproblemsolving activity for it education” Procedia-Social and Behavioral Sciences vol 9 pp 903–907 2010 [20] D Giordano and F Maiorana “Use of cutting edge educational tools for an initial programming course” in Global Engineering Education Conference (EDUCON) 2014 IEEE IEEE 2014 pp 556–563 [21] L Seiter “Using solo to classify the programming responses of primary grade students” in Proceedings of the 46th ACM Technical Symposium on Computer Science Education ACM 2015 pp 540–545 [22] S M Pulimood K Pearson and D C Bates “A study on the impact of multidisciplinary collaboration on computational thinking” in Proceedings of the 47th ACM Technical Symposium on Computing Science Education ACM 2016 pp 30–35 [23] C Duncan and T Bell “A pilot computer science and programming course for primary school students” in Proceedings of the Workshop in Primary and Secondary Computing Education ACM 2015 pp 39–48 [24] I Zur-Bargury B Paˆrv and D Lanzberg “A nationwide exam as a tool for improving a new curriculum” in Proceedings of the 18th ACM Conference on Innovation and Technology in Computer Science EducationserITiCSE’13 NewYorkNYUSAACM2013pp267– 272 [Online] Available http//doiacmorg/101145/24624762462479 [25] S Jun S Han H Kim and W Lee “Assessing the computational literacy of elementary students on a national level in korea” Educational Assessment Evaluation and Accountability vol 26 no 4 pp 319–332 2014 [26] L Gouws K Bradshaw and P Wentworth “First year student perfor- mance in a test for computational thinking” in Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference ACM 2013 pp 271–277 [27] P Hubwieser and A Muhling “Investigating the psychometric structure of bebras contest Towards mesuring computational thinking skills” in Learning and Teaching in Computing and Engineering (LaTiCE) 2015 International Conference on IEEE 2015 pp 62–69 [28] M Csernoch P Biro ́ J Ma ́th and K Abari “Testing algorithmic skills in traditional and non-traditional programming environments” Informatics in Education vol 14 no 2 pp 175–197 2015 [29] JAJoinesDRaubenheimerandACraig“Usingcomputationaltools to enhance problem solving” Computers in Education Journal vol 20 no 4 pp 101–112 2010 [30] L A Gouws K Bradshaw and P Wentworth “Computational thinking in educational activities an evaluation of the educational game light- bot” in Proceedings of the 18th ACM conference on Innovation and technology in computer science education ACM 2013 pp 10–15 [31] L Seiter and B Foreman “Modeling the learning progressions of computational thinking of primary grade students” in Proceedings of the ninth annual international ACM conference on International computing education research ACM 2013 pp 59–66 [32] K Brennan and M Resnick “New frameworks for studying and assessing the development of computational thinking” in Proceedings of the 2012 annual meeting of the American Educational Research Association Vancouver Canada 2012 [33] M U Bers “The tangiblek robotics program Applied computational thinking for young children” Early Childhood Research & Practice vol 12 no 2 p n2 2010 [34] B Zhong Q Wang J Chen and Y Li “An exploration of three- dimensional integrated assessment for computational thinking” Journal of Educational Computing Research p 0735633115608444 2015 [35] A P Ambrosio C Xavier and F Georges “Digital ink for cognitive assessment of computational thinking” in Frontiers in Education Con- ference (FIE) 2014 IEEE IEEE 2014 pp 1–7 [36] D Giordano F Maiorana A P Csizmadia S Marsden C Riedesel S Mishra and L Vinikiene ̇ “New horizons in the assessment of com- puter science at school and beyond Leveraging on the viva platform” in Proceedings of the 2015 ITiCSE on Working Group Reports ACM 2015 pp 117–147 [37] M Akcaoglu “Learning problem-solving through making games at the game design and learning summer program” Educational Technology Research and Development vol 62 no 5 pp 583–600 2014 [38] J M Wing “Computational thinking and thinking about computing” Philosophical Transactions of the Royal Society of London A Math- ematical Physical and Engineering Sciences vol 366 no 1881 pp 3717–3725 2008 [39] V Barr and C Stephenson “Bringing computational thinking to k-12 what is involved and what is the role of the computer science education community?” Acm Inroads vol 2 no 1 pp 48–54 2011 
Computational thinking builds on the power and limits of computing processes whether they are executed by a human or by a machine Computational methods and models give us the courage to solve problems and design systems that no one of us would be capable of tackling alone Computational thinking confronts the riddle of machine intelligence What can humans do better than computers? and What can computers do better than humans? Most fundamentally it addresses the question What is computable? Today we know only parts of the answers to such questions Computational thinking is a fundamental skill for everyone not just for computer scientists To reading writing and arithmetic we should add computational thinking to every child's analytical ability Just as the printing press facilitated the spread of the three Rs what is appropriately incestuous about this vision is that computing and computers facilitate the spread of computational thinking Computational thinking involves solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science Computational thinking includes a range of mental tools that reflect the breadth of the field of computer science Having to solve a particular problem we might ask How difficult is it to solve? and What's the best way to solve it? Computer science rests on solid theoretical underpinnings to answer such questions precisely Stating the difficulty of a problem accounts for the underlying power of the machinethe computing device that will run the solution We must consider the machine's instruction set its resource constraints and its operating environment In solving a problem efficiently we might further ask whether an approximate solution is good enough whether we can use randomization to our advantage and whether false positives or false negatives are allowed Computational thinking is reformulating a seemingly difficult problem into one we know how to solve perhaps by reduction embedding transformation or simulation Computational thinking is thinking recursively It is parallel processing It is interpreting code as data and data as code It is type checking as the generalization of dimensional analysis It is recognizing both the virtues and the dangers of aliasing or giving someone or something more than one name It is recognizing both the cost and power of indirect addressing and procedure call It is judging a program not just for correctness and efficiency but for aesthetics and a system's design for simplicity and elegance Computational thinking is using abstraction and decomposition when attacking a large complex task or designing a large complex system It is separation of concerns It is choosing an appropriate representation for a problem or modeling the relevant aspects of a problem to make it tractable It is using invariants to describe a system's behavior succinctly and declaratively It is having the confidence we can safely use modify and influence a large complex system without understanding its every detail It is modularizing something in anticipation of multiple users or prefetching and caching in anticipation of future use Computational thinking is thinking in terms of prevention protection and recovery from worst-case scenarios through redundancy damage containment and error correction It is calling gridlock deadlock and contracts interfaces It is learning to avoid race conditions when synchronizing meetings with one another Computational thinking is using heuristic reasoning to discover a solution It is planning learning and scheduling in the presence of uncertainty It is search search and more search resulting in a list of Web pages a strategy for winning a game or a counterexample Computational thinking is using massive amounts of data to speed up computation It is making trade-offs between time and space and between processing power and storage capacity Thinking like a computer scientist means more than being able to program a computer It requires thinking at multiple levels of abstraction Consider these everyday examples When your daughter goes to school in the morning she puts in her backpack the things she needs for the day; that's prefetching and caching When your son loses his mittens you suggest he retrace his steps; that's backtracking At what point do you stop renting skis and buy yourself a pair?; that's online algorithms Which line do you stand in at the supermarket?; that's performance modeling for multi-server systems Why does your telephone still work during a power outage?; that's independence of failure and redundancy in design How do Completely Automated Public Turing Test(s) to Tell Computers and Humans Apart or CAPTCHAs authenticate humans?; that's exploiting the difficulty of solving hard AI problems to foil computing agents Computational thinking will have become ingrained in everyone's lives when words like algorithm and precondition are part of everyone's vocabulary; when nondeterminism and garbage collection take on the meanings used by computer scientists; and when trees are drawn upside down We have witnessed the influence of computational thinking on other disciplines For example machine learning has transformed statistics Statistical learning is being used for problems on a scale in terms of both data size and dimension unimaginable only a few years ago Statistics departments in all kinds of organizations are hiring computer scientists Schools of computer science are embracing existing or starting up new statistics departments Computer scientists' recent interest in biology is driven by their belief that biologists can benefit from computational thinking Computer science's contribution to biology goes beyond the ability to search through vast amounts of sequence data looking for patterns The hope is that data structures and algorithmsour computational abstractions and methodscan represent the structure of proteins in ways that elucidate their function Computational biology is changing the way biologists think Similarly computational game theory is changing the way economists think; nanocomputing the way chemists think; and quantum computing the way physicists think This kind of thinking will be part of the skill set of not only other scientists but of everyone else Ubiquitous computing is to today as computational thinking is to tomorrow Ubiquitous computing was yesterday's dream that became today's reality; computational thinking is tomorrow's reality back to top What It Is and Isn't Computer science is the study of computationwhat can be computed and how to compute it Computational thinking thus has the following characteristics Conceptualizing not programming Computer science is not computer programming Thinking like a computer scientist means more than being able to program a computer It requires thinking at multiple levels of abstraction; Fundamental not rote skill A fundamental skill is something every human being must know to function in modern society Rote means a mechanical routine Ironically not until computer science solves the AI Grand Challenge of making computers think like humans will thinking be rote; A way that humans not computers think Computational thinking is a way humans solve problems; it is not trying to get humans to think like computers Computers are dull and boring; humans are clever and imaginative We humans make computers exciting Equipped with computing devices we use our cleverness to tackle problems we would not dare take on before the age of computing and build systems with functionality limited only by our imaginations; Complements and combines mathematical and engineering thinking Computer science inherently draws on mathematical thinking given that like all sciences its formal foundations rest on mathematics Computer science inherently draws on engineering thinking given that we build systems that interact with the real world The constraints of the underlying computing device force computer scientists to think computationally not just mathematically Being free to build virtual worlds enables us to engineer systems beyond the physical world; Ideas not artifacts It's not just the software and hardware artifacts we produce that will be physically present everywhere and touch our lives all the time it will be the computational concepts we use to approach and solve problems manage our daily lives and communicate and interact with other people; and For everyone everywhere Computational thinking will be a reality when it is so integral to human endeavors it disappears as an explicit philosophy Many people equate computer science with computer programming Some parents see only a narrow range of job opportunities for their children who major in computer science Many people think the fundamental research in computer science is done and that only the engineering remains Computational thinking is a grand vision to guide computer science educators researchers and practitioners as we act to change society's image of the field We especially need to reach the pre-college audience including teachers parents and students sending them two main messages Intellectually challenging and engaging scientific problems remain to be understood and solved The problem domain and solution domain are limited only by our own curiosity and creativity; and One can major in computer science and do anything One can major in English or mathematics and go on to a multitude of different careers Ditto computer science One can major in computer science and go on to a career in medicine law business politics any type of science or engineering and even the arts Professors of computer science should teach a course called Ways to Think Like a Computer Scientist to college freshmen making it available to non-majors not just to computer science majors We should expose pre-college students to computational methods and models Rather than bemoan the decline of interest in computer science or the decline in funding for research in computer science we should look to inspire the public's interest in the intellectual adventure of the field We'll thus spread the joy awe and power of computer science aiming to make computational thinking commonplace 
1 Introduction This work presents and discusses a specific didactic approach to support the development of students’ computational thinking (CT) skills in educational robotics (ER) activities As Wing [1] argues computational thinking (CT) is a fundamental skill for everyone and it should be considered as an important component of every child’s analytical ability along with reading writing and arithmetic Recently there has been growing recognition of the importance of CT in controlling and managing cognitive activities as well as understanding and solving problems in a wide range of contexts not only in the field of computer science but in all disciplines [2] ∗ Corresponding author Tel +30 6977718143 E-mail addresses atmatzid@csdauthgr (S Atmatzidou) sdemetri@csdauthgr (S Demetriadis) Robotics can be used as a tool that offers opportunities for students to engage and develop computational thinking skills [34] Educational robotics is being introduced in many schools as an innovative learning environment enhancing and building higher order thinking skills and abilities and helping students solve complex problems [5] Furthermore a guided instruction approach using robots facilitates teamwork develops conceptual understanding enhances critical thinking and promotes higher-order learning in the domains of mathematics and science [6] This paper describes the implementation of ER activity in secondary school focusing on the different possible impacts that the instructional approach might have on the development of students’ CT skills depending on their age and gender Guided by worksheets students worked in small groups to solve robot programming problems The level of their CT skills was evaluated at different times during the activity with focus on five key CT constructs—abstraction generalisation algorithm modularity and decomposition http//dxdoiorg/101016/jrobot201510008 0921-8890/© 2015 Elsevier BV All rights reserved 662 S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 2 Background Robotics is usually seen as an interdisciplinary activity drawing mostly in Science Mathematics Informatics and Technology and offering major new benefits to education in general at all levels [78] Educational robotics is a powerful flexible teaching and learning tool encouraging students to construct and control robots using specific programming languages [7] The roots of ER are to be found in Seymour Papert’s work creator of the Logo programming language [9] Papert suggests that learning is most effective when students are experiencing and discovering things for themselves He also argues that robotics activities have tremendous potential to improve classroom teaching [910] Drawing on the theoretical underpinnings of Papert’s constructionism and Vygotsky’s sociocognitive approaches ER activities help students transform themselves from passive to active learners constructing new knowledge by collaborating with their peers and developing essential mental skills by acting as researchers Many studies indicate that ER activities have a positive impact on the development of students’ critical thinking problem solving and metacognitive skills [51112] and also on the learning of a programming language [71314] Other studies demonstrate how ER promotes a joyful mode of learning while advancing students’ motivation collaboration self-confidence and creativity [15–17] Many researchers argue that robotics programs provide a valuable avenue to increase students’ interest and participation in science technology engineering and mathematics (STEM) while they motivate them to pursue a career in one of these fields (eg [18–20]) However certain researchers point out that although robotics seems to be an excellent tool for teaching and learning and a compelling topic for students of all ages the pedagogy of teaching with robotics is still in its infancy [721] It is also noted that more research is needed to point out how to work with educational robotics to help students develop specific skills [1022] As this study focuses on ER as a means for advancing students’ CT skills we concisely review next the CT theoretical framework and studies on the ER-CT relationship Wing [1] describes CT as a type of analytical thinking that draws on concepts fundamental to computer science and provides a way for solving problems designing systems and understanding human behaviour CT roots go back to Papert’s ideas of the computer being the children’s machine that would allow them to develop procedural thinking through programming and refers to ways of algorithmically solving problems and to the acquisition of technological fluency [9] In the literature there are multiple definitions of CT and several suggestions about which skills and abilities are relevant to CT and how to integrate CT in the curricula of all grades Wing [2] asserts that CT has the potential to advance the students’ problemsolving skills through processes such as abstraction generalisation decomposition algorithm design and separation of concerns Astrachan et al [23] emphasise skills such as developing computational artefacts abstracting analysing problems and artefacts and communicating and working effectively in teams Still others argue that the key concepts of CT are abstraction automation simulation evaluation algorithm building conditional logic debugging decomposition problem analysis distributed computing and effective teamwork [24–26] Emphasis is also given to the view that the educational benefits of CT transfer to any domain – not only in the field of computer science – by enhancing and reinforcing intellectual skills [127] Yadav [28] argues emphatically that ‘CT in education has the potential to significantly advance the problem-solving skills of K-12 students’ Naturally researchers have started exploring also the potential of educational robotics to promote the development of CT [429–31] Certain studies emphasise that children who program robots learn and apply core CT concepts such as abstraction automation analysis decomposition modularisation and iterative design [42930] A 2011 study by National Science Foundation [4] provided evidence that student programmers in a robotics project developed abstraction automation and analysis related skills while programming the robot agent to interact with its environment However it is worth mentioning according to researchers that the field requires systematic assessment procedures Research engaging younger children reported also positive outcomes demonstrating that children 4–6 years old can build simple robotics projects becoming acquainted with powerful ideas of engineering technology and computer programming while also building CT skills [303233] More specifically a study with 53 kindergarten children [33] using Lego WeDo robots and the CHERP (Creative Hybrid Environment for Robotics Programming) language reported that the children were involved and understood basic programming and CT concepts relevant to sequencing and choosing the correct instructions A similar study by Kazakoff et al with 27 kindergarten children focusing solely on sequencing showed improvement of the students’ scores from the first activity to the last [29] Regarding elder children (Junior and High School students) studies report also positive results on the development of CT skills Grover [27] developed a curriculum for teaching CT Language and CT principles in schools The results indicated that students after the intervention were capable of using certain CT related vocabulary and principles (such as conditional logic and decomposition) whereas other concepts like abstraction representation and algorithmic flow control were seldom used Another study by Touretzky et al [34] engaging children aged 10–17 (some of them with special abilities) focused on abstraction across different programming environments and especially on deep and abstract understanding of programming concepts The researchers concluded that – despite the limitations – robotics is a helpful tool for young students ‘‘facilitating a more abstract understanding’’ Penmetcha [35] investigated the effects of ER activity on university students exploring the relationship between robotics and developing programming and algorithmic thinking The results showed that robotics fulfil their purpose as a medium for incorporating CT practices regardless of the students’ background and can be used to teach concepts such as designing programming and testing at a more abstract level As in the other studies limitations were reported relevant to the study small sample size [27] Finally a case study by Eguchi [36] explores the effects of a robotics competition on students’ CT and problem solving skills reporting an overall very positive effect Overall although the CT concept has attracted considerable attention the literature on implementing CT in a K-12 setting is still relatively sparse [28] There is also lack of empirical evidence in defining the explicit CT boundaries [37] although recent articles begin to describe what it looks like [4303839] More than that research into how CT can be introduced in the classroom is on the early stages and there is shortage of description about how children can learn and develop CT skills [272837] Another issue is to understand at what age – or grade level – children are ready to be familiar with advanced concepts such as abstraction automation decomposition etc and how to teach those skills progressively [4] Likewise there is little agreement on strategies for assessing the development of CT in young people [23384041] Existing studies typically employ a student group of specific age thus limiting the generalisation of the results to other age groups (eg [82933]) have small sample sizes (eg [27293435]) and do not provide explicit teacher guidance on how to organise a well-guided ER activity to promote students’ CT skills Researchers also differ in the way they build an operational CT skills framework to apply to their studies Table 1 presents the various CT skill models employed in various ER studies Another issue of interest is the gender differences observed in studies on STEM learning activities Much research has S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 663 Table 1 CT skills models employed in various ER studies Article Context CT skills model Lee et al [4] K-12 Abstraction Automation and Analysis Grover [27] 10 students mean age 13 Computational Thinking Language (CTL) [42] Abstraction Taskbreakdown Conditional logic Representation Algorithm and Debugging Penmetcha [35] 26 university students Abstraction Algorithm Programming and Designing Bers et al [33] 53 kindergarten students Sequencing Kazakoff et al [29] 27 kindergarten students Sequencing Touretzky et al [34] 31 students aged 10–17 Abstraction between three software frameworks (Kodu Alice Lego NXT) Recognise fundamental programming concepts Bers et al [33] 53 kindergarten students Debugging Correspondence Sequencing and Control flow Eguchi [36] 168 students aged 10–19 Problem Solving Debugging Prototyping Decomposition Logical thinking Creating step-by-step procedure Analysing Skills Critical Thinking Iteration and Debugging documented gender differences showing that men have higher levels of self-efficacy and higher probability of success in STEMrelated fields (eg [4344]) However over the past few decades the gender gap has narrowed The stereotypic gender role might have a clear impact on attitudes about technology but this can be positively changed under the right conditions [4546] Studies indicate that both genders can have a successful and rewarding experience being exposed to robotics activities Milto et al [47] found that although men were more confident in their abilities than women in an introductory engineering class women and men displayed equivalent competency in robotics activities Similarly Nourbakhsh et al [48] investigated the gender differences in a robotics course involving high school students According to the study although girls entered the course with less confidence than boys and were more likely to have struggled with programming by the end of the course girls’ confidence increased more than boys’ Another study by Cheng [49] reported that in terms of assembling and programming Lego robots while there were slightly higher average scores for male students it was not of significant difference However research on comparing the development of CT skills between genders in K-12 robotics activities is relatively sparse While research has been conducted on gender differences in many science and mathematics areas [50] limited research has been carried out into gender differences in robotics and programming achievement especially in early childhood [51] Research motivation and key research question Considering the above background the current study aimed to conduct an instructional well-guided ER activity recruit a relatively large student sample size and explore the impact of the activity on students’ CT skills comparing student groups of different age and gender Thus the overarching research question set by the study is ‘‘Are students of different age and gender developing CT skills in the same way in the context of educational robotics activity?’’ 3 Method 31 Participants For the purpose of our study we conducted a series of robotic training seminars in public schools in the area of Thessaloniki In total 164 students of two different school levels (Junior high and High vocational) participated in the study Specifically in the seminars were engaged • Junior high (J) 89 K-9 students (age 15 48 boys and 41 girls) • High vocational (H) 75 K-12 students (age 18 64 boys and 11 girls) 32 A model for CT skills To operationalise the CT theoretical approach we focused on five core dimensions of the broader CT conceptual framework These included abstraction generalisation algorithm modularity and decomposition The proposed model encompasses skills that can easily emerge when students engage in educational robotics activities In detail the proposed model for CT skills presented in Table 2 33 Implementation procedure In total we conducted 8 training robotics seminars (4 at Junior high and 4 at High vocational schools’) during the 2012–2013 school year The Lego Mindstorms NXT 20 educational robotics kit was used in all seminars Organised and supervised by the main researchers (authors of this work) each seminar comprised 11 sessions (2 h each conducted once a week) Trained postgraduate students (‘‘trainers’’) assisted with the practicalities of the activity (eg organising student groups handling out worksheets encouraging and scaffolding teams administering questionnaires etc) The seminars were conducted during the typical school time schedule and the class teachers remained in the classroom during the activity simply helping to maintain the flow of each lesson In detail the sessions were as follows 1st session In the beginning the teacher introduced robotics in general the Lego Mindstorms NXT robot and the Lego NXTG programming environment Then she handed out the Profile Questionnaire (PQ) to be filled in individually by students Working in groups the students implemented their first program using their own robot kit Emphasis was placed on the concept of algorithm and the importance of developing precise instructions that when implemented they lead to the solution of the problems 2nd session The objective here was students’ familiarisation with some basic programming concepts (sequential structure and loop structure) The students also became familiar with the motors the touch sensor the sound sensor and finally with some basic feature of NXT such us displaying images on the screen of the robot In this session students programmed their robots to dance and presented them to the other groups The session placed focus on the abstraction and generalisation concepts Participants were prompted to reflect on the role of these two concepts in their own problem solving activities 3rd and 4th sessions The students worked on the control structure and on how to use the ultrasonic sensor and the wait block They also practised conversion of numbers to text in order to show a numerical value on the screen In the last activity of the 4th session the challenge was to create a robotic alarm system that detects motion and sound At the end of the fourth session we administered the first questionnaire (Q1) in order to assess the students’ level of CT skills development In 3rd session the focus here was on modularity and decomposition and their importance in optimising the structure of an algorithm implementation From the 4th session onwards the activities challenged the students to engage in practising all the concepts of the CT model and develop relevant skills 5th and 6th sessions The students became familiar with the operation of light sensor the creation of reusable subprograms 664 S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 Table 2 The CT skills model applied in the current study CT skills Description Student skills (The student should be able to   ) Abstraction Abstraction is the process of creating something simple from something complicated by leaving out the irrelevant details finding the relevant patterns and separating ideas from tangible details [52] Wing [2] argues that the essence of CT is abstraction 1 Separate the important from the redundant information 2 Analyse and specify common behaviours or programming structures between different scripts 3 Identify abstractions between different programming environments Generalisation Generalisation is transferring a problem-solving process to a wide variety of problems [38] Expand an existing solution in a given problem to cover more possibilities/cases Algorithm Algorithm is a practice of writing step-by-step specific and explicit instructions for carrying out a process Kazimoglu et al [37] argue that selection of appropriate algorithmic techniques is a crucial part of CT 1 Explicitly state the algorithm steps 2 Identify different effective algorithms for a given problem 3 Find the most efficient algorithm Modularity Modularity is the development of autonomous processes that encapsulate a set of often used commands performing a specific function and might be used in the same or different problems [38] Develop autonomous code sections for use in the same or different problems Decomposition Decomposition is the process of breaking down problems into smaller parts that may be more easily solved Break down a problem into smaller/simpler parts that are easier to manage Wing [2] argues that CT is using decomposition when attacking or designing a large complex task (make a new ‘‘My Block’’) the use of the lamp block and the parallel programming The students programmed a recycler robot where the robot moves following a black line and sorts items to be recycled depending on their colours 7th and 8th sessions The students worked on the concept of variable and basic arithmetic operators In this context the students implemented a security guard robot that moves around a building and detects every motion sound and change in lightness 9th and 10th sessions Students were given activities of increased difficulty to practise their developing CT skills in the context of more complex authentic problems such as a car that moves following the traffic code etc The project allowed children to demonstrate the powerful ideas they learned over the previous sessions as well as to apply them and continue learning by solving a new problem A second questionnaire (Q2) was administered at the end of this session to assess the students’ current level of CT skills development 11th session In the final session student groups were given the ‘‘final challenge’’ that is a demanding robot programming task for groups to compete against each other The winner was the group that proposed an effective and efficient task solution (optimised code and fastest solution) After the completion of each seminar two other instruments were used to capture the students’ level of CT skills and also their views regarding the ER training experience These were (a) a ‘think-aloud’ protocol implementation (b) a student’s opinion questionnaire Overall the procedure of each training seminar and the various data collection instruments are presented in Fig 1 34 Didactic model In each seminar students worked in groups of three (or four if necessary) and were guided by worksheets in the investigating robot programming tasks of gradually increased complexity These enabled them to start constructing understanding and developing the CT skills prescribed by our model The worksheets also directed students to assume the roles of analyst (analyse the problem) algorithm designer (describe the algorithm) programmer (write the code) or debugger/evaluator (review and assess the solution) The students exchanged roles successively as the activities evolved During the sessions the trainers acted as facilitators to scaffold students while solving programming tasks After the 5th session trainers gradually faded their support This means that detailed guidance was gradually replaced by simple prompts to students to assume the relevant role and practise the acquired skills on their own capacity [5] The trainers were ready to fade-in again and support students should the circumstances require it To trigger students’ reflection and development of CT modelled skills prompts such as the following (see Table 3) were included in the worksheets Peers were expected to spend some time discussing how to answer these prompts; then one peer was assigned the responsibility of writing down the group answer to the worksheet 35 Measures instruments and data analysis The instruments that we used to collect evaluation data (and respective measures) are as follows Profile Questionnaire (PQ) An individual questionnaire was administered in the beginning of each seminar The questionnaire recorded some simple demographic data (eg student gender) the students’ background on computer use (for example frequency of computer use computer experience etc) and experience with robotics (such as previous knowledge on constructing and programming robots) Two intermediate Questionnaires (Q1 and Q2) Q1 was handed out after the 4th and Q2 after the 10th session Both questionnaires asked students to solve programming problems and practise CT skills during their solution process; for example identify common programming structures that guide robot behaviour in two tasks (abstraction) propose a more general solution (generalisation) describe step-by-step the solution process (algorithm) etc The assessment of students’ answers in Q1 and Q2 was based on a graded criterion instrument (rubric) using a 4-point Likert scale (1 = ‘unsatisfactory’ 2 = ‘quite satisfactory’ 3 = ‘satisfactory’ 4 = ‘excellent’) There were specific criteria for each construct of the CT model (abstraction generalisation algorithm modularity decomposition) and so each student was assigned a grade for each CT construct after answering the Q1 and Q2 questionnaires A mean value was also calculated across all CT constructs (in Q1 and Q2 respectively) We consider the Q1 and Q2 measurements as indicators of student’s level of CT skills development at certain phases during the training seminar (Q1 after the 4th session Q2 after the 10th session) In the following we refer to Q1 measurement as ‘‘Students’ starting CT skill level’’ (or simply CT-4) and to Q2 measurement as ‘‘Students’ final CT skill level’’ (or simply CT-10) As CT-4 is a measurement reflecting students’ CT skills early in the training we use it as covariate in our statistical analysis We would like to clarify that although administering a pre-test S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 665 Fig 1 Seminar organisational structure lower row indicates session when CT skills were introduced; arrows indicate sessions when evaluation interventions were conducted Table 3 CT skills and relevant prompts to trigger students’ self-reflection Abstraction What is common in robot behaviour in both programs? How would you describe this common behaviour? What is the common programming structure? Which is the information you actually need? What is irrelevant detail and not necessary in your description? Generalisation Propose a more general solution for the activity above that can cover a wider variety of cases Is the proposed solution more general and why? Algorithm Write step-by-step the operations needed so that the robot can do what the problem asks What are the steps I will need to do to solve this problem? Modularity Are there any parts of the code that you have met before? Have you created your own blocks for these? What are they? Do you expect to need some parts of this particular code in the future or in a different problem? Decomposition Can I break down this complex problem into smaller ones? Can I solve and explain the smaller problems building up a solution towards the complex problem? before any training was feasible we though as a better approach to first provide students with a common programming tool for expressing CT (in our case the Lego Mindstorms programming software) and then collect initial data after few sessions (session 4) We argue that this approach enabled us to (a) help students develop a homogeneous background that led to more reliable measurement of their initial CT level (students can express their CT using the same programming tool) and (b) compare students’ ‘‘short training’’ CT development (session 4) to ‘‘long training’’ CT development (session 10) Student Opinion Questionnaire (SOQ) An opinion questionnaire was handed out to students to be filled individually after the completion of the training The instrument recorded (a) students’ subjective views on understanding CT concepts and developing relevant skills and (b) students’ views and opinions regarding the outcomes of the overall learning experience on four key aspects (1) development of students’ CT skills (2) understanding of basic programming concepts (3) students’ in-group collaboration (benefits and possible drawbacks) and (4) likes and dislikes relevant to the overall activity Think-aloud protocol After the training students individually were given a certain robot programming task and were asked to describe aloud the process they would follow to solve it Simultaneously the researcher prompted students to reflect on CT concepts relevant to their solution The assessment of the student’s proposed solution was based also on the same graded criterion instrument (rubric) as before We consider this grade as an indicator of student’s CT skills when evaluated in a different context than that of the Q1 and Q2 questionnaires The main difference is that the ‘think-aloud’ method allows students to express their thinking more freely as opposed to the highly structured form of the questionnaire instruments In the following we refer to ‘thinkaloud’ measurement as ‘‘Students’ TA CT skill level’’ (or simply CTTA) As before we have 5 individual measures for each CT construct and a mean CT-TA grade calculated across all CT constructs Interview After the think-aloud activity students were asked (as a semi-structured interview) to freely state their opinion on key aspects of the activity (the four aspects described above in the SOQ section) Observation Systematic monitoring of the students’ work was applied by taking notes on a structured form (observation sheets) Both the supervising researcher and trainers filled in the sheets and then extensively discussed their observations to reach consent and decide on their importance So an observation table was gradually developed displaying researchers’ observations in order of their discussed importance 36 Results 361 Statistical analysis Profile questionnaire data revealed that none of the participating students had any previous experience with robotics After the data collection the statistical processing was as follows (a) Table 4 presents statistical controls applied on students’ CT-4 and CT-10 scores in Junior high (J) and High vocational (H) groups (b) Table 5 presents statistical controls applied on students’ CT-4 and CT-10 scores analysed in each of the five dimensions of the CT model (c) Table 6 presents statistical control applied on the students’ CT-TA scores (both total and analytical scores for each of the five CT dimensions) (d) Table 7 presents statistical control applied on students’ CT-4 and CT-10 scores across different gender groups Two gender groups were used Girls and Boys at Junior (J) level The Girls/Boys distribution in the High (H) group was highly uneven and this group was excluded from across gender comparisons (e) Table 8 presents statistical controls applied on students’ CT-4 and CT-10 scores analysed in each one of the five dimensions of our CT model As before (Table 7) data refer to gender groups only within J group (f) Table 9 presents statistical control applied on the students’ CTTA scores across gender (both total and analytical scores for each of the five CT dimensions) 666 S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 Table 4 Comparing CT-10 and CT-4 scores between J and H groups Level N CT-4 CT-10 Paired t-test ANCOVA M (SD) M (SD) CT-10 compared to CT-4 (same student group) comparing CT-10 across student groups (CT-4 as covariate) J 89 296 (051) 308 (059) t(88) = −191 p = 0059 F (1 161) = 0289 H 75 236 (069) 271 (077) t(74) = −669 p = 000 p = 0592 η2 = 002 Total 164 269 (067) 291 (070) t(163) = −527 p = 000  Significant difference at the 005 level Table 5 Comparing CT-10 and CT-4 scores analytically for the five CT dimensions CT skills Level CT-4 CT-10 Paired t-test ANCOVA M (SD) M (SD) Comparing CT-10 across student groups with CT-4 as covariate Abstraction J 250 (081) 252 (087) t(88) = −022 p = 083 F (1 161) = 0014 H 261 (083) 257 (085) t(74) = 059 p = 055 p = 0907 η2 = 000 Generalisation J 257 (081) 270 (081) t(88) = −118 p = 024 F (1 161) = 0189 H 215 (089) 248 (098) t(74) = −279 p = 001 p = 0665 η2 = 001 Algorithm J 308 (074) 298 (064) t(88) = 106 p = 029 F (1 161) = 0446 H 248 (077) 281 (079) t(74) = −519 p = 000 p = 0505 η2 = 003 Modularity J 334 (078) 357 (087) t(88) = −219 p = 003 F (1 161) = 00 H 211 (104) 280 (125) t(74) = −628 p = 000 p = 0998 η2 = 000 Decomposition J 311 (096) 366 (070) t(88) = −558 p = 000 F (1 161) = 11861 H 227 (103) 283 (106) t(74) = −531 p = 000 p = 0001  η 2 = 069  Significant difference at the 005 level Table 6 Comparing CT-TA scores between J and H groups CT skills J H t-test M (SD) M (SD) Abstraction 220 (087) 231 (095) t(162) = −080 p = 042 Generalisation 228 (109) 268 (106) t(162) = −240 p = 002 Algorithm 277 (076) 260 (097) t(140) = 121 p = 023 Modularity 260 (133) 236 (102) t(161) = 131 p = 019 Decomposition 303 (119) 284 (105) t(162) = 106 p = 029 Total CT-TA 262 (069) 260 (075) t(162) = −016 p = 087  Significant difference at the 005 level Table 7 Comparing CT-10 and CT-4 scores between gender groups (J level only) Gender N CT-4 CT-10 Paired t-test ANCOVA M (SD) M (SD) CT-10 compared to CT-4 (same student group) Comparing CT-10 across student groups (CT-4 as covariate) Girl 41 281 (049) 309 (065) t(40) = −343 p = 000 F (1 86) = 1146 Boy 48 302 (054) 308 (051) t(47) = −071 p = 048 p = 0287 η2 = 0013 Total 89 292 (053) 309 (058) t(88) = −268 p = 001  Significant difference at the 005 level 362 Students’ Opinion Questionnaire (SOQ) Data from SOQs and interviews helped us understand students’ opinions regarding the overall activity Key findings can be summarised as follows (i) Students’ subjective impression was that they acquired certain CT skills They reported that they can detect and describe the common behaviours or programming structures used in different tasks (M = 403 SD = 077) and also that they can suggest a more general solution for a given problem (M = 400 SD = 079) (ii) Students reported that the guidelines in the worksheets helped them develop a certain problem-solving process (M = 373 SD = 080) They find this process useful to think of (‘‘it comes to mind’’) when solving problems in other domains as well (M = 358 SD = 081) Some relevant students’ statements are ‘‘Now I think differently and solve problems more easily’’ and ‘‘I changed my way of thinking in problem solving even in other subjects such as mathematics’’ (iii) The students stated that they became familiar with basic programming constructs (M = 416 SD = 068) and that they would like to continue with programming In particular H level students mentioned that they better understood some basic programming concepts they learned in other programming environments such as the control structure (‘‘If   then   else’’) and the loop structure (‘‘For   Next’’ ‘‘Do While   ’’) They also said that working with the robots not only helped them develop a deeper understanding of programming (M = 411 SD = 067) but also kept them in- S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 667 Table 8 Comparing CT-10 and CT-4 scores analytically for the five CT dimensions (J level only) CT skills Gender CT-4 CT-10 Paired t-test ANCOVA M (SD) M (SD) Comparing CT-10 across school levels (CT-4 as covariate) Abstraction Girl 242 (078) 262 (091) t(40) = −156 p = 013 F (1 86) = 1866 Boy 257 (084) 244 (084) t(47) = 088 p = 038 p = 0175 η2 = 0021 Generalisation Girl 243 (070) 266 (092) t(40) = −166 p = 011 F (1 86) = 000 Boy 270 (087) 274 (091) t(47) = −025 p = 080 p = 0989 η2 = 000 Algorithm Girl 301 (071) 299 (065) t(40) = 020 p = 085 F (1 86) = 0037 Boy 315 (077) 297 (065) t(47) = 115 p = 026 p = 0848 η2 = 000 Modularity Girl 318 (079) 354 (094) t(40) = −202 p = 005 F (1 86) = 0073 Boy 348 (076) 360 (082) t(47) = −098 p = 033 p = 0787 η2 = 0001 Decomposition Girl 300 (097) 366 (082) t(40) = −459 p = 000 F (1 86) = 0123 Boy 320 (094) 367 (060) t(47) = −339 p = 000 p = 0727 η2 = 0001  Significant difference at the 005 level Table 9 Statistical analysis comparing CT-TA between gender groups (J level only) CT skills Girls (N = 41) Boys (N = 48) Independent t-test M (SD) M (SD) Abstraction 231 (094) 211 (080) t(87) = 112 p = 027 Generalisation 232 (108) 224 (111) t(87) = 033 p = 074 Algorithm 291 (069) 265 (080) t(87) = 166 p = 010 Modularity 268 (1 33) 253 (134) t(87) = 054 p = 060 Decomposition 312 (1 25) 295 (116) t(87) = 068 p = 050 Total CT-TA 271 (073) 254 (066) t(82) = 114 p = 026 terest and motivated them to keep working on programming (M = 342 SD = 066) (iv) Regarding collaboration the students enjoyed working in groups (‘‘three minds are better than one’’ ‘‘we motivate each other when working together’’) and assuming CT relevant roles (M = 406 SD = 072) with the most popular role being that of the ‘‘Programmer’’ (v) Finally the students found the robotics experience very interesting (M = 438 SD = 063) reporting that they would like to continue practising ER in the future (M = 365 SD = 084) and engage in more challenging tasks Indicative of their interest is the fact that when finishing with the worksheets they explored different programming structures (‘‘blocks’’) – even those they had not learned yet – and different ideas to expand and improve their solutions 37 Discussion and conclusions The current work analysed the development of students’ computational thinking skills in the context of educational robotics with special focus on the impact that the instructional approach may have on student groups of different ages and genders The study provides evidence from evaluation instruments administered at various times during the activity thus offering a picture of how CT skills develop as students’ work progresses Students’ CT skills are also evaluated using different modalities in assessment instruments (questionnaires answered in written and problemsolving think aloud protocols) Finally researchers’ observations and qualitative data from students’ opinion questionnaires help triangulate data and deeper understand their meaning A first observation is that students develop the same level of CT skills at the end of their training independently of age Additionally CT skills in most cases are significantly improved as the training proceeds (comparing CT-4 and CT-10 scores in Tables 4 and 5) This is clear for the total population and for each of the two groups although for the J group appears as a strong tendency (p = 0059) not exactly reaching the level of significance (Table 4 paired t-test and ANCOVA) Thus one key conclusion is that the satisfactory development of CT skills needs a considerable number of training sessions – independently of student’s age – and is not simply a matter of a few training sessions This conclusion is in line with studies emphasising that skill development in general requires adequate amount of training time [3353] Reflecting further on Table 5 we see that significant differences between CT-10 and CT-4 measures are identified in certain cases independently of student’s level (age) (clearly for the Modularity and Decomposition dimensions) while in other cases such differences are evidenced only for the H group (Algorithm and Generalisation dimensions) or not at all (Abstraction) To explain these differences we resort to researchers’ observations regarding the group composition and students’ preference for writing Most students in the H group are boys not so willing to provide answers in written (this is in line with studies suggesting that boys are significantly more reluctant writers than girls for example [54]) By contrast students in the J group are almost equally distributed across gender and adopt a more positive attitude towards expressing themselves in written (compared to boys in H group) Keeping this in mind we explore the implications of data in Table 5 As the development of the Abstraction skill for both groups reaches a high level already in session 4 (not to be surpassed in the next sessions) this is an indication that students from session 4 onwards deal with programming tasks without further development of this skill in a way that is reflected in the measures Also the additional workload of expressing this skill in written does not seem to affect students in the High group However Generalisation and Algorithm skills are further developed (from CT-4 to CT-10) only for the High group (Table 5) This is probably explained by the observation that younger students in the J group are more willing to follow instructions and provide answers in written (so their scores are high already from the 4th session (CT-4)) while students in the H group improve significantly from CT-4 to CT-10 as they gradually familiarise themselves with following the worksheet guidelines and become more willing to provide written documents expressing their thinking These explanations are further supported by the fact that the aforementioned differences are not observed when the modality of the assessment instrument changes (see also comments below regarding Table 6) Finally considering the Modularity and Decomposition dimensions we observe significant differences between CT-10 and CT-4 for both J and H groups Regarding Modularity we believe that the significant improvement of 668 S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 CT-10 score for the J group is mainly due to the improvement of the girls’ CT-10 score in the group (see also Modularity in Table 8 we comment on that further below) Regarding Decomposition we see that both boys and girls in J group improve significantly their CT-10 score (see also Table 8) and this we believe is due to the increase of problem complexity as the training proceeds Increased problem complexity gives the opportunity to students of both groups (J and H) to practise the skill more extensively and this is reflected in their scores Additionally we identify – only for Decomposition – a statistically significant difference between the two groups favouring students in the J group (ANCOVA in Table 5) We suggest that this is another manifestation of the unwillingness of boys in the H group to routinely follow instructions Students in this group do not actually think it is necessary to decompose the problem into smaller ones to solve it However this attitude could also be linked to the cognitive maturity of elder adolescents in group H as compared to the younger adolescents in group J which enables the former to manage more complex programming solutions without decomposing them Moving on to Table 6 (CT-TA scores) we see that when evaluating students’ CT skills orally (Think-Aloud protocol) no betweengroup differences are identified (except for Generalisation favouring the H group) This corroborates our already stated conclusions that (a) development of CT skills happens in the same way for both groups independently of age and (b) CT skills measures might be affected by the workload imposed on students from the recording instrument modality When students are asked to provide written evidence of their skills they might appear to underperform because of poorly following the instructions (as in Decomposition Table 5) However it is not clear why the H group outperforms J in Generalisation (Table 6) One possible explanation is that the oral modality allows the specific profile male students in group H to thoroughly express their more complex thinking required to describe a generalised problem solution Thus we might have here another indication of the interaction between students’ scores and assessment instrument modality which should be seriously considered by researchers in relevant studies In all other dimensions (and also in the total CT skills score) no significant differences are recorded Next we focus on the analysis of scores between gender groups (Tables 7–9) A key conclusion here is that although boys and girls reach the same CT skills level (ANCOVA in Table 7) there is however a significant difference between CT-10 and CT-4 scores for the girls’ subsample indicating that the girls need longer time to reach the same skills level This difference is also reflected on the total population (paired t-tests in Table 7) This outcome is in line with other studies suggesting that girls seem to require more time compared to boys when it comes to skills development (see [55]) Table 8 presents analytically the CT-10 and CT-4 skills scores in the five dimensions for boys and girls The previously discussed pattern (‘‘both genders reach the same skill level but girls need more time’’) appears again for the Abstraction (strong tendency for girls p = 013) Generalisation (strong tendency for girls p = 011) Modularity (significant difference for girls p = 005) but not for the Algorithm or the Decomposition dimensions For the Decomposition we believe the explanation is the same as before; the increased complexity of programming tasks as the training proceeds allow students of both genders to practise decomposition more systematically and this is reflected in their scores Finally some interesting evidence emerges in Table 9 On one hand no significant differences in CT skill scores appear (neither for the total CT-TA score nor for any dimension except for strong tendency in Algorithm favouring girls) The ‘‘no significant’’ outcome is compatible with the overall gender pattern that boys and girls reach finally the same skills level On the other hand however the strong tendency in Algorithm seems to be at odds with what has been discussed so far as the Algorithm relevant skill is the only one developed in the same way by both boys and girls (Table 8) One possible explanation might be that while girls in the J group understand and express the algorithmic dimension of a programming task as efficiently as boys (Table 8) nevertheless when they are additionally given the opportunity to express their algorithmic thinking orally they tend to do that more effectively than boys (Table 9) Anyway we acknowledge that more research is needed to clarify that point By reflecting on researchers’ observations we report the most important of them as follows (a) Despite any initial difficulties in grasping the concept of abstraction students were able to easily identify the common programming concepts when comparing different scenarios This conclusion is in line with quantitative data indicating that Abstraction is easily grasped and practised by students (b) In the beginning the students faced difficulties in understanding the concept of generalisation and suggesting more general solutions However at the end of the training interesting generalisations were observed in students’ solutions Especially students in the H group assimilated the concept more easily and used it in the activities often without any intervention from trainers This corroborates the findings in Table 6 where elder adolescents (the H group) seem to practise Generalisation significantly better when the assessment modality is oral Thus Generalisation appears to be a CT skill which develops better in elders and this is perhaps related to the cognitive developmental level of the H group Certainly more research is needed to further clarify the issue (c) Most students had difficulty in describing the algorithm with clarity and accuracy They preferred to describe a process in general rather than analyse it step by step Perhaps this is due to the cognitive load induced when analytically expressing the algorithm Here again a modality effect is identified (girls tend to orally describe the algorithm better than boys— Table 9) (d) The students encouraged by the trainers practised the skill of modularity in their activities by creating their own programming ‘‘blocks’’ The students in J group familiarised with and integrated the skill more than the students in H group This last observation is in line with quantitative data (Table 5) showing that J group applies Decomposition better We attribute that behaviour mostly to H group students’ unwillingness to follow instructions for decomposing problems being able to manage the code as a whole Overall this study provides evidence that (a) students of different ages (15 vs 18) and genders eventually reach the same level of CT skills development; this view is supported by evidence from assessment instruments using two modalities (b) Time is an essential commodity for CT skills development; skills level evaluated in later session have been found in most cases to be significantly improved when compared to initial session (c) When analysing the particular skills of the CT model certain differences are identified which are related to the following factors age and student cognitive developmental level students’ attitudes relevant to following instructions and afford workload induced by the task and also gender (d) The assessment instrument modality may have an impact on students’ scores as boys are generally more reluctant writers compared to girls When this attitude is intense then boys may appear to underperform if skills evaluation is based on instruments of written modality (e) Girls appear in most cases to need more time (training sessions) in order to reach the same skill level as boys (f) Provided that the overall instructional context is supportive and the learning activity time is adequate students may overcome their initial difficulties and successfully develop their CT skills Understanding the above conclusions should be done while also considering the limitations of the study It is important to remember that educational robotics activities cannot be conducted under full experimental control and many factors might S Atmatzidou S Demetriadis / Robotics and Autonomous Systems 75 (2016) 661–670 669 interact in an unexpected and – relatively – uncontrolled way The current study provides evidence coming from various data collecting methods and with assessment instruments of different modality something that – we believe – increases the validity of the conclusions However it was not possible to include a control group in the design that would allow exploring the issue of whether the CT skills in ER activities develop in the same way compared to a control non-ER instructional condition An additional limitation is the exclusion of the H group from across gender controls due to the highly uneven distribution of girls/boys in the sample This does not permit the current study to simultaneously apply across-age and across-gender controls that could further shed light on the gender relevant differences and reveal any possible interaction between the two factors Finally the study did not administer any pre-intervention controls of students’ ‘‘preference for writing’’ attitude and general ability levels Our experience indicates that such tests could provide valuable information regarding some of the observed gender and group relevant differences Acknowledgements The authors would like to thank all school teachers postgraduate student-trainers and the students involved in the ER seminars for their helpful collaboration and also the journal editor and the manuscript reviewers for their constructive comments 
The current issue and full text archive of this journal is available on Emerald Insight at wwwemeraldinsightcom/2056-4880htm Abstract Artificial intelligence computational thinking and mathematics education Artificial intelligence 133 Received 17 September 2016 Revised 29 October 2016 Accepted 29 November 2016 George Gadanidis Western University London Canada Purpose – The purpose of this paper is to examine the intersection of artificial intelligence (AI) computational thinking (CT) and mathematics education (ME) for young students (K-8) Specifically it focuses on three key elements that are common to AI CT and ME agency modeling of phenomena and abstracting concepts beyond specific instances Design/methodology/approach – The theoretical framework of this paper adopts a sociocultural perspective where knowledge is constructed in interactions with others (Vygotsky 1978) Others also refers to the multiplicity of technologies that surround us including both the digital artefacts of our new media world and the human methods and specialized processes acting in the world Technology is not simply a tool for human intention It is an actor in the cognitive ecology of immersive humans-with-technology environments (Levy 1993 1998) that supports but also disrupts and reorganizes human thinking (Borba and Villarreal 2005) Findings – There is fruitful overlap between AI CT and ME that is of value to consider in mathematics education Originality/value – Seeing ME through the lenses of other disciplines and recognizing that there is a significant overlap of key elements reinforces the importance of agency modeling and abstraction in ME and provides new contexts and tools for incorporating them in classroom practice Keywords Artificial intelligence Mathematics education Computational thinking Paper type Conceptual paper Introduction This paper examines the intersection of artificial intelligence (AI) computational thinking (CT) and mathematics education (ME) for young students (K-8) Specifically it focuses on three key elements that are common to AI CT and ME agency modeling of phenomena and abstracting concepts beyond specific instances (see Figure 1) As is the case with a lot of the author’s work the theoretical framework of this paper adopts a sociocultural perspective where knowledge is constructed in interactions with others (Vygotsky 1978) Others also refers to the multiplicity of technologies that surround us including both the digital artefacts of our new media world and the human methods and specialized processes acting in the world Technology is not simply a tool for human intention It is an actor in the cognitive ecology of immersive humans-with-technology environments (Levy 1993 1998) that supports but also disrupts and reorganizes human thinking (Borba and Villarreal 2005) Actor-network theory (Latour 2005) emphasizes the reciprocal relationship between the “actor” and technology where we are both acting and acted upon (Thumlert et al 2014) In this examination of the overlap of AI CT and ME I identify and explore key elements of CT as actors we (can) think-with in the learning and teaching process The first two sections below introduce AI and CT The third section discusses how agency modeling and abstraction may be seen as three common key elements of AI CT and ME AI AI is the intelligence evident in machines or software It is also the name of the academic field of study which studies how to create computers and computer software that are capable of intelligent behavior Major AI researchers and textbooks The International Journal of Information and Learning Technology Vol 34 No 2 2017 pp 133-139 © Emerald Publishing Limited 2056-4880 DOI 101108/IJILT-09-2016-0048 IJILT 342 134 define this field as “the study and design of intelligent agents” in which an intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success (“Artificial Intelligence” nd para 1) Today AI is increasingly pursued in a variety of ways by industry such as seen in the development of self-driving cars by Google and cognitive systems like Watson by IBM AI singularity Some experts estimate that we are 20-50 years away from an AI singularity where machines capable of recursive self-learning surpass human intellectual capacity and control AI machines that match and surpass human intelligence may be seen as leading to positive technological advances such as eliminating aging and disease or enhanced space travel (Bostrom and Yudkowsky 2014) At the same time an AI singularity may prove disastrous Stephen Hawking told the BBC (Cellan-Jones 2014) “The development of full AI could spell the end of the human race” Hawking (2014 para 7) wrote If a superior alien civilisation sent us a message saying “We’ll arrive in a few decades” would we just reply “OK call us when you get here – we’ll leave the lights on”? Probably not – but this is more or less what is happening with AI Although we are facing potentially the best or worst thing to happen to humanity in history little serious research is devoted to these issues [] All of us should ask ourselves what we can do now to improve the chances of reaping the benefits and avoiding the risks AI in education AI in education has historically focused on the design of digital tutors that not only provide exposition of concepts to be learned but also have the intelligence to respond meaningfully to student behavior such as providing adaptive support (Gilbert et al 2015) addressing student learning styles (Dorca 2015) or providing culturally appropriate communication (Blanchard 2015) Historically these tutors were embedded in software packages designed for specific content areas such as mathematics Today especially in higher grades and in post-secondary settings with student learning increasingly occurring in online settings there is a focus on web-based intelligent agents that may act as content tutors or as online discussion facilitators (Adamson et al 2014; Tegos et al 2014) AI support of online learning is especially important with the growth of Massive Open Online Courses (MOOCs) where enrollment in the most popular MOOC platforms averages over 40000 students (Ferenstein 2014) AI can play a role in organizing and supporting online collaboration and in assessing student learning Another form of educational AI which most of us take for granted is online search engines coupled with the tremendous amount of freely accessible online information ME agency modeling abstracting CT Figure 1 Three elements common to AI CT and ME AI If we need a definition the knowledge to complete a task or help to understand a concept a quick search of available online knowledge will identify a variety of text and multimedia resources to assist us CT CT in education has three instances screen-based coding digital tangibles (such as programmable robots and circuits) and off-screen algorithms or pseudocode The term CT was popularized by Wing’s (2006) advocacy “To reading writing and arithmetic we should add CT to every child’s analytical ability” ( p 33) Currently CT in education is more as its own isolated curriculum objective rather than integrated with and enriching existing subject areas (Gadanidis 2014) However there is a natural connection between CT and mathematics – such as in the logical structure or in the ability to model mathematical relationships (Wing 2008) AI∩CT∩ME Let us now turn to the intersection of AI CT and ME and explore their common focus on agency modeling and abstraction Agency AI Agency and the associated features of self-regulation and self-learning are key aspects of AI Let’s take self-driving cars as an example where a core problem is the analysis of sensor and image data For instance what kind of object is in front of the car and how should the car respond? It examines the images and guesses the kind of object in each image Initially most of its guesses will be wrong Therefore the algorithm modifies internal parameters or parts of its structure somewhat and tries again This process continues discarding changes that reduce the algorithm’s accuracy keeping changes that increase the accuracy until it correctly classifies all images Afterward when entirely new images are presented to the algorithm it will classify them with high accuracy The algorithm has learned (Top misconceptions of autonomous cars and self-driving vehicles 2015 para 29) The team of programmers designing the self-driving car could attempt to anticipate every obstacle or situation but variations are too numerous The car-in-action has to be able to learn from its experience and to make decisions based on that self-learning What is also interesting is that once one car learns something from a situation its knowledge can be immediately shared with all other cars so that all cars learn CT Student agency is a key feature of education-oriented CT environments Building on Papert’s (1980) work with Logo programming several programming languages are available today (eg Scratch available at https//scratchmitedu/) that offer a low floor enabling even young children to engage with little prerequisite knowledge and a high ceiling providing opportunities to explore more complex relationships As elaborated in greater detail in Gadanidis (in press) this environment offers students opportunities to abstract automate and dynamically model concepts to explore their relationships and to experience conceptual surprise and insight not only by implementing pre-programmed simulations but also by creating and editing their own thus experiencing CT and mathematics as producers as well as consumers For example Figure 2 shows the Scratch code for drawing a set of circles rotated about a point Young students can drag and drop code blocks that snap together to model various of mathematical concepts In such computer coding experiences students are in control writing personally meaningful code and exploring related problems and extensions ME Students’ agency is also a key feature of ME theory Burton (1999) suggests that agentic control makes a substantial difference in mathematics attitude and achievement Artificial intelligence 135 IJILT 342 136 go to x 0 y 0 clear pen down repeat 20 draw circle turn 20 degrees change pen color by 25 define draw circle repeat 90 move 4 steps turn 4 degrees Schoenfeld (1987) suggests “Many students come to believe that school mathematics consists of mastering formal procedures that are completely divorced from real life from discovery and from problem solving” (p 197) Papert (1993 p 25) adds “I am convinced that the best learning takes place when the learner takes charge” Modeling AI Developing a self-driving car involves conceptualizing models of how other cars move and react and how pedestrians interact with vehicles to give two examples Similarly designing intelligent agents in education contexts such as tutoring or online learning facilitation requires the development of models of the subject matter and of the learners This model-creation and the associated model-testing and -refinement is an integral component of AI development CT CT is an approach to problem solving that focuses on the logic and design of computational algorithms or sequences of steps that can be implemented using a computer (Aho 2012; Wing 2006 2008 2011) The power of CT modeling is its dynamic nature making a change in the computer code shows the mathematical reaction immediately For example changing the values of parameters in Figure 2 can cause the program to draw fewer circles or different shapes ME Dynamic modeling allows students to “play” with mathematics and helps bring to life the concepts students are studying Play naturally engages children with creative problem solving (Ginsburg 2006) and has historically been valued in early childhood learning (Perry and Dockett 2002; Duncan and Lockwood 2008) Abstraction AI Abstraction “plays a key role in representing knowledge and in reasoning” (Saitta and Zucker 2013 p 2) and is an integral component of AI development For example in the case of the self-driving car creating a model of “pedestrian” abstracts key attributes Figure 2 Creating a circles pattern in Scratch CT Yadav et al (2014) note that abstraction is a key element of CT Wing (2008 p 3717) states “In computing we abstract notions beyond the physical dimensions of time and space Our abstractions are extremely general because they are symbolic where numeric abstractions are just a special case” This process of abstraction can be seen in Figure 1 where the code used represents a variety of related cases at once ME Abstraction is at the heart of mathematics Abstraction in the everyday sense of the word is also a natural human activity For example very young children easily abstract beyond specific instances of objects and develop mental models of classes of objects such as “cat” despite the many different sizes colors and behaviors of cat instances However as I have argued in Gadanidis (2014 2015) the idea of engaging young students with abstraction is not widely accepted in education primarily due to the widespread acceptance of Piaget’s stages of development Egan (2002) notes that “Piaget’s ideas and overall approach absolutely dominate in education” (p 105) Papert (1980) Egan (1997) Fernandez-Armesto (1997) and Schmittau (2005) challenge Piaget’s notion that young children are not capable of abstract thinking which Egan identifies as integral to language development Abstraction helps students conceptualize and engage with complex problems and relationships by reducing information and detail Wing (2011) notes that we use abstraction to better manage complexity Concluding remarks There is tremendous interest and enthusiasm today for CT in education In Canada for example in January 2016 Prime Minister Justin Trudeau said “We need to do a lot better job of getting young people to understand what coding is and how it’s important how to program how to problem solve how to create the most elegant algorithm possible” (Kitchener Post 2016) Around the same time the provinces of British Columbia and Nova Scotia announced that computer coding will be added to all grades of the K-12 curriculum Internationally as one example England in 2014 mandated a coding curriculum for all K-12 students At the same time as discussed above there is a growing industry focus on AI These phenomena are not distinct or separate As the ancient Greek playwright Sophocles suggested there are few plots in life To better understand the evolving phenomena around us it is important to examine how they overlap and to see each through the lens of another This paper offers a nascent exploration of the intersection of AI CT and ME highlighting three of their common elements agency modeling and abstraction This seeing of ME through the lenses of other disciplines helps us recognize that there is a significant overlap of key elements draws our pedagogical attention to the importance of agency modeling and abstraction in ME and provides new contexts and tools for incorporating them in classroom practice References Adamson D Dyke G Jang H and Rose CP (2014) “Towards an agile approach to adapting dynamic collaboration support to student needs” International Journal of Artificial Intelligence in Education Vol 24 pp 2-6 Aho AV (2012) “Computation and computational thinking” Computer Journal Vol 55 pp 832-835 Artificial Intelligence (nd) “In Wikipedia” available at https//enwikipediaorg/wiki/Artificial_ intelligence (accessed March 15 2016) Blanchard EG (2015) “Socio-cultural imbalances in AIED research investigations implications and opportunities” International Journal of Artificial Intelligence in Education Vol 25 pp 204-228 Borba MC and Villarreal ME (2005) Humans-With-Media and Reorganization of Mathematical Thinking Information and Communication Technologies Modeling Experimentation and Visualization Springer New York NY Artificial intelligence 137 IJILT 342 138 Bostrom N and Yudkowsky E (2014) “The ethics of artificial intelligence” in Frankish K and Ramsey W (Eds) The Cambridge Handbook of Artificial Intelligence Cambridge University Press Cambridge pp 316-334 Burton L (1999) “The practices of mathematicians what do they tell us about coming to know mathematics?” Educational Studies in Mathematics Vol 37 pp 121-143 Cellan-Jones R (2014) “Stephen hawking warns artificial intelligence could end mankind” British Broadcasting Corporation December 2 available at wwwbbccom/news/ technology-30290540 (accessed February 23 2017) Dorca F (2015) “Implementation and use of simulated students for test and validation of new adaptive educational systems a practical insight” International Journal of Artificial Intelligence in Education Vol 25 pp 319-345 Duncan J and Lockwood M (2008) Learning through Play A Work-Based Approach for the Early Years Continuum International Publishing Group New York NY Egan K (1997) The Educated Mind How Cognitive Tools Shape our Understanding University of Chicago Press Chicago IL Egan K (2002) Getting it Wrong from the Beginning Our Progressive Inheritance from Herbert Spencer John Dewey and Jean Piaget Yale University Press New Haven CT Ferenstein G (2014) “Study massive online courses enroll an average of 43000 students 10% completion” Tech Crunch available at http//techcrunchcom/2014/03/03/study-massive- online-courses-enroll-an-average-of-43000-students-10-completion/ (accessed February 23 2017) Fernandez-Armesto F (1997) Truth A History and a Guide for the Perplexed Bartam London Gadanidis G (2014) “Young children mathematics and coding a low floor high ceiling wide walls learning environment” in Polly D (Ed) Cases on Technology Integration in Mathematics Education IGI Global Hershey PA pp 312-344 Gadanidis G (2015) “Coding as a trojan horse for mathematics education reform” Journal of Computers in Mathematics and Science Teaching Vol 34 No 2 pp 155-173 Gadanidis G Hughes J Minniti L and White B (in press) “Computational thinking grade 1 students and the binomial theorem” Digital Experience in Mathematics Education Gilbert SB Blessing SB and Guo E (2015) “Authoring effective embedded tutors an overview of the extensible problem specific tutor (xPST) system” International Journal of Artificial Intelligence in Education Vol 25 pp 428-454 Ginsburg HP (2006) “Mathematical play and playful mathematics a guide for early education” in Golinkoff RM Hirsh-Pasek K and Singer D (Eds) Play1⁄4learning Oxford University Press New York NY pp 145-165 Hawking S (2014) “Transcendence looks at the implications of artificial intelligence – but are we taking AI seriously enough?” Independent May 1 available at wwwindependentcouk/news/ science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence-but- are-we-taking-9313474html (accessed February 23 2017) Kitchener Post (2016) “Google opens its doors on Breithaurt; PM Trudeau takes part” available at wwwkitchenerpostca/news-story/6240341-google-opens-its-doors-on-breithaupt-pm-trudeau- takes-part/ (accessed June 20 2016) Latour B (2005) Reassembling the Social An Introduction to Actor-Network-Theory Oxford University Press Oxford Levy P (1993) Tecnologias da Inteligência O futuro do pensamento na era da informática [Technologies of Intelligence the future of thinking in the informatics era] Editora 34 Rio de Janeiro Levy P (1998) Becoming Virtual Reality in the Digital Age Plenum Press New York NY Papert S (1980) Mindstorms Children Computers and Powerful Ideas Basic Books New York NY Papert S (1993) The Children’s Machine Rethinking School in the Age of the Computer Basic Books New York NY Perry B and Dockett S (2002) “Young children’s access to powerful mathematical ideas” in English LD (Ed) Handbook of International Research in Mathematics Education Directions for the 21st Century Lawrence Erlbaum Associates Mahwah NJ pp 81-111 Saitta L and Zucker JD (2013) Abstraction in Artificial Intelligence and Complex Systems Springer New York NY Schmittau J (2005) “The development of algebraic thinking – a Vygotskian perspective” ZDM Vol 37 No 1 pp 16-22 Schoenfeld AH (1987) “What’s all the fuss about metacognition?” in Schoenfeld AH (Ed) Cognitive Science and Mathematics Education Lawrence Erlbaum Associates Hillsdale NJ pp 189-215 Tegos S Demetriadis S and Tsiatsos T (2014) “A configurable conversational agent to trigger students’ productive dialogue a pilot study in the CALL domain” International Journal of Artificial Intelligence in Education Vol 24 pp 62-91 Thumlert J de Castell S and Jenson J (2014) “Short cuts and extended techniques rethinking relations between technology and educational theory” Educational Philosophy and Theory Vol 47 No 8 pp 786-803 Top misconceptions of autonomous cars and self-driving vehicles (2015) “In driverless car market watch” available at wwwdriverless-futurecom/?page_id=774 (accessed February 23 2017) Vygotsky LS (1978) Mind in Society Harvard University Press Cambridge MA Wing J (2011) “Research notebook computational thinking – what and why?” The Link Magazine Spring Carnegie Mellon University Pittsburgh PA available at http//linkcscmuedu/ articlephp?a=600 Wing JM (2006) “Computational thinking” Communications of the ACM Vol 49 No 3 pp 33-35 Wing JM (2008) “Computational thinking and thinking about computing” Philosophical Transactions of the Royal Society A Vol 366 No 1881 pp 3717-3725 Yadav A Mayfield C Zhou N Hambrusch S and Korb JT (2014) “Computational thinking in elementary and secondary teacher education” ACM Transactions on Computing Education Vol 14 No 1 pp 1-5 16 Corresponding author George Gadanidis can be contacted at ggadanid@uwoca Artificial intelligence 139 For instructions on how to order reprints of this article please visit our website wwwemeraldgrouppublishingcom/licensing/reprintshtm Or contact us for further details permissions@emeraldinsightcom 
comprehensive articles Bringing Computational Thinking to K-12 What is Involved and What is the Role of the Computer Science Education Community? By Valerie Barr and Chris Stephenson The process of increasing student exposure to computational thinking in K-12 is complex requiring systemic change teacher engagement and development of significant resources Collaboration with the computer science education community is vital to this effort 48 acm Inroads 2011 March • Vol 2 • No 1 comprehensive articles 10 INTRODUCTION When Jeanette Wing [12] launched a discussion regarding the role of “computational thinking” across all disciplines she ignited a profound engagement with the core questions of what computer science is and what it might contribute to solving problems across the spectrum of human inquiry Wing argued that advances in computing allow researchers across all disciplines to envision new problem-solving strategies and to test new solutions in both the virtual and real world Computing has made possible profound leaps of innovation and imagination as it facilitates our efforts to solve pressing problems (for example the prevention or cure of dis- eases the elimination of world hunger) and expands our under- standing of ourselves as biological systems and of our relationship to the world around us These advances in turn drive the need for educated individuals who can bring the power of computing- supported problem solving to an expanded field of endeavors It is no longer sufficient to wait until students are in college to introduce these concepts All of today’s students will go on to live a life heavily influenced by computing and many will work in fields that involve or are influenced by computing They must be- gin to work with algorithmic problem solving and computational methods and tools in K-12 The successful embedding of com- putational thinking concepts into the K-12 curriculum requires efforts in two directions Educational policy must be changed overcoming significant infrastructure hurdles and K-12 teachers need resources starting with a cogent definition and relevant age- appropriate examples In this paper we report on the first part of a multiphase project aimed at developing an operational definition of computational thinking for K-12 along with suitable resources for policy and curricular change In addition to explaining the is- sues involved in the K-12 arena this paper following Gal-Ezer and Stephenson [4] is intended to help bridge the gap between the K-12 and CS education communities We note that this effort is distinct from CS education efforts such as that of Zendler and Spannagel [13] in that our goal is to articulate a set of key con- cepts within computation that can be applied across disciplines rather than proposing a set of central concepts of computer sci- ence solely for CS curricula The computer science education community can play an impor- tant role in highlighting algorithmic problem solving practices and applications of computing across disciplines and help integrate the application of computational methods and tools across diverse areas of learning At the same time CS educators must understand the complexities of the K-12 educational setting incorporating that knowledge into outreach activities and support for K-12 changes Developing a definition of or approach to computational think- ing that is suitable for K-12 is especially challenging in light of the fact that there is yet no widely agreed upon definition of compu- tational thinking Certainly K-12 students already learn how to think and to problem solve but computer scientists can help teach- ers understand these processes as algorithmic and identify where actual computation and manipulation of data with a computer may fit in Many disciplines require promote and teach problem solv- ing skills logical thinking or algorithmic thinking Computer sci- entists can promote understanding of how to bring computational processes to bear on problems in other fields and on problems that lie at the intersection of disciplines For example bioinformatics and computational biology are different but both benefit from the combination of biology and computer science The former involves collecting and analyzing biological information The latter involves simulating biological systems and processes Presenting both bio- informatics and computational biology in algorithmic form helps scientists exchange information [5] 20 MULTIPLE DEFINITIONS OF COMPUTER SCIENCE AND COMPUTATIONAL THINKING Questions of the nature and educational value of computer science are as old as the discipline itself In 1985 Abelson and Sussman argued that computer science is “a discipline of constructing ap- propriate descriptive languages” [1] Denning [2] however posited that computer science consists of mechanics (computation com- munication coordination automation and recollection) design principles (simplicity performance reliability evolvability and se- curity) and practices (programming engineering systems model- ing and validation innovating and applying) The ACM Model Curriculum for K-12 Computer Science [11] provides a defini- tion of computer science specifically for K-12 educators Computer science it argues is neither programming nor computer literacy Rather it is “the study of computers and algorithmic processes in- cluding their principles their hardware and software design their applications and their impact on society” (pg1) Computer science therefore includes I programming I hardware design I networks I graphics I databases and information retrieval I computer security I software design I programming languages and paradigms I logic I translation between levels of abstraction I artificial intelligence I the limits of computations (what computers cannot do) I applications in information technology and information systems and I social issues (Internet security privacy intellectual property etc) More recently Felleisen and Krishnamurthy [3] have argued that “imaginative programming” is the most crucial element of computing because it closely aligns mathematics with computing and in this way brings mathematics to life In framing the conceptual and educational importance of com- putational thinking as distinct from computer science Wing [12] suggested that computational thinking includes seeking algorithmic 2011 March • Vol 2 • No 1 acm Inroads 49 comprehensive articles Bringing Computational Thinking to K-12 continued approaches to problem domains; a readiness to move between dif- fering levels of abstraction and representation; familiarity with de- composition; separation of concerns; and modularity More recently Isbell et al [7] have argued for “computationalist thinking” a focus on providing services interfaces and behaviors that involves a more central role for modeling as a means of formulating relationships and identifying relevant agencies that are sources of change As the International Working Group on Computational Thinking [8] pointed out however computational thinking “shares elements with various other types of thinking such as algorith- mic thinking engineering thinking and mathematical thinking” Perkovic et al [10] similarly focus on the intellectual skills neces- sary to “apply computational techniques or computer applications to  problems and projects” in any discipline Hemmendinger [6] notes that we must be aware of the risks of arrogance and over- reaching when discussing the role of computational thinking es- pecially across disciplines He argues that the elements of compu- tational thinking that computer scientists tend to claim for their own (constructing models finding and correcting errors creating representations and analyzing) are shared across many disciplines and that the appearance of grand territorial claims risks provoking I What would computational thinking look like in the classroom? I What are the skills that students would demonstrate? I What would a teacher need in order to put computational thinking into practice? I What are teachers already doing that could be modified and extended? To be useful a definition must ultimately be coupled with ex- amples that demonstrate how computational thinking can be in- corporated in the classroom Research regarding the implementa- tion of computational thinking skills in informal education also provides valuable insights The International Working Group on Computational Thinking [8] for example points to several suc- cessful projects that use simulation and modeling robotics and computer game design to teach abstraction automation and analy- sis As they note these kinds of activities also involve an iterative design refinement and reflection process that Resnick [9] argues is central to creative as well as computational thinking In the summer of 2009 the Computer Science Teachers As- sociation (CSTA) and the International Society for Technology in Education (ISTE) began a multi- phase project aimed at develop- ing an operational definition of computational thinking for K-12 These two organizations (see Appendix A for more informa- tion about CSTA and ISTE) are particularly suited for this under- taking because of their extensive involvement in K-12 and their ex- pertise in developing educational standards curriculum materials and professional development for educators This project would bring together computational think- ing and K-12 curriculum thought leaders committed to focusing on definitions and implementation of computational thinking in the context of real K-12 curriculum outcomes standards and arti- facts The project began with the selection of a small steering com- mittee that met to I identify criteria for and names of potential invitees for a Thought Leaders meeting; and I develop an agenda for a two-day Thought Leaders meeting designed to create a framework/lexicon to better facilitate discussions of key elements of computational thinking across diverse disciplines The steering committee identified a group of educators and ad- ministrators who I had interest in computational thinking for K-12 or expertise in curriculum development and implementation I would provide representation from a broad spectrum of backgrounds and perspectives (higher education faculty and researchers K-12 professional associations school-based leaders teachers the corporate community) I had experience with or demonstrated interest in K-12 issues and To be useful a definition must ultimately be coupled with examples that demonstrate how computational thinking can be incorporated in the classroom adverse reactions Hemmendinger concludes that the ultimate goal should not be to teach everyone to think like a computer scientist but rather to teach them to apply these common elements to solve problems and discover new questions that can be explored within and across all disciplines 30 CREATING A DEFINITION FOR COMPUTATIONAL THINKING IN K-12 K-12 education today is a highly complex highly politicized en- vironment where multiple competing priorities ideologies peda- gogies and ontologies all vie for dominance It is simultaneously subject to wildly diverse expectations intense scrutiny and di- minishing resources Any effort to achieve systemic change in this environment requires a deep understanding of the realities of the system Passionate debate about the nature of computer science or computational thinking may provide intellectual stimulation for those in the computing fields However embedding computational thinking in K-12 requires a practical approach grounded in an op- erational definition It requires that we begin with a set of ques- tions focused specifically on K-12 implementation 50 acm Inroads 2011 March • Vol 2 • No 1 comprehensive articles I demonstrated leadership particularly in STEM discipline areas The steering committee eventu- ally selected 26 Thought Leaders and charged them with developing a shared vision and set of strategies for embed- ding computational thinking across the K-12 curriculum most especially in the STEM subject areas The purpose of the meeting held over two days in April 2010 was not to craft a formal or defin- itive definition of computational think- ing to be debated by academics Rather the goal of the meeting was to reach a consensus of what computational think- ing means in K-12 as well as explain the particularities of K-12 education to the CS education representatives Spe- cifically for any K-16 collaboration to be successful college faculty must un- derstand the complexities of teaching in and making changes in the K-12 setting The computer scientists participating in particular noted that educational change was considerably more complex than they suspected and that working with educators from multiple diverse disciplines meant learning to “disconnect computational thinking from computer science” 40 WAYS OF ENVISIONING COMPUTATIONAL THINKING IN K-12 CLASSROOM The participants identified many ideas about what computational thinking is and what it could be in K-12 classrooms When chal- lenged with the task of describing what makes computational thinking distinct from other kinds of thinking participants tended to focus on the centrality of the computer and a set of concepts encompassed by computational thinking and doing CT is an approach to solving problems in a way that can be implemented with a computer Students become not merely tool users but tool builders They use a set of concepts such as ab- straction recursion and iteration to process and analyze data and to create real and virtual artifacts CT is a problem solving methodology that can be automated and transferred and applied across subjects They also considered the generation of computational thinking from and its potential use in a wide variety of disciplines The power of computational thinking is that it applies to every other type of reasoning It enables all kinds of things to get done quantum physics advanced biology human-computer systems de- velopment of useful computational tools The participants envisioned computational thinking manifesting in the classroom through active problem solving They saw students “engaged in using tools to solve problems” “comfort- able with trial and error” and working in “an atmosphere of figuring things out to- gether” They also saw students using key concepts so that “you will hear them talk about sequences inputs outputs saved value how complex the solution is” The meeting participants also predicted that students whose learning abounded with opportunities for “computational do- ing” would evidence a more fluid kind of problem solving These students would understand that “problems can be solved in multiple ways” have “a tolerance for ambiguity and flexibility” and have “rea- sonable expectations about the prospect of producing a working solution” One structured model that emerged focused on identifying core computa- tional thinking concepts and capabili- ties and providing examples of how they might be embedded in activities across multiple disciplines Table 1 shows the results of these efforts Participants also discussed the core concepts in the context of capabilities dispositions and pre-dispositions and classroom cul- ture In many ways the capabilities category is a reiteration of the core concepts focused on what students would actually do These capabilities include I Design solutions to problems (using abstraction automation creating algorithms data collection and analysis); I Implement designs (programming as appropriate); I Test and debug; I Model run simulations do systems analysis; I Reflect on practice and communicating; I Use the vocabulary; I Recognize abstractions and move between levels of abstractions; I Innovation exploration and creativity across disciplines; I Group problem solving; and I Employ diverse learning strategies The dispositions and pre-dispositions category arose from an attempt to capture the “areas of values motivations feelings stereotypes and attitudes” applicable to computational thinking These included I Confidence in dealing with complexity I Persistence in working with difficult problems I The ability to handle ambiguity I The ability to deal with open-ended problems I Setting aside differences to work with others to achieve a common goal or solution and I Knowing one's strengths and weaknesses when working with others The meeting participants also predicted that students whose learning abounded with opportunities for “computational doing” would evidence a more fluid kind of problem solving 2011 March • Vol 2 • No 1 acm Inroads 51 comprehensive articles Bringing Computational Thinking to K-12 continued TABLE 1 CORE COMPUTATIONAL THINKING CONCEPTS AND CAPABILITIES CT Concept Capability Data collection Data analysis Data representation Problem Decomposition Abstraction Algorithms & procedures Automation Parallelization Simulation CS Find a data source for a problem area Write a program to do basic statistical calculations on a set of data Use data structures such as array linked list stack queue graph hash table etc Define objects and methods; define main and functions Use procedures to encapsulate a set of often repeated commands that perform a function; use conditionals loops recursion etc Study classic algorithms; implement an algorithm for a problem area Threading pipelining dividing up data or task in such a way to be processed in parallel Algorithm animation parameter sweeping Math Find a data source for a problem area for example flipping coins or throwing dice Count occurrences of flips dice throws and analyzing results Use histogram pie chart bar chart to represent data; use sets lists graphs etc To contain data Apply order of operations in an expression Use variables in algebra; identify essential facts in a word problem; study functions in algebra compared to functions in programming; Use iteration to solve word problems Do long division factoring; do carries in addition or subtraction Use tools such as geometer sketch pad; star logo; python code snippets Solve linear systems; do matrix multiplication Graph a function in a Cartesian plane and modify values of the variables Science Collect data from an experiment Analyze data from an experiment Summarize data from an experiment Do a species classification Build a model of a physical entity Do an experimental procedure Use probeware Simultaneously run experiments with different parameters Simulate movement of the solar system Social Studies Study battle statistics or population data Identify trends in data from statistics Summarize and represent trends Summarize facts; deduce conclusions from facts Language Arts Do linguistic analysis of sentences Identify patterns for different sentence types Represent patterns of different sentence types Write an outline Use of simile and metaphor; write a story with branches Write instructions Use a spell checker Do a re-enactment from a story Use excel Play age of empires; Oregon trail In attempting to define a classroom culture that would be most conducive to computational thinking the participants identified strategies or characteristics that could be considered broadly beneficial to any learning experience These included I Team work by students with explicit use of • decomposition - breaking problems down into smaller parts that may be more easily solved • abstraction - simplifying from the concrete to the general as solutions are developed • negotiation - groups within the team working together to merge parts of the solution into the whole and • consensus building - working to build group solidarity behind one idea or solution I I Increased use by both teachers and students of computational vocabulary where appropriate to describe problems and solutions; Acceptance by both teachers and students of failed solution attempts recognizing that early failure can often put you on the path to a successful outcome; 52 acm Inroads 2011 March • Vol 2 • No 1 In order to articulate and expand on these two set of resources the Thought Leaders identified several strategic areas that would have to be addressed in order to successfully embed computational thinking within K-12 For each strategic area they developed a set of requirements and suggestions that would support that element of systemic and sustained change 51 Policies Vision and Language Educational policies that include computational thinking as a part of every student's education include the following activities I Present a single message at federal state and local levels about the importance of computational thinking in K-12 education I Encourage computer science professional organizations to advocate at the federal and state levels and work with groups that are active on state K-12 standards I Incorporate computational thinking throughout the entire K-12 experience with outcomes that demonstrate incremental steps I Attach computational thinking where possible to existing policies For example it could be included as an explicit outcome of state level technology tests I Include in all teacher pre-service preparation programs a class on computational thinking across disciplines A shared vision and common language include the following activities Inspiring and preparing teachers to change include the follow- ing activities I Foster professional development since it is critical to successful educational change CS faculty can help by providing summer institutes demonstrating the role of computational thinking in non-CS disciplines and providing relevant curricular materials I Encourage school administrators to provide incentives for K-12 teachers to change courses and curricula The NSF RET grants awarded to CPATH grantees are one model that provides incentives for K-12 teachers to adopt curricular or pedagogic changes that have been piloted at the college level I Provide teachers with resources to support change including curricular materials models and simulations model activities and web sites for independent student activities I Provide teachers with professional development and support in the form of learning communities summer institutes peer learning offered by teachers with computational thinking experience exposure to industry applications where CT skills are utilized and help identifying where computational thinking is already included in teaching I Make available to school districts open-source tools (blogs wikis forums) and web-based social networks and content delivery systems for use by teachers and students (vetted so that districts are not likely to block them) I Encourage current professional education associations to show how computational thinking fits into their current standards/work comprehensive articles While further detail and synthesis work is clearly required (and planned for in the next phase of the project) these models provide a way to begin embedding computational thinking within K-12 formal education This counters the potential claim that computa- tional thinking can only be addressed in informal education expe- riences where discipline based-learning and classroom constraints are not major encumbrances However there are still considerable barriers that must be considered in any attempt at systemic and sustained change 50 STRATEGIES FOR ACHIEVING SYSTEMATIC CHANGE The kind of systemic and sustained educational change proposed necessitates two sets of resources Resources are needed to help I Improve the relationships and communication between K-12 educators (faculty and administrators) college CS faculty computer science professionals and others in industry I Develop a clear statement of computational thinking as a core competency in K-12 I Demystify terminology about computational thinking give clear examples of ways it applies to and can be integrated into a range of curricular areas 52 Inspiration and Leadership An activity for school and district level leadership inspiring change is to provide materials that will help school administrators under- stand computational thinking and see why associated knowledge and skills are important for today's students The larger CS com- munity can help by providing suitable materials and taking advan- tage of opportunities to work with K-12 administrators inform educational policy makers about the nature and importance of computational thinking its con- nections to learning goals that may have already been set for students (for example national and state standards) and ways it can best be integrated within the larger framework for student learning and suc- cess Teachers also need resources that demonstrate how to most appropriately and effectively integrate these new concepts first into their own sphere of content and pedagogical knowledge and then into their classroom content and practice The larger CS community can help by providing suitable materials and taking advantage of opportunities to work with K-12 administrators 2011 March • Vol 2 • No 1 acm Inroads 53 comprehensive articles Bringing Computational Thinking to K-12 continued I Ask professional education associations to include a focus on computational thinking in their conferences workshops and professional development events These represent strategic areas that would support the long- term goal of embedding computational thinking in K-12 They clearly demonstrate the myriad issues and obstacles involved when trying to achieve educational change in K-12 They also illustrate the critical importance of engaging knowledgeable K-12 educators in projects that purport to improve student learning and the extent to which a successful effort will require the expertise resources and dedication of educators and policy makers at all educational levels 60 NEXT STEP The next phase of this project will involve a Practitioners Workshop that will begin to develop the resources and strategies identified in the Thought Leaders meeting The challenge will be to determine the best possible artifacts to promote the implementation of compu- tational thinking concepts in K-12 We expect that the Practitioners Workshop will therefore include development of various resource sets For example a framework might be developed to guide high- level policy work (eg school district state) A second resource might consist of exemplars or activities for classroom teachers While the precise set of resources and their content have not yet been deter- mined it is clear that the Practitioners Workshop will be focused on formulating new materials both for implementing CT concepts into the curriculum and for advocating for computational thinking as a key educational component for all students Given efforts already under way at the college level including the development of new curricula and resources we expect the computer science education community will have much to contribute to this effort Ir CSTA is a membership organization of more than 7000 computing educators at the K-12 and post-secondary level Its mission is to support and promote the teaching of computer science and other computing disciplines at the K-12 level by providing opportuni- ties for teachers and students to understand better the computing disciplines and to prepare themselves more successfully to teach and to learn Since its inception five years ago CSTA has become the primary voice for K-12 computer science education advocating for the importance of computer science as part of the educational canon and its centrality to all of the STEM (science technology engineer- ing mathematics) disciplines Through its development and publication of the ACM Model Curriculum for K-12 Computer Science and supporting curriculum implementation documents CSTA has provided the de facto national standards for computer science in K-12 CSTA also conducts groundbreaking research and has published several germinal white papers on key computer science education issues It provides multiple levels of professional development (through workshops and annual conferences) that have helped educators improve theIir technical knowledge and pedagogical skills References [1] Abelson H and Sussman G Structure and Interpretation of Computer Programs MIT Press Cambridge MA 1985 [2] Denning P Great Principles of Computing Communications of the ACM 46(11) 15-20 [3] Felleisen M and Krishnamurthi S Viewpoint - Why computer science doesn't matter Com- munications of the ACM 52(7) 37 [4] Gal-Ezer J and Stephenson C Computer Science Teacher Preparation is Critical ACM Inroads 1(1) 61-66 [5] Hey T Tansley S and K Tolle “Jim Gray on eScience a transformed scientific method” in The Fourth Paradigm Data-Intensive Scientific Discovery Microsoft Research RedmondWA 2009 [6] Hemmendinger D A Plea for Modesty ACM Inroads 1(2) 4-7 [7] Isbell C Stein A Cutler R Forber J Fraser L Impagliazzo J Proulx V Russ S Thomas R Xu Y (Re)Defining computing curricula by (re)defining computing ACM SIGCSE Bulletin 41(4) 195-207 [8] IWG 2010 May Computational Thinking for Youth Education Development Center Inc Newton MA [9] Resnick M All I really need to know (about creative thinking) I learned (by studying how chil- dren learn (in kindergarten) ACM 2007 Creativity and Cognition Conference Washington DC [10] Perkovic L Settle A Hwang S and Jones J A Framework for Computational Thinking across the Curriculum Proceedings of the 2010 Conference on Innovation and Technology in Computer Science Education 2010 123-127 [11] Tucker A McCowan D Deek F Stephenson C Jones J and Verno A A model curriculum for K-12 computer science Report of the ACM K-12 Task Force Computer Science Curriculum Committee Association for Computing Machinery New York NY 2003 [12] Wing JM Computational Thinking Communications of the ACM 49(3) 33-35 [13] Zendler A and Spannagel C Empirical Foundation of Central Concepts for Computer Sci- ence Education ACM Journal on Educational Resources in Computing 8(2) VALERIE BARR Computer Science Department Union College 807 Union Street Schenectady NY 12308 barrv@unionedu CHRIS STEPHENSON Computer Science Teachers Association 2 Penn Plaza Suite 701 New York NY 10121-00701 cstephenson@cstaacmorg Categories and Subject Descriptors K32 [Computers and Education] Computer and Information Science Education - Computer science education Curriculum General terms Human Factors Keywords Computational thinking K-12 curriculum K-12 CS Education cross-disciplinary computing DOI 101145/19298871929905 © 2011 ACM 2153-2184/11/0300 $1000 APPENDIX A STE is recognized for its leadership to improve learning and teaching through effective integration of technology across the curriculum and throughout the education enterprise ISTE's commitment to educational transformation is best represented by its work to develop the National Educational Technology Standards (NETS) for Students Teachers and Administrators By convening K-12 educators teacher educators curriculum and education associations government business and private foundations ISTE built consensus for the framework and momentum for using the standards ISTE is a also a leader in convening educators and school leaders best illustrated by its annual conference which showcases emerging technology and innovative and effective use of technology in the K-12 classroom 54 acm Inroads 2011 March • Vol 2 • No 1 Note This project is supported by the National Science Foundation under Grant Nos 0964217 and 1030054 
Computers in Human Behavior xxx (xxxx) xxxx Contents lists available at ScienceDirect Computers in Human Behavior journal homepage wwwelseviercom/locate/comphumbeh Full length article Can computational thinking be improved by using a methodology based on metaphors and scratch to teach computer programming to children? Diana Pérez-Marína∗ Raquel Hijón-Neiraa Adrián Baceloa Celeste Pizarrob a Rey Juan Carlos University Computer Science Department Móstoles Madrid Spain b Rey Juan Carlos University Applied Mathematics Department Móstoles Madrid Spain ARTICLE INFO Keywords Computational thinking Primary education Programming Methodology Metaphor 1 Introduction Computational Thinking (CT) can be defined as the skill of solving problems designing systems and understanding human behavior based on computer science concepts (Wing 2006) CT is a key skill for chil- dren in the 21st century (Wing 2016) However it is unclear how CT can be developed in the most effective way in children Currently different pedagogical methodologies that can be used to develop CT are being researched In the last years some authors have claimed that CT can be acquired and developed by teaching programming to children In addition it has been claimed that this should be done as early as possible (Heintz Mannila & Färnqvist 2016; Kazakoff Sullivan & Bers 2013; McCartney 2015; McCartney & Tenenberg 2014; Papadakis Kalogiannakis & Zaranis 2016; Strawhacker Portelance Lee & Bers 2015) It is possible that CT can be acquired by other means such as Educational Robotics (Bers et al 2010) storytelling (Lee et al 2011) unplugged activities (Brackmann Barone Casali Boucinha & Muñoz- Hernández 2016) Scratch Jr (Papadakis et al 2016) or even in Ethics lessons (Seoane-Pardo 2018) Although this paper focuses on pro- gramming to foster CT learning how to program is worthwhile not only for that reason but also because of the real need for programmers in ∗ Corresponding author E-mail address dianaperez@urjces (D Pérez-Marín) https//doiorg/101016/jchb201812027 ABSTRACT Computational thinking (CT) is a key skill in the 21st century However it is not clear which is the most effective way to acquire and improve CT Big research efforts are made to determine which pedagogical means should be used One research trend is based on the idea that teaching programming since Primary Education suffices to improve CT In our previous work we proposed and validated a methodology based on metaphors and used of Scratch (MECOPROG) to teach basic programming concepts to children It is our hypothesis H that by applying MECOPROG students will develop their CT To check H we carried out an experiment with 132 Primary Education Students (9–12 years in age) At the beginning of the experiment all students were asked to fill in a programming concepts test and two tests to measure their CT During the sessions all students were taught according to MECOPROG Finally they took the three tests again A significant increase in the results on all the tests has been measured supporting the use of metaphors and Scratch to teach computer programming concepts to Primary Education students to develop their CT our digital society (Margulieux Catrambone & Guzdial 2016) as well as other advantages such as the improvement of higher cognitive skills (Pea & Kurland 1984) Many countries implemented Computer Science as a subject in Primary Education to train students into creators of computer programs (Heintz et al 2016) A common approach to teaching Computer Sci- ence to children is Scratch defined as an authoring environment - de- veloped by the Lifelong Kindergarten research group at the MIT Media Lab - to design interactive media by snapping together programming- instruction blocks (Resnick et al 2009; Ouahbi Kaddari Darhmaoui Elachqar & Lahmine 2015) Other approaches focus on using Makey Makey where students can interact with the computer by means of fruits or Play-Doh rather than using the traditional mouse (Lee Kafai Vasudevan & Davis 2014); using Lego WeDo or Mindstorms EV3 ro- bots (Sović Jagušt & Seršić 2014) and (producing) making games (Campe & Denner 2015) Another possibility is to follow unplugged approaches using storytelling or free exercises from Codeorg This is particularly useful in countries with limited resources but also in de- veloped countries where Computer Science is considered interesting but there is a lack of trained teachers and/or resources (Brackmann et al 2016) The results of these approaches have not yet been properly eval- uated and their effectiveness is still unclear (Kalelioğlu 2015) Received 28 December 2017; Received in revised form 6 August 2018; Accepted 16 December 2018 0747-5632/ © 2018 Elsevier Ltd All rights reserved Please cite this article as Diana Pérez-Marín et al Computers in Human Behavior https//doiorg/101016/jchb201812027 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Moreover no methodology or particular resources have been identified as the most adequate to teach programming to children There are difficulties in teaching children even basic concepts such as program construction (Lahtinen Ala-Mutka & Järvinen 2005) loops (Ginat 2004) structures control and algorithms (Seppälä Malmi & Korhonen 2006) These difficulties arise because of poor teacher training or a lack of a proper teaching methodology (Barker McDowell & Kalahar 2009; Coull & Duncan 2011) It has become evident that teachers need guidance to approach this task adequately (Brackmann et al 2016; Jovanov Stankov Mihova Ristov & Gusev 2016; Yadav Gretter Hambrusch & Sands 2016) In our previous work we proposed and validated the use of meta- phors to introduce children to basic concepts of programming according to the methodology MECOPROG (Pérez-Marín et al 2018) For in- stance we proposed using the metaphors of a Thermomix® recipe as a program (and sequence) pantry as memory and boxes as variables We also illustrated the possibility of applying these metaphors to any re- source available to the teacher such as Scratch The reason for using metaphors is the widely reported usefulness of metaphors as powerful educational tools Metaphors focus on concepts and facilitate students' organization of ideas and clearer more straightforward thinking (Rodríguez Diéguez 1988) Using metaphors does not require special equipment and helps teachers turn abstract concepts into simple ideas and images Students need clear and careful well-focused thinking to correctly write computer programs (Heintz et al 2016) This research paper asks the following question Can computational thinking be improved by using a methodology based on metaphors and Scratch to teach computer programming to children? It is our hypoth- esis (H) that the answer is yes For this study we asked 132 Primary Education students (aged 9 to 12) to follow MECOPROG for six weeks There were two objectives 1) to teach students the basic concepts of computer science programming; and 2) to develop students' CT by teaching them those concepts using metaphors and Scratch The results derived from this study show that using metaphors and Scratch can significantly develop students' CT but also that students are able to learn basic programming concepts The paper is organised as follows Section 2 reviews background literature on computational thinking and teaching programming in Primary Education; Section 3 outlines the materials and methods of the experiment carried out so that this study can be reproduced elsewhere; Section 4 presents the results of the experiment; and Section 5 sum- marises the main conclusions and suggests future lines of work 2 Background Computational Thinking (CT) is not a new term It dates back to 1950s when it was referred to as “algorithmic thinking” It was defined as a way to use algorithms to produce appropriate output to a given input (Denning 2009) In 2006 Wing relaunched interest in the topic and defined CT as follows “it involves solving problems designing systems and understanding human behavior by drawing on the con- cepts fundamental to computer science” (Wing 2006) Given the gen- eric nature of that definition there has recently been several un- successful attempts to make it more specific (Aho 2012; Brennan & Resnick 2012; CSTA & ISTE 2011; Google for Education 2018; Wing 2008) According to Grover and Pea (2013) CT includes decomposition pattern generalisations and location abstraction and algorithms among other Computer Science resources such as debugging and systematic error detection iterative parallel and recursive thinking control flow and use of symbols Brennan Balch and Chung (2014) also explored CT in terms of programming more specifically using Scratch based on a 3-D CT clas- sification into concepts practices and computational perspectives (Brennan & Resnick 2012) See Table 1 Table 1 Summary table of the 3-D CT dimensions model (source Brennan & Resnick 2012) 2 • Concepts − Sequences − Loops − Parallelism − Events − Conditionals − Operators − Data • Practices − Incremental & iterative development − Test & debugging − Mix & reuse − Abstract & encapsulate • Perspectives − To express − To connect − To question The goal is not to replace creative and critical thinking or other competences but to add the skill of using computers and algorithms to solve problems (Cuny Snyder & Wing 2010; Wing 2011; CSTA & ISTE 2011; Furber 2012; Espino Soledad & González 2015) Many governments emphasise the need for children to be fluent in the digital language rather than making them mere users of computer software (García-Peñalvo 2016) There are already certain resources available in the specialised literature for this (Balanskat & Engelhardt 2015; Wing 2008) Learning how to program can induce changes in the way that people think (Papert 1980; Resnick 1996) This is likely because of the ana- lytical component of CT which is quite similar to mathematical thinking (ie problem solving) engineering thinking (design and eva- luation of processes) and scientific thinking (systematic analysis) CT can be useful not only for students or professionals of Computer Science but for any other person (Wing 2006) Starting CT training as early as possible is of particular interest and it has been shown that children aged as young as four can understand programming concepts and even build simple robots which can move and interact with the environment (Bers Ponte Juelich Viera & Schenker 2002; Bers et al 2006) This is why teaching Computer Science programming has been in- cluded in the Primary Education curricular in many countries (Heintz et al 2016; see Table 2) A commonly used approach to teach Com- puter Science to children is using Scratch (Resnick et al 2009) While interacting with Scratch students learn basic concepts such as se- quences loops parallelism events conditionals operators and data (Brennan & Resnick 2012; Ouahbi et al 2015) Other approaches include making an own program (Campe & Denner 2015) using Lego WeDo or Mindstorms EV3 robots (Sović et al 2014) With regard to unplugged approaches these are common in countries with limited resources but also in developed countries which consider Computer Science an interesting option but lack trained teachers and/or Internet connections (Brackmann et al 2016) In unplugged approaches the concepts of Computer Science are transmitted through storytelling or free exercises available on Codeorg It bears mentioning here that there is no established method to evaluate the effectiveness of these approaches; therefore their validity is still unclear (Kalelioğlu 2015) A previous study by Pérez-Marín et al (2018) contributed to the debate by introducing metaphors as an alternative approach to teaching programming Metaphorical language is employed in real everyday life and is considered a crucial component of thinking (Lakoff & Johnson 2008) In particular conceptual metaphors (ie cognitive mechanisms that project from a source domain to a target domain in order to facilitate understanding of a concept in the target domain) are of great interest in educational environments (Sanford Tietz Farooq Guyer & Shapiro 2014) Metaphors have been used to teach Biology (Paris & Glynn 2004) Chemistry (Thomas & McRobbie 2001) and Mathematics (Boero Bazzini & Garuti 2001) The use of metaphors to teach Computer Science is common at college level and has been the subject of research interest (Putnam Sleeman Baxter & Kuspa 1986; Sanford et al D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Table 2 Interest in teaching programming (based on Heinz Mannila & Färnqvist et al 2016) Country Australia England Estonia Finland New Zealand Norway Sweden South Korea Finland USA Macedonia Content Form Own subject and integrated Replaces existing subject Integrated Integrated Primary Compulsory Compulsory Compulsory Compulsory Compulsory Compulsory Compulsory Compulsory Secondary Compulsory Compulsory Opcional Opcional Opcional Opcional Compulsory Opcional Digital Technologies Computing Programming Programming Programming Programming Programming Informatics Computer Science Computer Science Computers and basics of programing Own subject Own subject Integrated Own subject Own subject Own subject Own subject and Computer Science and Digital Competence 2014) There are studies on specific metaphors such as the locker memory to teach dynamic memory (Jiménez-Peris Pareja-Flores Patiño-Martínez & Velázquez-Iturbide 1997) or matrixes for event- handling in JAVA (Milner 2010) However the use of metaphorical language as a tool to teach basic concepts of Computer Science for Primary Education and the minimum age at which it can be used have not yet been researched in detail Therefore we proposed and validated a methodology called MECOPROG (see description in Section 3) to teach programming to Primary Education students using metaphors The purpose of the experiment described in this paper is to analyse whether MECOPROG has an impact on the students' programming knowledge and whether it can improve computational thinking in students 3 Method 31 Participants 132 Spanish Primary Education students (561% male and 439% femal aged 9 to 12) recruited in two parts were asked to take part in the experiment in order to assess whether their Computational Thinking (CT) improved after teaching programming using the MECOPROG methodology based on metaphors The reason for having two different parts is that programming is not compulsory in Spanish schools Therefore only a few students usually in Private schools have the opportunity to attend programming lessons We asked several Private schools that offered programming to colla- borate in the study; one school agreed because their programming teacher was on sick leave and they required a skilled temporary teacher for 4th 5th and 6th grades We were given permission to teach using the MECOPROG method during the six weeks the teacher needed to convalesce In addition and in order to provide other children with the op- portunity to attend programming classes and to ensure a more het- erogeneous sample we offered other schools in Madrid and the City Council of Fuenlabrada (where the authors live) a cost-free program- ming camp to be held on three consecutive Saturdays which children aged 10 to 12 could attend This camp also used the MECOPROG methodology 50% of our participants attended Private schools and the rest at- tended 32 different public schools and were recruited as they partici- pated in the programming camp Fig 1 shows the distribution of the students per grade (in Spain 4th grade corresponds to students aged 9–10 5th grade corresponds to students aged 10–11 and 6th grade corresponds to students aged 11–12) 182% were 4th grade students 386% were 5th grade students and 452% were 6th grade students 32 Design The research model followed a longitudinal pretest-posttest quasi- experimental design because the Head-Master of the Private School did Fig 1 Distribution of the participants in grades not provide a control group and we could not randomly assign students to each group Similarly we could not have a control group in the programming camp or randomly assign students to each group because one of the City Council's conditions to providing us with a class-room was that all students must receive the same teaching Moreover as rooms were only available from 1000 am to 200 pm we had to divide students; thus students in the 5th grade attended from 1000 am to midday whereas those in the 6th grade attended from midday to 200 pm It was not possible to recruit 4th grade students from the City Council According to Cook & Campbell (1986) we could measure the im- pact of our intervention using MECOPROG by following the quasi-ex- perimental design outlined below No rewards were offered 33 Materials 331 MECOPROG Our main resource was MECOPROG (Pérez-Marín et al 2018) Table 3 summarises the metaphors used in MECOPROG grouped into three blocks 1 – Program sequence variable and input and output instructions 2 - Conditional instructions and 3 - Loops The process for each block was (1) introduce the concept by using metaphors and then (2) practice with Scratch See Fig 2 for a global overview of MECOPROG Block 1 (2 h) First the concept of programming was explained by using the Thermomix® (Tx) cooking recipe metaphor Children were explained that – just likewhen they are following steps in a Tx recipe - Table 3 Metaphors used in MECOPROG for programming concepts Block Concept 1 Program sequence memory and variable Input and Output 2 Conditional 3 Loop Metaphor Thermomix® (Tx) recipe pantry and box Mouth and rectum (beginning and end of the digestive system) Intelligent fridge Hand mixer 3 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Fig 2 Overview of MECOPROG blocks up (first) concept (second) Scratch From left to right Sample script to work with Input/Output (block 1) sample script to work with Conditionals (Block 2) sample script to work with Loops (Block 3) the computer is able to execute the instructions of a program one step at a time No ambiguity is allowed as the computer does not understand instructions that are not precise Additionally just as the goal of fol- lowing a recipe is to produce good food a program always has a specific output The first program that they are asked to execute in Scratch is to say “Hello“ Scratch's “say” and “ask” instructions help to teach basic input/ output programming concepts Whenever students do not understand them the metaphor of input as eating something with their mouth and how their digestive system processes it until it passes through the rectum (output) is used That way students understand that you can enter data into the computer (input) execute a program and produce a result (output) The concept of sequence is also explained here as the sentences in a Tx recipe/program must be executed one after another Students are also asked whether they think that a computer has a memory Surprisingly not all students think they do Therefore we help them understand the concept of computer memory by using the pantry me- taphor The concept of data was explained by comparing the in- gredients they need to carry out a Tx recipe with the data a computer needs to executes a program Moreover the pantry metaphor can also be used to explain the concept of variables as a boxes metaphor Just like food is organised in the kitchen eggs in their box fruit in their fruit-bowl etc so the computer organises data into boxes inside its memory as variables To illustrate the concept we created the Scratch program shown in Fig 2 left Block 2 (2 h) An intelligent fridge was used as a metaphor to ex- plain conditionals Students were told that the fridge has a sensor to detect how many pieces of food it contains For instance we told children to imagine that they were in charge of serving dessert to their family at dinner An intelligent fridge would know how many family members there are and thus how many pieces of fruit they would need If they were four family members they would need at least four pieces of fruit If there were fewer than four pieces contained in the fridge the intelligent fridge will connect to Internet to buy more fruit To illustrate the concept we created the Scratch program shown in Fig 2 center Block 3 (2 h) For loops a hand mixer metaphor was used Just like a hand mixer repeats the same movement over and over again a loop repeats the same command over and over again until a condition is fulfilled Students are told that the condition in the case of the hand mixer is to whip the eggs five times To illustrate the concept we cre- ated the Scratch program shown in Fig 2 right Following the 3D CT Model (see Table 1) for Concept Dimensions the methodology covers Sequences Loops Conditionals Operators and Data (see Table 4 left) MECOPROG also covers the first three practices of the Practices Dimension (see Table 1) All students were encouraged to revisit their programs and incrementally improve them as they learnt new concepts All the examples involved testing and debugging when simple coding was reused and incorporated into more complex ones (see Table 4 top right) In regard to the Perspective Dimension the metaphor methodology also allows questioning (giving solutions to a proposed guided metho- dology) and expressing (giving solution to a problem using the com- puter) (see Table 4 right bottom) Table 4 Concepts Practices and Perspectives covered by MECOPROG highlighted in underlined in the 3D CT Model proposed by Brennan and Resnick (2012) •Concepts − Sequences − Loops − Parallelism − Events − Conditionals − Operators − Data • Practices − Incremental & iterative development − Test & debugging − Mix & reuse • − Abstract & encapsulate Perspectives − To express − To connect − To question 4 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx computational thinking Unplugged approaches use these types of ex- ercises to develop CT (Brackmann et al 2016) We debated whether to use PCNT exclusively for all students re- gardless of their age However we decided against that idea as ROMT is a validated test and we wanted to ensure that the results provided by both tests could be correlated 34 Procedure Fig 6 shows the experimental procedure At the start of the ex- periment all students took three tests • Students from 4th to 6th grades in Spanish Primary Education (aged 9–12) attended classes that taught programming through the MECOP- ROG pedagogical method Certain students who had chosen Programming as one of their optional school subjects attended as part of their schooling while the remaining students who did not take Programming as a subject (as it is not compulsory in Spain) were grouped into a programming camp on Saturdays All of them used Scratch After 6 weeks/1 h per week in the Private School and 3 2 h-sessions in the camp all students took those same three tests again We had previously decided to use the same tests again to guarantee that the post-tests had the same level of difficulty as the pre-tests In order to avoid student boredom of taking the same tests again we waited a minimum of 3 weeks before asking them to take the post-test In addition during the first test session we did not resolve any questions they had from taking the pre-tests to avoid giving solutions to the post- test 35 Measures The variables were the scores achieved by the students in the CONT ROMT and PCNT tests Specifically the following • CON students' knowledge test (CONT) score • ROM students' validated CT (ROMT) score • PCNT students' new CTT test score (PCNT) 36 Data analysis A comparative study using non-parametric tests to measure the hypothesis contrast between the pre-post PCN CON and ROM values was performed Non-parametric tests were used because when the data gathered was analysed we saw that they had not come from a normal distribution and we did not have enough data to assume normality 4 Findings 41 Overall results Table 6 shows the means medians (more representative than the mean in asymmetric distribution) and standard deviation for pre-test and post-test of PCN CON and ROM Without making distinctions per grade Table 6 reveals a clear in- crease in the post-test results in the three variables showing a greater improvement in CON variable and a smaller improvement in ROM variable Standard deviation slightly increases in all the variables ex- cept in PCN where it is more reduced in the post-test Fig 7 shows box-plots for these three variables both in the pre-test and post-test Graphically 50% of the central data are represented in During the experiment cutting cross all three blocks we occasion- ally used an application named CompThink App in our sessions (2018) developed ad-hoc for the improvement of children's computational thinking The app works with seven aspects all focused on improving the students' computational thinking (see Fig 3) 1 Loops Students select an element and set the number of times that the element will repeat the action Then they can watch an ani- mation of the action being repeated the selected number of times 2 Algorithms Students establish the order of a finite set of steps to carry out a certain activity such as cooking a recipe or planting a tree 3 Patterns Students choose the different features of a face out of a variety of options to create a face They choose between different types of hair eyes or mouths and the outcome is an animated gif with the selections they have made 4 Conditionals Students drag and drop images according to the op- tions given in “if/else” branches For instance “if the weather is cold (scarfs coat and boots) else (t-shirts bathing suit and shorts)“ 5 Steps Students select which part is missing from several possibilities in the picture In Fig 3 for example Cream and a Cherry is needed to complete the cupcake 6 Instructions Students find the final position on a map divided in squares after following a set of movement instructions 7 Automats Students select the correct order to follow a path from one place to another with certain restrictions CompThink App (CompThink App 2018) is a drag-and-drop visual interface for Android tablets or smartphones Table 1 shows the 3-D CT dimensions model (Brennan & Resnick 2012) Table 5 presents the concepts that each part of the App covers including those proposed by Brennan and Resnick (op cit) 332 Tests Three tests have been used to measure the impact of our interven- tion that used MECOPROG to teach students programming concepts and skills and to improve their computational thinking We used the CONT1 questionnaire to measure participants' knowl- edge of programming concepts (measures the CON variable as ex- plained in Section 35) CONT tests the participants' knowledge of Programming Sequence Memory & Variables Input & Output in- structions Conditionals and Loops The question formats are as fol- lows “What do you think a program is? Can you give an example?“ and seek to measure students' knowledge of those areas Two tests were used to measure computational thinking The first test is called ROMT2 (measures the ROM variable as explained in Sec- tion 35) ROMT is a validated test with 28 items that measures the Computational Thinking of children aged over 10 (Román-González Pérez-González & Jiménez-Fernández 2017) Fig 4 shows a sample question in ROMT Questions are based on Scratch code blocks and cover certain CT areas Given that ROMT cannot evaluate Computational Thinking in children younger than 10 we also used a second validated test suitable for those students However as far as we know no test has been vali- dated to measure CT in children younger than 10 Therefore this study proposed using a new test to measure CT created for children of this age It is called PCNT3 and measures the PCN variable as explained in Section 35 Fig 5 shows an example PCNT question PCNT has 14 exercises grouped into the categories outlined in Section 331 for the CompThink App (2018) to cover the 3-D CT di- mensions model created by Brennan and Resnick (2012) to assess 1 https//tinyurlcom/mecoprogCT (in Spanish) 2 https//tinyurlcom/mecoprogTRG (in Spanish) 3 https//tinyurlcom/mecoprogCTL (in Spanish) ROMT a validated test for children to measure computational • thinking (Román-González et al 2017) • CONT a concept test created ad-hoc for the experiment PCNT a new test to measure CT based on the field's literature 5 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Fig 3 CompThink App (2018) an example of the games for each of the seven options available Concept Dimension Covered of 3-D CT dimensions model by CompThink APP Table 5 CompThink App Loops Algorithms Pattern Conditionals Steps Instructions Automats Brennan and Resnick Concept Dimension on CT Loops and Data Sequences Sequences and Data Conditionals Sequences and Operators Sequences Sequences and Conditionals the box and the median are marked with a line as representative measure The highest and lowest values for each box-plot correspond to values which are not less than Q1-15·(Q3-Q1) and not greater than Q3+15·(Q3-Q1) Some outliers are marked with the case number After analysing the data using the Shapiro-Wilk test we found that the distribution of the variables under study did not come from a normal distribution except in POST_CON variable (p=0292) and POST_ROM (p = 0203) Therefore and without having a high enough number of population nonparametric tests were chosen for the study to guarantee the robustness of the results Spearman's rank correlation coefficient shows a significant corre- lation (p < 0001) between pre and post-tests in PCN CON and ROM variables The Wilcoxon signed-rank test is used to compare two related samples in this case the pre and post-tests and evaluate whether there is any statistically-significant difference in the pre and post-tests in the three variables studied Table 7 shows a significant improvement for all tests The ROM p- value is much higher than the others Therefore CON variable is the most significant Consequently we could conclude that the population saw a significant improvement in the tests Some additional information to size the effect is the r value in- troduced by Rosenthal in 1991 PCN had a value of r = 015 corre- sponding to a small effect r = 055 for CON variable corresponding to a large effect and finally r = 016 for ROM variable indicating a small effect 42 Results per grades First a descriptive analysis for each variable in the three grades is presented Tables 8–10 show the median mean and standard deviation Fig 4 An example of a ROMT question (“What instructions can you give Pac- Man to reach the ghost?” Choose from a b c or d) CON variable shows a large increase for all grades in addition to increasing data dispersion (see Table 9) In ROM variable 5th and 6th show an increase for the median as well as the standard deviation Box- 6 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Fig 5 Example of a PCNT question (“Do you know what steps you need to take to plant a tree? Place the following four actions into order 1) Take a shovel 2) Water the tree 3) Plant the tree 4) Dig a hole”) Fig 7 Box-plot for variables PCN CON and ROM in pre and post-test Again Spearman's rank correlation coefficient shows a significant correlation (p < 0001) between pre and post-tests in PCN and CON in all the grades and in 5th and 6th grades in ROM The Wilcoxon signed- rank test is used to compare two related samples in this case pre and post-test and evaluate whether there is any statistically significant Table 6 Median mean and standard deviation in pre- and post-tests PCN CON and ROM PCN CON ROM Table 7 Comparative study using Wilcoxon test PCN CON Z −2830 −8543 p-value 0005 0000 ROM −2294 0022 Fig 6 Flow diagram of the experiment Mdn M SD Pre 857 837 125 Post 928 899 105 Mdn M 269 277 5 508 SD Mdn M SD 132 428 423 136 159 464 477 156 difference in pre- and post-tests in the three variables studied for each grade Table 11 shows significant differences in different grades there is a significant improvement in PCNT variable in 5th (p = 0008) as well as ROMT variable although with a higher p-value (p = 0023) In the case of CON variable the improvement is significant in all grades (p = 0000) Rosenthal r value quantifies the improvement where it happens In 4th grade a large improvement close to very large is observed in CON variable (r = 062) In 5th grade there is a small increase near to a plots confirm this statement (see Table 10) PCN variable shows a large increase in 5th grade followed by 6th grade Standard deviation is reduced No improvement is observed for 4th grade students (see Table 8) Box-plots confirm this reasoning and show the existence of several outliers related to low marks for the three grades especially in 4th grade 7 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx Table 8 Median mean and standard deviation for pre-test and post-test for PCN per grades Table 12 Rosenthal r to quantify the improvement detected in the three tests PCN 4th Mdn MSD 5th 6th N DPCN 4th 23 – 5th 38 027 6th 50 – All 85 015 DCON DROM 062 – 051 023 055 – 055 016 Pre 928 Post 928 Table 9 860 142 875 168 Mdn M 785 826 928 903 SD Mdn 112 857 101 928 MSD 845 134 895 109 is possible to teach children basic computer programming concepts such as memory programming conditionals or loops and improve their CT with children as young as nine It is worth noting that although there is a general consensus re- garding the need to foster children's CT (Román-González 2015) and the results reported in this study significantly contribute to the litera- ture in this sens there is still much controversy surrounding the defi- nition of the term CT and how and when to integrate it into the cur- riculum (Gouws Bradshaw & Wentworth 2013) Since this study required a practical definition of what comprises CT in order to work with children and anaylse what parts of CT could be improved and how we chose the 3D CT Model (Brennan & Resnick 2012; see Table 1) The reason for selecting that model was that it had been created by the authors of Scratch a program that allows children to program As noted by Vico (2017) (translated from Spanish); “A child who does not learn how to program will have the same handicap as a Spanish child who is not able to understand English” This is also why we wanted to foster an interest in CT so that children can become programmers Otherwise it seems as though we have only taught our Pre-school children to read but not how to write However some Computer Science educators have argued that pro- gramming is not necessary to teach computational thinking (Lu & Fletcher 2009; Yadav Zhou Mayfield Hambrusch & Korb 2011) Some have even suggested that teaching programming to foster CT could deter students as some may find computer science and pro- gramming boring (Lu & Fletcher 2009) In light of our results and from our experience with children age 9 to 12 learning how to program is engaging and helps them focus on problems All children payed attention during the lessons regardless of their grade In general it is well known that children love computers and do not think that they are difficult or boring to use This could be used as a base to start working with children who are naturally fasci- nated by technology This study is particularly relevant for teachers and national curri- culums as it shows that children can enjoy learning about program- ming Until recently it was unconceivable to think children could learn about programming On the contrary children were not taught these concepts until Secondary School or even University at an age that students begin to find these complex ideas difficult to understand in contrast to younger children who can easily absorb them when adapted to their age It has also become evident that teachers need guidance in their approach to this task According to this study students are able to learn programming concepts if they are taught with methodologies such as MECOPROG with Scratch and those that use metaphors Teachers must be trained in those methodologies if we want to reach Primary Median mean and standard deviation for pre-test and post-test for CON per grades CON 4th Mdn MSD 5th 6th Pre 269 Post 519 Table 10 250 101 509 128 Mdn M 231 274 480 501 SD Mdn 167 269 168 519 MSD 280 099 514 154 Median mean and standard deviation for pre-test and post-test for ROM per grade ROM 5th 6th Mdn M SD Mdn M SD Pre 428 443 Post 500 517 154 411 408 121 171 464 446 138 medium increase in PCN variable (r = 027) A large increase occurs in the CON variable (r = 057) and a small increase in the ROM variable (r = 023) Finally in 6th grade a large effect is found with r = 055 43 Synopsys table Table 12 gathers the increase of the scores in the three tests taken by the students before and after MECOPROG Finally in response to our question regarding the relationship be- tween PCNT and ROMT there is a low lineal correlation between them (Spearman r = 0248 p < 001) 5 Discussion This paper explored whether Primary Education students' CT can be improved and to what extent Primary Education students are able to learn programming concepts It included factors such as grade and used tests to measure children's’ knowledge and computational thinking One important conclusion is that there is a statistic significant in- crease in children's post-test results both in knowledge (according to the CONT knowledge test) and CT values for all grades (according to PCNT and ROMT CT tests) This suggests that even in a short period of time it Table 11 Comparative study using Wilcoxon test PCN CON ROM 5th 6th −2274 −0928 0023 0354 4th 5th Z −0515 −2674 p-value 0607 0008 6th 4th −1362 −4204 0173 0000 5th 6th −4845 −5715 0000 0000 8 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx to them as they were aged younger than 10 no conclusion could be drawn from this test When the results of the PCNT are analysed no significant results could be drawn either indicating the need for more studies to quantify the increase (if any) of the development of CT in students aged younger than 10 when they learn programming concepts We cannot end without highlighting the fact that 5th grade students improved their performance in all tests Not only did they learn more programming concepts through MECOPROG but their scores in both CT-measuring tests increased significantly Finally 6th and 4th grade students' knowledge of programming improved but no significant im- provement was found in ROMT or PCNT scores This may indicate ei- ther that these students need more time to improve their CT or that the MECOPROG metaphors methodology is more applicable to students aged 10–11 Acknowledgments Research funded by the projects TIN 2015-66731-C2-1-R and S2013/ICE-2715 References Aho A V (2012) Computation and computational thinking The Computer Journal 55(7) 832–835 Balanskat A & Engelhardt K (2015) Computing our future Computer programming and coding Priorities school curricula and initiatives across Europe Brussels Belgium European Schoolnet2015 Barker L J McDowell C & Kalahar K (2009) Exploring factors that influence com- puter science introductory course students to persist in the major ACM SIGCSE bulletin Vol 41 (pp 153–157) ACM No 1 Bers M U (2010) The TangibleK Robotics program Applied computational thinking for young children Early Childhood Research & Practice 12(2) 2 Bers M U Ponte I Juelich C Viera A & Schenker J (2002) Teachers as designers Integrating robotics in early childhood education Information Technology in Childhood Education Annual 1(1) 123–145 Bers M Rogers C Beals L Portsmore M Staszowski K Cejka E et al (2006) Innovative session Early childhood robotics for learning Proceedings of ISTE C 2011 Computational thinking in K–12 education leadership toolkit Boero P Bazzini L & Garuti R (2001) Metaphors in teaching and learning mathe- matics A case study concerning inequalities Pme conference Vol 2 (pp 2–185) Brackmann C Barone D Casali A Boucinha R & Muñoz-Hernández S (2016) Computational thinking Panorama of the americas Computers in education (SIIE) international symposium on IEE (pp 1–6)  Brennan K Balch C & Chung M (2014) Creative computing Cambridge [masachussets] Harvard Graduate School of Educationhttp//scratchedgseharvardedu/guide/files/ CreativeComputing20141015pdf [Consulta 30/05/2017] Brennan K & Resnick M (2012) New frameworks for studying and assessing the de- velopment of computational thinking Proceedings of the annual meeting of the American educational research association Vancouver Canada (pp 1–25)  Campe S & Denner J (2015) Programming games for learning A research synthesis Paper presented at the annual meeting of the American educational research association Chicago IL Cook T D & Campbell D T (1986) The causal assumptions of quasi-experimental practice Synthese 68(1) 141–180 CompThink App (2018) http//wwwliteetsiiurjces/tools/compthink-app/ Coull N J & Duncan I M (2011) Emergent requirements for supporting introductory programming Innovation in Teaching and Learning in Information and Computer Sciences 10(1) 78–85 CSTA & ISTE (2011) Operational definition of computational thinking for K–12 education Retrieved from http//cstaacmorg/Curriculum/sub/CurrFiles/CompThinkingFlyer pdf Cuny J Snyder L & Wing J M (2010) Demystifying computational thinking for non- computer scientists Unpublished manuscript in progress [On line] Available refer- enced in http//wwwcscmuedu/∼CompThink/resources/TheLinkWingpdf Denning P J (2009) The profession of IT Beyond computational thinking Communications of the ACM 52(8) 28–30 Espino E Soledad C & González C (2015) Estudio sobre diferencias de género en las competencias y las estrategias educativas para el desarrollo del pensamiento com- putacional Revista de Educación a Distancia 46 Furber S (2012) Shut down or restart The way forward for computing in UK schools [On line] Available Retrieved from http//royalsocietyorg/education/policy/ computing-in-schools/report/ García-Peñalvo F J (2016) A brief introduction to TACCLE 3—coding european project Computers in education (SIIE) international symposium on IEEE (pp 1–4)  Ginat D (2004) On novice loop boundaries and range conceptions Computer Science Education 14(3) 165–181 Google for Education (2018) Exploring computational thinking Retrieved from https// wwwgooglecom/edu/resources/programs/exploring-computational-thinking/ Gouws L A Bradshaw K & Wentworth P (2013) Computational thinking in Education students Therefore and in line with the Digital Competence that teachers should develop we should include this training in their pedagogical education (INTEF 2017) Measuring the progress of CT is also necessary The tests used for this could differ depending on the definition of CT and the age of the students For instance the test created by Korkmaz Çakir and Özden (2017) is limited to the sub-skills comprising the ISTE (2015) definition In addition it is limited to associate students and older students Only one validated test was found to measure CT according to the 3D CT Model and to be useful for young children The authors of this test kindly allowed us to use it (Román-González et al 2017) for this study However the test (ROMT) is only validated for children older than 10 For younger students we tried a new test (PCNT) as explained above which was also in line with the published 3D CT Model The results gathered both from ROMT and PNCT proved that CT can be improved by using MECOPROG However given the low correlation found between PCNT and ROMT more studies should be carried out focusing on how to assess CT for young students particularly those aged under 9 51 Limitations and future work We are aware that these measures would change if we use a dif- ferent CT definition and that the results may change if we use a dif- ferent model and/or a different computer program other than Scratch Furthermore MECOPROG can be used with different resources and may thus produce different results in each case The core metaphors used in this paper are based on cooking Different metaphors can be used such as car metaphors the door as input/output for the car junctions for conditionals roundabouts for loops and so on During class teachers are able to select the most adequate metaphor from MECOPROG as published (Pérez-Marín et al 2018) The experiment has been described in great detail so that other researchers are interested in repeating it with a different sample or to test more advanced programming concepts can do so easily This study experiment focused on basic introductory computer programming concepts because it was the first contact with those particular students and the project only had a limited amount of time The authors are currently also carrying out a multifactorial study to determine whether other factors such as sex motivation or effort might have an impact on students' CT test scores We would also like to continue with the validation of PCNT given the low correlation found between PCNT and ROMT 6 Conclusions The findings of this longitudinal pre- and post-test quasi-experiment carried out with 132 Primary Education students (aged 9 to 12) posi- tively confirmed the formulated research question Can computational thinking be improved using a methodology based on metaphors and using Scratch to teach computer programming to children? Table 12 gathers the main results of the research study Here both the knowledge programming concept test and the CT tests (ROMT and PCNT) found better post-test scores when data were analysed for all the grades These results suggest that using metaphors and Scratch is useful for teaching computer programming concepts to Primary Education students and for improving students' CT providing a positive answer to the research question It contributes to the area of study exploring how to develop Computational Thinking by covering gaps in methodologies and uses for the first time metaphors to teach basic programming concepts to Primary Education Students together with Scratch When the analysis is carried out per grade it shows that 4th grade students can understand programming concepts In fact it seems to show that these students are actually able to learn more about pro- gramming concepts as their increase in CONT knowledge improves more than any other group Because we could not apply the ROMT test 9 D Pérez-Marín et al Computers in Human Behavior xxx (xxxx) xxxx educational activities An evaluation of the educational game light-bot Proceedings of the 18th ACM conference on innovation and technology in computer science education (pp 10–15)  Grover S & Pea R (2013) Computational thinking in K–12 A review of the state of the field Educational Researcher 42(1) 38–43 Heintz F Mannila L & Färnqvist T (2016) A review of models for introducing computational thinking computer science and computing in K-12 education Frontiers in education Conference (FIE) 2016 (pp 1–9) IEEE INTEF (2017) Marco común de Competencia digital docente https//intefes/Blog/marco- comun-de-competencia-digital-docente-septiembre-2017/ ISTE (2015) CT leadership toolkit Available at https//wwwisteorg/docs/ctdocuments/ ct-leadershipt-toolkitpdf%3fsfvrsn%bc;4 Jiménez-Peris R Pareja-Flores C Patiño-Martínez M & Velázquez-Iturbide JÁ (1997) The locker metaphor to teach dynamic memory ACM SIGCSE bulletin Vol 29 (pp 169–173) ACM No 1 Jovanov M Stankov E Mihova M Ristov S & Gusev M (2016) Computing as a new compulsory subject in the Macedonian primary schools curriculum Global engineering education conference (EDUCON) 2016 IEEE (pp 680–685) IEEE Kalelioğlu F (2015) A new way of teaching programming skills to K-12 students Code Org Computers in Human Behavior 52 200–210 Kazakoff E R Sullivan A & Bers M U (2013) The effect of a classroom-based in- tensive robotics and programming workshop on sequencing ability in early child- hood Early Childhood Education 41 245–255 Korkmaz Ö Çakir R & Özden M Y (2017) A validity and reliability study of the Computational Thinking Scales (CTS) Computers in Human Behavior 72 558–569 Lahtinen E Ala-Mutka K & Järvinen H M (2005) A study of the difficulties of novice programmers ACM SIGCSE bulletin Vol 37 (pp 14–18) no 3 Lakoff G & Johnson M (2008) Metaphors we live by University of Chicago press Lee E Kafai Y B Vasudevan V & Davis R L (2014) Playing in the arcade Designing tangible interfaces with MaKey MaKey for scratch games Playful user interfaces (pp 277–292) Springer Singapore Lee I Martin F Denner J Coulter B Allan W Erickson J & Werner L (2011) Computational thinking for youth in practice Acm Inroads 2(1) 32–37 Lu J J & Fletcher G H (2009) Thinking about computational thinking ACM SIGCSE Bulletings 41(1) 260e264 Margulieux L E Catrambone R & Guzdial M (2016) Employing subgoals in com- puter programming education Computer Science Education 26(1) 44–67 https//doi org/101080/0899340820161144429 Special issue II on computer science education in K-12 schools R McCartney (Ed) Transactions on Computing Education ACM 14 2 Special issue on computing education in (K-12) schools Transactions on computing education R McCartney & J Tenenberg (Eds) ACM 14 2 Milner W W (2010) A broken metaphor in Java ACM SIGCSE Bulletings 41(4) 76–77 Ouahbi I Kaddari F Darhmaoui H Elachqar A & Lahmine S (2015) Learning basic programming concepts by creating games with scratch programming environment Procedia-Social and Behavioral Sciences 191 1479–1482 Papadakis S Kalogiannakis M & Zaranis N (2016) Developing fundamental pro- gramming concepts and computational thinking with ScratchJr in preschool educa- tion A case study International Journal of Mobile Learning and Organisation 10(3) 187–202 Papert S (1980) Mindstorms Children computers and powerful ideas New York NY Basic Books Paris N A & Glynn S M (2004) Elaborate analogies in science text Tools for en- hancing preservice teachers' knowledge and attitudes Contemporary Educational Psychology 29(3) 230–247 Pea R D & Kurland D M (1984) On the cognitive effects of learning computer pro- gramming New Ideas in Psychology 2(2) 137–168 Pérez-Marín D Hijón-Neira R & Martín-Lope M (2018) A Methodology proposal based on metaphors to teach programming to children IEEE Revista Iberoamericana de Tecnologías del Aprendizaje 13(1) 46–53 Putnam R T Sleeman D Baxter J A & Kuspa L K (1986) A summary of mis- conceptions of high school Basic programmers Journal of Educational Computing Research 2(4) 459–472 Resnick M (1996) New paradigms for computing new paradigms for thinking In Y InKafai & M Resnick (Eds) Constructionism in practice Designing thinking and learning in a digital world Mahwah NJ Erlbaum Resnick M Maloney J Monroy-Hernandez A Rusk N Eastmond E Brennan K et al (2009) Scratch Programming for all Communications of the ACM 52(11) 60–67 Rodríguez Diéguez J L (1988) Las metáforas en la enseñanza Enseñanza & Teaching Revista interuniversitaria de didáctica (pp 223–240) Universidad de Salamanca 6 Román-González M (2015) Computational thinking test Design guidelines and content validation Proceedings of EDULEARN15 conference (pp 2436–2444)  Román-González M Pérez-González J C & Jiménez-Fernández C (2017) Which cognitive abilities underlie computational thinking? Criterion validity of the com- putational thinking test Computers in Human Behavior 72 678–691 https//doiorg/ 101016/jchb201608047 nd Rosenthal R (1991) Meta-analytic procedures for social research (2 ed) Newbury Park CA Sage Sanford J P Tietz A Farooq S Guyer S & Shapiro R B (2014) Metaphors we teach by Proceedings of the 45th ACM technical symposium on Computer science education (pp 585–590) ACM Seoane-Pardo A M (2018) Computational thinking between philosophy and STEM Programming decision making applied to the behaviour of “moral machines” in ethical values classroomIEEE-RITAhttps//doiorg/101109/RITA20182809940 Seppälä O Malmi L & Korhonen A (2006) “Observations on student mis- conceptions—a case study of the Build–Heap Algorithm” Computer Science Education 16(3) 241–255 Sović A Jagušt T & Seršić D (2014) How to teach basic university-level program- ming concepts to first graders? Integrated STEM education conference (ISEC) 2014 IEEE (pp 1–6) IEEE Strawhacker A Portelance D Lee M & Bers M (2015) Designing tools for developing minds The role of child development in educational technology IDC 2015 workshop Available on-line at http//everychildacoderorguk/wp-content/uploads/2015/05/ Strawhacker_et_al_finalpdf Last visit November 23rd 2017  Thomas G P & McRobbie C J (2001) Using a metaphor for learning to improve students' metacognition in the chemistry classroom Journal of Research in Science Teaching 38(2) 222–259 Vico F (2017) El niño que no programe tendrá un hándicap como hoy lo tiene el que no entiende inglés Entrevistas Educación 30 https//wwweducaciontrespuntocerocom/ entrevistas/francisco-j-vico-programacion/59063html Wing J M (2006a) Computational thinking Communications of the ACM 49(3) 33–35 Wing J M (2006b) Computational thinking Communications of the ACM 49(3) 33–35 Wing J (2008) Computational thinking and thinking about computing Philosophical Transactions of the Royal Society of Mathematical Physical and Engineering Sciences 366 3717–3725 Wing J (2011) Research notebook Computational thinking— what and why [On line] Available The link magazine SpringPittsburgh Carnegie Mellon University Retrieved from http//linkcscmuedu/articlephp?a=600 Wing J M (2016) Computational thinking 10 years later http//wwwmicrosoftcom/en- us/research/blog/computational-thinking-10-years-later Yadav A Gretter S Hambrusch S & Sands P (2016) Expanding computer science education in schools Understanding teacher experiences and challenges Computer Science Education 1–20 Yadav A Zhou N Mayfield C Hambrusch S & Korb J T (2011) Introducing computational thinking in education courses Proceedings of ACM special interest group on computer science education dallas TX 10 
© 2010–2011 by ACM Original version in ACM Ubiquity Reprinted here with permission doi101093/comjnl/bxs074 Computation and Computational Thinking Alfred V Aho Department of Computer Science Columbia University New York NY 10027 Corresponding author aho@cscolumbiaedu We recommend using the term Computation in conjunction with a well-defined model of computation whose semantics is clear and which matches the problem being investigated Computer science already has a number of useful clearly defined models of computation whose behaviors and capabilities are well understood We should use such models as part of any definition of the term computation However for new domains of investigation where there are no appropriate models it may be necessary to invent new formalisms to represent the systems under study 1 THE NEED FOR CLEAR DEFINITIONS In any scientific discipline there are many reasons to use terms that have precise definitions Understanding the terminology of a discipline is essential to learning a subject and precise terminology enables us to communicate ideas clearly with other people In computer science the problem is even more acute we need to construct software and hardware components that must smoothly interoperate across interfaces with clients and other components in distributed systems The definitions of these interfaces need to be precisely specified for interoperability and good systems performance Using the term “computation” without qualification often generates a lot of confusion Part of the problem is that the nature of systems exhibiting computational behavior is varied and the term computation means different things to different people depending on the kinds of computational systems they are studying and the kinds of problems they are investigating Since computation refers to a process that is defined in terms of some underlying model of computation we would achieve clearer communication if we made clear what the underlying model is Rather than talking about a vague notion of “computation” my suggestion is to use the term in conjunction with a well- defined model of computation whose semantics is clear and which matches the problem being investigated Computer science already has a number of useful clearly defined models of computation whose behaviors and capabilities are well understood We should use such models as part of any definition of the term computation However for new domains of investigation where there are no appropriate models it may be necessary to invent new formalisms to represent the systems under study 2 COMPUTATIONAL THINKING We consider computational thinking to be the thought processes involved in formulating problems so their solutions can be represented as computational steps and algorithms An important part of this process is finding appropriate models of computation with which to formulate the problem and derive its solutions A familiar example would be the use of finite automata to solve string pattern matching problems A less familiar example might be the quantum circuits and order finding formulation that Peter Shor [1] used to devise an integer- factoring algorithm that runs in polynomial time on a quantum computer Associated with the basic models of computation in computer science is a wealth of well-known algorithm- design and problem-solving techniques that can be used to solve common problems arising in computing However as the computer systems we wish to build become more complex and as we apply computer science abstractions to new problem domains we discover that we do not always have the appropriate models to devise solutions In these cases computational thinking becomes a research activity that includes inventing appropriate new models of computation Corrado Priami and his colleagues at the Centre for Computational and Systems Biology in Trento Italy have been using process calculi as a model of computation to create programming languages to simulate biological processes Priami states “the basic feature of computational thinking is The Computer Journal Vol 55 No 7 2012 Downloaded from https//academicoupcom/comjnl/article-abstract/55/7/832/339564 by 59662000 user on 29 January 2020 abstraction of reality in such a way that the neglected details in the model make it executable by a machine” [2] As we shall see finding or devising appropriate models of computation to formulate problems is a central and often nontrivial part of computational thinking 3 FORCES AT PLAY In the last half century what we think of as a computational system has expanded dramatically In the earliest days of computing a computer was an isolated machine with limited memory to which programs were submitted one at a time to be compiled and run Today in the Internet era we have networks consisting of millions of interconnected computers and as we move into cloud computing many foresee a global computing environment with billions of clients having universal on-demand access to computing services and data hosted in gigantic data centers located around the planet Anything from a PC or a phone or a TV or a sensor can be a client and a data center may consist of hundreds of thousands of servers Needless to say the models for studying such a universally accessible complex highly concurrent distributed system are very different from the ones for a single isolated computer Another force at play is that because of heat dissipation considerations the architecture of computers is changing An ordinary PC today has many different computing elements such as multicore chips and graphics processing units and an exascale supercomputer by the end of this decade is expected to be a giant parallel machine with up to a million nodes each with possibly a thousand processors Our understanding of how to write efficient programs for these machines is limited Good models of parallel computation and parallel algorithm design techniques are a vital open research area for effective parallel computing In addition there is increasing interest in applying computation to studying virtually all areas of human endeavor One fascinating example is simulating the highly parallel biological processes found in human cells and organs for the purposes of understanding disease and drug design Good computational models for biological processes are still in their infancy And it is not clear we will ever be able to find a computational model for the human brain that would account for emergent phenomena such as consciousness or intelligence 4 THE THEORY OF COMPUTATION The theory of computation has been and still is one of the core areas of computer science It explores the fundamental capabilities and limitations of models of computation A model of computation is a mathematical abstraction of a computing system The most important model of sequential computation studied in computer science is the Turing machine first proposed by Alan Turing in 1936 [3] Let us briefly review the definition of a Turing machine to appreciate the detail necessary to understand even this familiar model of computation We can think of a Turing machine as a finite-state control attached to a tape head that can read and write symbols on the squares of a semi-infinite tape Initially a finite string of length n representing the input is in the leftmost n squares of the tape An infinite sequence of blanks follows the input string The tape head is reading the symbol in the leftmost square and the finite control is in a predefined initial state The Turing machine then makes a sequence of moves In a move it reads the symbol on the tape under the tape head and consults a transition table in the finite-state control which specifies a symbol to be overprinted on the square under the tape head a direction the tape head is to move (one square to the left or right) and a state to enter next If the Turing machine enters an accepting halting state (one with no next move) the string of nonblank symbols remaining on the input tape at that point in time is its output Mathematically a Turing machine consists of seven components a finite set of states; a finite input alphabet (not containing the blank); a finite tape alphabet (which includes the input alphabet and the blank); a transition function that maps a state and a tape symbol into a state tape symbol and direction (left or right); a start state; an accept state from which there are no further moves; and a reject state from which there are no further moves We can characterize the configuration of a Turing machine at a given moment in time by three quantities (i) the state of the finite-state control (ii) the string of nonblank symbols on the tape and (iii) the location of the input head on the tape A computation of a Turing machine on an input w is a sequence of configurations the machine can go through starting from the initial configuration with w on the tape and terminating (if the computation terminates) in a halting configuration We say a function f from strings to strings is computable if there is some Turing machine M that given any input string w always halts in the accepting state with just f (w) on its tape We say that M computes f  The Turing machine provides a precise definition for the term algorithm an algorithm for a function f is just a Turing machine that computes f  There are scores of models of computation that are equivalent to Turing machines in the sense that these models compute exactly the same set of functions that Turing machines can compute Among these Turing-complete models of computation are multitape Turing machines lambda-calculus random access machines production systems cellular automata and all general-purpose programming languages The reason there are so many different models of computation equivalent to Turing machines is that we rarely want to implement an algorithm as a Turing machine program; Computation and Computational Thinking 833 The Computer Journal Vol 55 No 7 2012 Downloaded from https//academicoupcom/comjnl/article-abstract/55/7/832/339564 by 59662000 user on 29 January 2020 834 AV Aho we would like to use a computational notation such as a programming language that is easy to write and easy to understand But no matter what notation we choose the famous Church-Turing thesis hypothesizes that any function that can be computed can be computed by a Turing machine Note that if there is one algorithm to compute a function f then there is an infinite number Much of computer science is devoted to finding efficient algorithms to compute a given function For clarity we should point out that we have defined a computation as a sequence of configurations a Turing machine can go through on a given input This sequence could be infinite if the machine does not halt or one of a number of possible sequences in case the machine is nondeterministic The reason we went through this explanation is to point out how much detail is involved in precisely defining the term computation for the Turing machine one of the simplest models of computation It is not surprising then as we move to more complex models the amount of effort needed to precisely formulate computation in terms of those models grows substantially 5 CONCURRENT MODELS Many real-world computational systems compute more than just a single function-the world has moved to interactive computing [4] The term reactive system is used to describe a system that maintains an ongoing interaction with its environment Examples of reactive systems include operating systems and embedded systems A distributed system is one that consists of autonomous computing systems that communicate with one another through some kind of network using message passing Examples of distributed systems include telecommunications systems the Internet air-traffic control systems and parallel computers Many distributed systems are also reactive systems Perhaps the most intriguing examples of reactive distributed computing systems are biological systems such as cells and organisms We could even consider the human brain to be a biological computing system Formulation of appropriate models of computation for understanding biological processes is a formidable scientific challenge in the intersection of biology and computer science Distributed systems can exhibit behaviors such as deadlock livelock race conditions and the like that cannot be usefully studied using a sequential model of computation Moreover solving problems such as determining the throughput latency and performance of a distributed system cannot be productively formulated with a single-thread model of computation For these reasons computer scientists have developed a number of models of concurrent computation which can be used to study these phenomena and to architect tools and components for building distributed systems There are many theoretical models for concurrent compu- tation One is the message-passing Actor model consisting of computational entities called actors [5] An actor can send and receive messages make local decisions create more actors and fix the behavior to be used for the next message it receives These actions may be executed in parallel and in no fixed order The Actor model was devised to study the behavioral properties of parallel computing machines consisting of large numbers of independent processors communicating by passing messages through a network Other well-studied models of concurrent computation include Petri nets and the process calculi such as pi-calculus and mu-calculus Many variants of computational models for distributed systems are being devised to study and understand the behaviors of biological systems For example Dematte et al [6] describe a language called BlenX that is based on a process calculus called Beta-binders for modeling and simulating biological systems We do not have the space to describe these concurrent models in any detail However it is still an open research area to find practically useful concurrent models of computation that combine control and data for many areas of distributed computing 6 BENEFITS OF MODELS OF COMPUTATION In addition to aiding education and understanding there are many practical benefits to having appropriate models of computation for the systems we are trying to build In cloud computing for example there are still a host of poorly understood concerns for systems of this scale We need to better understand the architectural tradeoffs needed to achieve the desired levels of reliability performance scalability and adaptivity in the services these systems are expected to provide We do not have appropriate abstractions to describe these properties in such a way that they can be automatically mapped from a model of computation into an implementation (or the other way around) In cloud computing there are a host of research challenges for system developers and tool builders As examples we need programming languages compilers verification tools defect detection tools and service management tools that can scale to the huge number of clients and servers involved in the networks and data centers of the future Cloud computing is one important area that can benefit from innovative computational thinking 7 CONCLUSION Mathematical abstractions called models of computation are at the heart of computation and computational thinking Computation is a process that is defined in terms of an underlying model of computation and computational thinking is the thought processes involved in formulating problems so The Computer Journal Vol 55 No 7 2012 Downloaded from https//academicoupcom/comjnl/article-abstract/55/7/832/339564 by 59662000 user on 29 January 2020 their solutions can be represented as computational steps and algorithms Useful models of computation for solving problems arising in sequential computation can range from simple finite- state machines to Turing-complete models such as random access machines Useful models of concurrent computation for solving problems arising in the design and analysis of complex distributed systems are still a subject of current research ABOUT THE AUTHOR Alfred V Aho is Lawrence Gussman Professor in the Computer Science Department at Columbia University He served as Chair of the department from 1995 to 1997 and in the spring of 2003 ACKNOWLEDGEMENTS The author would like to thank Peter Denning and Jeannette Wing for their thoughtful comments on the importance of computational thinking The author is also grateful to Jim Larus for his insights into the problems confronting cloud computing and to Corrado Priami for many stimulating conversations on computational thinking in biology REFERENCES [1] ShorPW(1994)Algorithmsforquantumcomputationdiscrete logarithms and factoring Proceedings of the 35th Annual Symposium on Foundations of Computer Science pp 124–134 IEEE Computer Society [2] Priami C (2007) Computational thinking in biology Transac- tions on Computational Systems Biology VIII 8 63–76 [3] Turing A (1937) On computable numbers with an application to the entscheidungsproblem Proceedings of the London Mathematical Society 2 42 pp 230–265 [4] Goldin D Q Smolka S A and Wegner P (eds) (2006) Interactive Computation The New Paradigm Springer [5] HewittCBishopPandSteigerR(1973)Auniversalmodular actor formalism for artificial intelligence Proceedings of the 3rd international joint conference on Artificial intelligence Stanford USA pp 235–245 Morgan Kaufmann Publishers Inc [6] Dematté L Priami C and Romanel A (2008) The blenx language a tutorial Proceedings of SFM’08 Bertinoro Italy pp 313–365 Springer-Verlag [7] Denning P J (2009) Beyond computational thinking Commun ACM 52 28–30 [8] Wing J M (2006) Computational thinking Commun ACM 49 33–35 Computation and Computational Thinking 835 The Computer Journal Vol 55 No 7 2012 Downloaded from https//academicoupcom/comjnl/article-abstract/55/7/832/339564 by 59662000 user on 29 January 2020 
Computational thinking BY SUSAN GERMAN Students develop computational thinking by approaching new situations using a variety of computer-based methods including simulation data mining networking automated data collection gaming algorithmic reasoning robotics and programming Computational thinking is different from mathematical thinking According to Sneider et al (2014) students develop mathematical thinking when they attempt to approach a new situation with their acquired math skills including counting arithmetic algebra geometry calculus set theory and topology Computational thinking is part of the Next Generation Science Standards science and engineering practices (see Figure 1) Computational thinking can be used in conjunction with any of the practices Implementing computational thinking Computer simulations provide students with the opportunity to model phenomena by changing the input conditions and measuring the outcome While I firmly believe it is best for students to interact with physical phenomena a computer simulation can be more time efficient and allows students to try out “What if…?” scenarios in a safe manner Computer simulations are best used in situations where physical phenomena are difficult to study directly such as the solar system or molecular motion However while electric circuits are directly observable using a simulation can bring the unobservable parts of the phenomenon to an observable level I developed an assessment on electric circuits after my students completed a unit on electricity during which they learned about series and parallel circuits The assessment used the PhET Circuit Construction Kit DC-Virtual Lab (see Resources) which allowed students to virtually construct different types of circuits adjust the | FIGURE 1 NGSS SEP Mathematical and Computational Thinking (NGSS Lead States 2013 Appendix F p 10) Mathematical and computational thinking in 6–8 builds on K–5 experiences and progresses to identifying patterns in large data sets and using mathematical concepts to support explanations and arguments • Use digital tools (eg computers) to analyze extensive data sets for patterns and trends • Use mathematical representations to describe and support scientific conclusions and design solutions • Create algorithms (a series of ordered steps) to solve a problem • Apply mathematical concepts and processes (eg ratio rate percent basic operations simple algebra) to scientific and engineering questions and problems • Use digital tools and mathematical concepts and arguments to test and compare proposed solutions to an engineering design problem 36 TEACHER TO TEACHER number of resistors used and add switches Students studied and measured the current (amps) and voltage (volts) of the following circuits simple (Figure 2) series (Figure 3) parallel (Figure 4) and complex (Figure 5) While building circuits and measuring current and voltage students asked “Why are the charges moving slower in the series circuit than in the parallel circuit?” To determine that the chargers were moving slower students chose to use an ammeter to measure the current of the circuit When the ammeter measured lower amperage on wires where the charges moved slower students were able to observe the current and build a mental model of electric current Alternatively students could work with a physical circuit and set up the series circuit and parallel circuit with light bulbs Students would be able to observe differences in the brightness of the bulbs and make measurements of the voltage and current in each circuit; however the actual movement of charge would be based on a student’s inference Using a computer simulation as a scientific model allows unseen parts of the circuit to be made visual To assess student understanding of series parallel and complex circuits I asked them to build models of a circuit of a flashlight with three bulbs and specific design criteria (Figure 6) In the simulation students had access to a large voltage battery as well as a regular battery While using a 100-V battery is beyond the norm of flashlight batteries allowing students to use the battery forced students to think deeper in constructing a circuit In order to solve the problem created by using a battery too large for a flashlight student needed to add resistors in order for the circuit to properly work (Students set a lot of simulation circuit fires as they worked on solutions) Conclusion Computational thinking is more than using a computer simulation to make observations This lesson required students to “use digital tools and mathematical concepts and arguments to test and compare proposed solutions to an engineering design problem” (NGSS Lead States Appendix F 2013) My students used a simulation to explore their “What if…?” questions when they integrated the high-voltage battery as the energy source for their circuit and created a circuit that meets the requirements of the assessment Furthermore the problem was engineering in nature Students used a simulation to develop and test ideas for how well they met the defined criteria—a process made quicker by using a simulation rather than physical materials The important step in the lesson is for students to understand that the simulation is programmed with algorithms based on data for how a physical circuit works and abstractions that allow students to visualize | FIGURE 2 Simple circuit | FIGURE 3 Series circuit | FIGURE 4 Parallel circuit | FIGURE 5 Complex circuit July 2019 37 TEACHER TO TEACHER | FIGURE 6 Flashlight problem You want to create a flashlight using three bulbs It will be essential to control which lights are turned on (one light two lights or three lights) You can use one or two batteries no more than three switches and as much wire as necessary The flashlight design should maximize the brightness of the bulbs and be on one circuit Use the simulation we have been working with to come up with a circuit design • Screenshots of your final design • A written explanation of your final design • Claim-a statement describing your final design • Evidence-data from investigation that supports your design • Reasoning-connect the evidence to claim by describing the science involved • Data on your final design (voltage and current) the normally unseen portions of the phenomenon • REFERENCES NGSS Lead States 2013 Next Generation Science Standards For states by states Washington DC National Academies Press Sneider C C Stephenson B Schafer and L Flick 2014 Teachers Toolkit Exploring the science framework and NGSS Computational thinking in the science classroom Science Scope 38 (03) 10–15 Yadav A H Hong and C Stephenson 2016 TechTrends (2016) 60 565 RESOURCE Circuit simulation—https//phet coloradoedu/en/simulation/circuitconstruction-kit-dc-virtual-lab Susan German (sgerman@hallsvilleorg) is a science teacher at Hallsville R-IV School District in Hallsville Missouri Grade Level K–5 SIMULATIONS • ASSESSMENTS • VIDEOS Be a Sky Sleuth helps students fi gure out how patterns can be used to predict the positions of the Sun Moon and stars Thinking Beyond English Language Arts Connections Mathematics Connections Differentiated Learning Use activities in the teacher’s guides to implement three-dimensional learning in your classrooms STEM for kids Phenomenon-based three-dimensional learning content that’s designed using the 5E model and incorporates the science and engineering practices (SEPs) crosscutting concepts (CCCs) and disciplinary core ideas (DCIs) Comprehensive teacher’s guides are available Each teacher’s guide provides connections to the grade-level content (including science ELA and mathematics) plus tips and practical information to enhance the e-book experience Use activities in the teacher’s guides to implement three-dimensional learning in your classroom Lexile Level 500L Visit wwwnstaorg/ebooks/GradesK-5 to learn more and order Purchases of 10+ e-books of a single title will include a detailed teacher's guide specifi c to that e-book 38 Reproduced with permission of copyright owner Further reproduction prohibited without permission 
Computational thinking and tinkering Exploration of an early childhood robotics curriculum Marina Umaschi Bers Louise Flannery Elizabeth R Kazakoff Amanda Sullivan Tufts University Medford MA USA article info Article history Received 30 January 2013 Received in revised form 22 October 2013 Accepted 29 October 2013 Keywords Elementary education Interactive learning environments Pedagogical issues Teaching/learning strategies robotics Programming Early childhood abstract By engaging in construction-based robotics activities children as young as four can play to learn a range of concepts The TangibleK Robotics Program paired developmentally appropriate computer programming and robotics tools with a constructionist curriculum designed to engage kindergarten children in learning computational thinking robotics programming and problem-solving This paper documents three kindergarten classrooms’ exposure to computer programming concepts and explores learning outcomes Results point to strengths of the curriculum and areas where further redesign of the curriculum and technologies would be appropriate Overall the study demonstrates that kindergartners were both interested in and able to learn many aspects of robotics programming and computational thinking with the TangibleK curriculum design  2013 Elsevier Ltd All rights reserved 1 Introduction For decades early childhood (preschool to grade two) curricula have focused primarily on literacy and math especially with the educational reforms of No Child Left Behind (Zigler & Bishop-Josef 2006) However there has been some recent attention to science technology engineering and math (STEM) learning for young children (Gelman & Brenneman 2004; Sesame Workshop 2009; White House 2011) Furthermore new technology learning standards and best practices for integrating technology into early childhood education have been developed (Barron et al 2011; International Society for Technology in Education (ISTE) 2007; NAEYC & Fred Rogers Center for Early Learning and Children’s Media 2012; US Department of Education 2010) Of note the technology policy statement from NAEYC & Fred Rogers Center for Early Learning and Children’s Media (2012) provides a guide for early childhood education professionals in using interactive digital technologies in balanced and developmentally appropriate ways It addresses important issues related to using digital technology with children ages three–eight years including the needs for technology use to serve the needs of the children and for educators to be able to understand evaluate and integrate developmentally appropriate technologies in their classrooms However there is little research on computer programming specifically for early childhood the subject this paper explores As new devices from smartphones and tablet computers to electronic learning toys find new audiences with increasingly young children challenging question arise about how to define developmentally appropriate activities and content for children of different ages While the majority of research on robotics and programming in education focuses on later schooling teaching these subjects during foundational early childhood years can be an engaging and rewarding experience for young learners (Bers 2008) Previous research has shown that children as young as four–six years old can build and program simple robotics projects (Bers Ponte Juelich Viera & Schenker 2002 pp 123–145; Cejka Rogers & Portsmore 2006; Kazakoff Sullivan & Bers 2012; Perlman 1976 p 260; Wyeth 2008) as well as learn powerful ideas from engineering technology and computer programming while also building their computational thinking skills (Bers 2008) Robotic manipulatives allow children to develop fine-motor skills and hand–eye coordination while also engaging in collaboration and teamwork Additionally robotics can provide a fun and playful way for teachers to integrate academic content with the creation of  Corresponding author DevTech Research Group Eliot Pearson Department of Child Development 105 College Ave Medford MA 02155 USA Tel þ1 617 347 5746 E-mail address ElizabethKazakoff@Tuftsedu (ER Kazakoff) Contents lists available at ScienceDirect Computers & Education journal homepage wwwelseviercom/locate/compedu 0360-1315/$ – see front matter  2013 Elsevier Ltd All rights reserved http//dxdoiorg/101016/jcompedu201310020 Computers & Education 72 (2014) 145–157 meaningful projects Through robotics young children can experiment with concepts of engineering as well as storytelling by creating narrative contexts for their projects (Bers 2008) By engaging in these types of robotics projects young children play to learn while learning to play in a creative context (Resnick 2003) Computers offer new ways of representing and interacting with information and an entirely new category of “objects to think with” (Papert 1980) In the form of programmable and interactive robots computers can become powerful learning tools Robotics offers children the opportunity to engage with content from the domain of computer science practice problem-solving skills and work on fine-motor skills and eye–hand coordination The TangibleK Robotics Program a design-based research initiative now in its fifth year has paired developmentally appropriate programming and robotics tools with a curriculum to engage kindergartners in learning computational thinking robotics and programming concepts as well as problem-solving and reasoning The goal of this paper is to present young children’s learning outcomes on computer programming concepts as taught through the TangibleK curriculum in order to highlight the potential for learning of integrating computer programming and robotics into the early childhood classroom 11 Theoretical framework constructionism and positive technological development The theoretical approach used for designing the educational intervention and curriculum and for integrating the TangibleK Robotics Program into early childhood classrooms incorporates elements from Papert’s (1980) constructionist framework which states that children can learn deeply when they build their own meaningful projects in a community of learners and reflect carefully on the process Papert’s (1980) constructionism is rooted in Piaget’s (1954) constructivism – which conveys the idea that the child actively builds knowledge through experience – and the related “learn-by-doing” approach to education While Piaget’s (1954) theory was developed to explain how knowledge is constructed in an individual’s mind Papert (1980) expands on it to focus on the ways that internal constructions are supported by constructions in the world including through the use of computers and robotics A constructionist teaching approach provides children the freedom to explore their own interests through technologies (Bers 2008) while investigating domain-specific content learning and also exercising meta-cognitive problem-solving and reasoning skills (eg Clements & Gullo 1984; Clements & Meredith 1992) Papert (1980) discussed that well-designed constructionist activities have embedded in them ‘powerful ideas’ central concepts within a domain that are both epistemological and personally useful interconnected with other disciplines and have roots in intuitive knowledge that a child has internalized over a long period of time (Bers et al 2002; Papert 1980) An idea may be considered powerful to the degree that it is useful in building and extending further knowledge (Papert 2000) The robotics curriculum described in this paper is composed of powerful ideas from the domains of computer science and engineering (eg the engineering design process debugging robotic motion and sensing using programming instructions control flow by sequence control flow by specific instructions) Classroom activities designed to impact learning outcomes and cognitive growth also have an impact on (and are influenced by) children’s social emotional and moral development As a framework to guide the design and implementation of a robotics curriculum that also focuses on these dimensions of the child Bers’ (2010 2012) Positive Technological Development (PTD) was utilized PTD takes into consideration the learning environment and pedagogical practices as well as cultural values and rituals which mediate teaching and learning (Bers 2008; Rogoff Goodman Turkanis & Bartlett 2001) The educational experience proposed by the presented robotics curriculum was structured using the PTD framework to encourage six behaviors which in turn foster the development of beneficial core cognitive and social traits Specifically engaging in content generation creative design and problem-solving collaboration communication choices of conduct and community-building may lead to a sense of competence and confidence the ability to connect with and care about others contribution to entities outside the self and moral character (Bers 2010 2012) For instance by iteratively planning and revising a robotics project in a supportive environment children may gain confidence in their abilities to learn and solve problems Alternatively discussions of how to share limited resources fairly amongst the class are opportunities for positive moral development 12 Learning through computer programming Embedded in the exploration of computer programming and robotics the TangibleK curriculum also fosters computational thinking This term has been defined in many ways and encompasses a broad and somewhat debated range of analytic and problem-solving skills dispositions habits and approaches used in computer science (Barr & Stephenson 2011; International Society for Technology Education and The Computer Science Teachers Association 2011; Lee et al 2011) The TangibleK curriculum specifically fosters computational thinking skills such as problem representation; systematicity in generating and implementing solutions; exploring multiple possible solutions; problem-solving on multiple levels – from approaching the overall challenge to “debugging” or trouble-shooting specific difficulties with a given solution’s implementation; productive attitudes toward “failure” and misconceptions uncovered along the route to a successful project; and strategies for approaching open-ended and often difficult problems Such skills are of general applicability beyond robotics and computational thinking 13 The TangibleK Robotics Program The TangibleK Robotics Program whose design is informed by the theoretical frameworks of constructionism and PTD has iteratively implemented and assessed a set of programming and robotics tools curricula and pedagogical approaches in close collaboration with hundreds of children and dozens of teachers over the course of five years The research goals of the TangibleK Robotics Program are to 1) Provide an evidence-based description of young children’s learning trajectories in computational thinking and capacity to understanding computer programming and robotics concepts when given developmentally appropriate materials 2) Develop and test an early childhood curriculum to teach developmentally appropriate concepts from computer programming and robotics to children in kindergarten through second grade 3) Investigate the design features of the programming interface and the mediating role interface design plays in learning to program 146 MU Bers et al / Computers & Education 72 (2014) 145–157 This paper addresses the first of these goals to describe young children’s learning trajectories in computational thinking and capacity to understand computer programming and robotics concepts This understanding will allow further revision to the TangibleK curriculum The TangibleK Robotics Project makes use of commercially available robotics construction kits and the CHERP (Creative Hybrid Environment for Robotics Programming) language to give behaviors to the robotic constructions (Bers 2008; Bers & Horn 2010; Horn et al 2011; Kazakoff & Bers 2012; Kazakoff Sullivan & Bers 2012) CHERP is a hybrid tangible and graphical computer language designed to provide young children with an engaging introduction to computer programming in a developmentally appropriate way The software allows children to create programs to control their robots from tangible wooden blocks and/or graphical on-screen icons The design of CHERP avoids the technical and syntax-related challenges of text-based programming languages Furthermore the hybrid interface allows children to choose the interface that best suits their changing preferences as physical abilities perceived social appeal and the level of challenge of the activity at hand evolve (Horn et al 2011) because both tangible and graphical interfaces can represent the same concepts The TangibleK curriculum introduces increasingly complex powerful ideas from computer science in a robotics context in a structured developmentally appropriate way The powerful ideas from computer science addressed in this curriculum include the engineering design process and debugging (trouble-shooting) robotic motion and sensing and three aspects of programming choosing the correct programming instructions controlling the flow of actions by sequencing the action instructions accordingly and controlling the flow of actions by using special control flow instructions Section 23 contains more detailed definitions of each powerful idea In addition to the concrete robotics and programming concepts and skills introduced in each activity skills such as observation reflection and decomposition of complex processes are interwoven throughout the curriculum The curriculum which takes approximately 20 h of classroom work includes six structured 60- to 90-min activities and a culminating interdisciplinary project All the activities focus on building and programming a robotic vehicle to accomplish a particular goal Each lesson addresses one or more powerful idea(s) within the context of a narrative theme The six lesson activities and their embedded content are as follows Lesson 1 The Engineering Design Process Children build sturdy non-robotic vehicles to transport toy people on a floor map Children apply the stages of the Engineering Design Process to plan test and improve their vehicles Lesson 2 Robotics Children share and learn ideas about what robots are and are not They explore robotic parts by designing and building their own robots They learn to appropriately connect robotic parts (eg snap-together wires and motors) to make a robot that moves Lesson 3 Choosing and Sequencing Programming Instructions In this activity children program their robots to dance the “Hokey-Pokey” by choosing relevant instructions and putting them in the correct order or sequence Lesson 4 Looping Programs (Control Flow Instructions 1) Children use “repeat” instructions to program their robots to move forward forever Next they program their robot to move forward only a particular number of times to reach a fixed location Lesson 5 Sensors Children use light sensors to program their robots to turn its light on when it is dark out and vice versa They draw comparisons between robotic sensors and the five human senses Lesson 6 Branching Programs (Control Flow Instructions 2) Children are introduced to a pair of conditional control flow instructions “If” and “If Not” which are also used with a sensor to make programs that incorporate environmental conditions into the robot’s behavior In addition to the structured activities described above the TangibleK curriculum includes songs games and free-play with the robotics and programming materials in order to foster a playful learning environment for children For example in Lesson 3 children sing and dance the “Robot Hokey-Pokey” and play Simon Says with the CHERP programming commands to recall and apply the programming instructions Throughout the 20 h curriculum children have ample opportunity to freely build and design with the robotics materials and to create their own CHERP programs beyond those that are set forth in each of the structured lessons After completing the six lessons described above each classroom embarks on a culminating interdisciplinary project which invite children to apply the now familiar powerful ideas to a particular theme or context The teacher decides on a theme drawn from other subjects studied during the year and each child chooses a challenge within this theme Past classrooms have selected topics such as animal behaviors vehicles that help the community or “Who Am I?” Children created projects representing snakes that slither recycling trucks that collect refuse and sewing needles that travel back and forth through fabric among many others The projects allow children to demonstrate the powerful ideas they learned over the six activities as well as to apply them and continue learning about them in a new context Having introduced an overview of the TangibleK Robotics Program including its technological curricular and theoretical components we now present a study of three kindergarten classrooms in which the TangibleK Robotics Program was implemented The following sections report the distribution of achievement scores children attained on selected computer programming concepts and skills tied to the MU Bers et al / Computers & Education 72 (2014) 145–157 147 powerful ideas listed above Achievement scores form the basis on which to discuss the curriculum structure and content and consider the implications for understanding children’s early learning trajectories of computational concepts and for further adaptation of the curriculum 2 Study design Within the design-based research tradition of iterative testing analysis and refinement of an intervention (see eg Cobb Confrey diSessa Lehrer & Schauble 2003) the TangibleK Robotics Program has spent five years exploring what children are capable of learning and accomplishing in the domains of robotics and programming The study described in this paper examines how successfully children learned the core concepts (powerful ideas) of robotics and programming in the TangibleK curriculum The study took place during the fourth year of the overall project following piloting and refinement of the software and curriculum in a range of settings from classrooms and after-school/summer programs to the research lab The extensive testing exploration and refinement of the preceding study iterations also laid a foundation for understanding how young children learn and think about core concepts of programming and robotics For instance several of the curricular activities were simplified to enable better focus on the target concepts; movement games and songs were added to the curriculum to engage children in multiple modes of understanding concepts and to provide reinforcement for basic knowledge In addition some of the programming icons were revised to use more familiar imagery for children 21 Participants Each of the three teachers involved in this study volunteered to participate following email notification of the opportunity to principals of a limited number of schools in the Greater Boston area All children in each classroom participated in the curriculum but each family had the option to allow or decline data collection According to school community needs consent materials were available in English Portuguese and Spanish Children in the study attended one of three Greater Boston area kindergarten classrooms two of which were at a public urban school and one at a private suburban school From a total of 63 children enrolled in the three classes during the study 53 are included in data analysis Children were included in data analysis unless they missed more than one activity or if data was not collectible for more than one activity Attrition was due to typical classroom absences as well as the difficulty of collecting data with limited researchers in a bustling classroom environment Classroom 1 a kindergarten in an independent K-8 religious-based private school in a suburb of Boston MA had 23 children 18 of whom are included in data analysis The student population at this school was 97% White 1% as Asian 1% as Black 1% Hispanic (http//nces edgov/globallocator/) Of the children in the kindergarten class 50% were male and 50% were female They ranged from ages 49 to 62 years at the start of the study with a median age of 56 years The only kindergarten classroom at this school this class was taught by a male teacher with seven years of teaching experience who on a scale from 1 (none) to 5 (expert) rated his computer experience as 5 programming experience as 3 and robotics experience as 1 Classrooms 2 and 3 were located at the same urban K-8 school (NCLB Level 3) located just outside of Boston MA The makeup of this school during the 2010–2011 school year was 389% White 363% Hispanic 162% African American 70% Asian American and 17% multirace The school was comprised of 411% English-Language Learners and 644% of students were classified as low income (Massachusetts Department of Education 2006) A female teacher with six years of teaching experience taught Classroom 2 She rated her computer experience as a 4 robotics experience as a 2 and programming experience as a 2 This classroom had 19 children enrolled 17 of whom are included in the data analysis Of those 17 children 59% were male and 41% were female At the start of the curriculum the children in this classroom ranged in age from 49 to 62 years old with a median age of 56 years A female teacher with 15 years of teaching experience taught Classroom 3 She also rated her computer experience as a 4 robotics experience as a 2 and programming experience as a 2 The data analysis includes 18 of 21 children enrolled in this classroom Of the 18 participants 44% were female and 56% were male The children’s ages at the start of the curriculum in Classroom 3 ranged from 56 to 65 years with a median age of 60 years old The overall age range for the 53 children included in data analysis was 49–65 years and their average age at the start of the curriculum was 57 years old Over the three classrooms as a whole 45% of the children were female and 55% male The participants in this study are thought to be generally representative of the general kindergartners population as the sample includes both public and private school students both male and female teachers a fairly even proportion of male and female students and as described above a diverse range of ethnic and socioeconomic backgrounds particularly at to the participating public school 22 Procedure Each classroom’s head teacher and all research assistants (nearly 20 research collaborators in total) received training to prepare them for teaching or assisting the robotics curriculum and participating in the research and data collection The high number of assistants was needed for two reasons First a low student-to-adult ratio in each lesson ensured adequate observation and documentation of students’ work Secondly most research assistants had limited availability across the full set of study sessions Therefore attention was given to all collaborators’ to ensure they received careful and detailed training The 3-h introductory training covered technical curricular and pedagogical aspects of the program including how to use the CHERP programming language and LEGO robotics kits as well as activity content and training on the structure and the teaching approach framed by the PTD model presented earlier The training also included explanation and examples of how to score children’s work in each activity according to a scale of understanding levels described below The teachers then implemented the TangibleK curriculum in their own classrooms with technical support from trained research assistants Two teachers used the curriculum with the whole class working together The third teacher worked with half of the class at a time finishing the entire curriculum with one group before starting it with the other Each curricular activity took one to two 60–90 min session(s) The teacher introduced key concepts and the day’s activity in a whole-group setting along with a short song or game to reinforce the 148 MU Bers et al / Computers & Education 72 (2014) 145–157 concepts As mentioned earlier in Lesson 3 each class sang and danced the “Hokey-Pokey” before programming their robots to do this dance Additionally the game “Simon Says” was often used in Lessons 3–6 to reinforce the CHERP programming instructions and their corresponding robotic actions After the whole-group activities children built and/or programmed their own robotic vehicles The children worked independently on their projects but sat in groups of four and received support as needed from the research assistant or classroom teacher at their group while also interacting with their peers With the variety of coders evaluating children’s work we systematically accounted for potential intercoder differences by varying which adult worked with which children during each lesson Each session’s work ended with a group discussion for children to share progress questions and successful strategies and for the teacher to help reinforce the core robotics and programming concepts and the engineering design process To assess learning outcomes after each activity research assistants evaluated the robot and/or program made by each child They assessed the child’s level of understanding of selected core concepts as seen by successful application of the concepts in the robot or program If needed they also talked with children to gain more information about their work and understandings By examining for instance the child’s program for correct selection and sequencing of action instructions or proper use of the “repeat” instruction research assistants scored each child’s achievement of the core goals of the lesson using the following 6-point Likert scale designed to document the thoroughness of the child’s understanding and application of activity-specific concepts and skills as well as their use of general problemsolving skills A score of 4 or higher was defined as the target level of achievement 5 Complete achievement of the goal task or understanding 4 Mostly complete achievement of the goal task or understanding; 3 Partially complete achievement of the goal task or understanding; 2 Very incomplete achievement of the goal task or understanding; 1 Did not complete the goal task or understanding; 0 Did not attempt/Other In each lesson children were scored on multiple concepts using this Likert scale For example in Lesson 3 children programmed their robots to dance the “Hokey-Pokey” by 1) choosing the correct instructions (a skill referred to here as correspondence) and 2) putting the instructions in the correct order (sequencing) The concepts of sequencing and correspondence are described in more detail in Sections 232 and 233 As an illustration of the general scale children received one point on the correspondence scale for each programming instruction that correctly matched a line of the song Below are examples of children’s programs that were scored at each level of correspondence in Lesson 3 5 Begin Forward Backward Forward Shake Spin End (all correct); 4 Begin Forward Forward Forward Shake Spin End (second Forward should be Backward); 3 Begin Forward Backward Shake End (missing Forward and Spin); 2 Begin Shake Spin End (missing Forward Backward Forward) 1 Begin Shake End (missing Forward Backward Forward and Spin) 0 Despite assistance and prompting the child did not attempt Hokey-Pokey task These same programs also received a 0–5 score for sequencing in Lesson 3 23 Variables examined To examine children’s growing computational thinking ability throughout implementation of the TangibleK curriculum four key variables were observed and assessed debugging correspondence sequencing and control flow 231 Debugging When faced with a difficult problem or task children (and adults) are often unable to determine a suitable solution on the first attempt In these situations “debugging” skills can be helpful Debugging or trouble-shooting is a form of problem-solving used in the fields of engineering and computer science It encompasses four steps 1) To debug a problem the child must first recognize that something is not working or not meeting the stated goal For example a child programming her robot to dance the Hokey-Pokey in Lesson 3 watches her program running and realizes that the robot does not “shake it all about” 2) In step 2 of the debugging process children either decide to keep their original goal or switch to an appropriate alternative This child might continue to pursue the original plan of making the robot dance all the parts of the Hokey-Pokey or as is common at this age she might come up with an alternative such as having their robot do a different dance 3) The third stage of debugging is generating a hypothesis as to the cause of the problem The child in our example may hypothesize that the program is missing an instruction that would make their robot shake 4) Finally the last aspect of debugging is attempting to solve the problem The child might put a “Shake” block in different positions in the program until the program fully matches the song Debugging skills are not limited to the arena of engineering and computer science Previous research has found that children can acquire and transfer debugging skills to activities outside of the programming context with appropriate support including explicit instruction (Klahr & Carver 1988; Salomon & Perkins 1987) The steps of the debugging process are a critical component of the Engineering Design Process which refers to the cyclical or iterative process engineers use to design an artifact in order to meet a need (Massachusetts Department of Education 2006) As defined by the MA curriculum frameworks its steps include identifying a problem looking for ideas for solutions and choosing one developing a prototype testing improving and sharing solutions with others (see Fig 4) The steps of testing and improving which require debugging are particularly important in establishing a learning environment where failure – rather than immediate success – is expected and seen as necessary for learning With the Engineering Design Process children are not expected to “get it right” the first time MU Bers et al / Computers & Education 72 (2014) 145–157 149 In the TangibleK curriculum debugging and the Engineering Design process were first introduced in Lesson 1 and the concepts and skills were applied throughout the rest of the curriculum Children were assessed on their ability to apply the four core aspects of debugging (described above) in each lesson and final project 232 Correspondences between actions and instructions A program is a sequence of instructions that a computer (in this case a robot) acts out in an order specified by the programmer (Stair & Reynolds 2003) Each instruction has a specific meaning and the order of the instructions leads to the robot’s overall actions Making correspondences between actions and instructions encompasses the understanding that each programming instruction represents a specific action carried out by the robot Another way to understand the process of correspondence is to frame it with the notion of symbols a core concept that children are learning in kindergarten in both math and literacy Each programming instruction is a symbol for the action the robot will carry out In order to program a robot’s behavior children must understand in general that people use symbolic language to communicate with computers and they must select specific instructions to accurately represent their intended outcome for the robot’s behavior Correspondence was first introduced in Lesson 3 of the curriculum when students choose and sequence programming instructions to make a robot dance the Hokey-Pokey Accomplishing this task requires children to identify the corresponding programming instruction for each line of the “Robot Hokey-Pokey” verse/dance For example a child who understands the correspondence between actions and instructions would find the programming instruction block with the “shake” symbol to recreate the line in which the robot “shakes it all about” To measure correspondence children were assessed on how many of the correct instructions they chose 233 Sequencing instructions Sequencing is a component of planning and involves putting objects or actions in the correct order (Zelazo Carter Reznick & Frye 1997) To create a successful program children must use procedural thinking and plan their programs in terms of a sequence of what happens next before or until another action (Pea & Kurland 1984) In both literacy and mathematics sequencing is essential for putting phonemes letters words or elements of a formula in the appropriate order (Neuman & Dickinson 2002) Prior research with the TangibleK project showed that children who participated in the program earned significantly higher scores on a test of story sequencing than children who did not (Kazakoff & Bers 2012; Kazakoff Sullivan & Bers 2012) In this curriculum children were first introduced to the idea of sequencing instructions in Lesson 3’s “Hokey-Pokey” challenge (described above) Sequencing was also a core component of Lessons 4–6 in which children had to properly arrange action instructions and increasingly complex control flow instructions in the correct order to achieve particular outcomes in the robot’s behavior 234 Use of control flow instructions “Control flow” refers to the concept that programmers can control the order in which a robot follows the instructions in its program through various programmatic methods This curriculum introduced children to control flow instructions and parameters Control flow instructions allow the robot to carry out instructions non-sequentially eg in a loop or only under certain conditions For example a CHERP program can include a “Repeat” control flow instruction in the following way “Begin Forward Repeat 3 Shake End-Repeat Sing End” to make the robot shake three times and then sing once With the attachment of a light or touch sensor to the robot sensor parameters can also be used to qualify the control flow instructions based on environmental stimuli For instance a child can program a robot to carry out an action or set of actions only “If (the environment is) Dark” or “If Light” and another set of actions “If Not (Light/Dark)” While there are currently no curriculum frameworks explicitly addressing control flow these activities connect to mathematics by reinforcing number sense and estimation or to natural science by comparing human and animal sensory functions with robot sensors Children are also able to compare and contrast repeating or looping programs to patterns cyclical events in the natural world and calendar time Children were assessed on their correct use of control flow structures in Lessons 4–6 and the final project 3 Results This section presents and compares children’s achievement on programming and debugging concepts and other skills taught using the TangibleK robotics curriculum Since the focus of this work is on computational thinking in a robotic context the assessments presented here evaluate programming concepts instead of robotics knowledge Children’s work in each introductory lesson was assessed for two relevant programming concepts These concepts seven in total were reassessed in the final project Additionally four debugging skills were assessed in all lessons and the final project Each measure uses the Likert scale shown above which ranges from 0 (did not attempt the task) or 1 (did not complete the goal task or understanding) to 5 (completely achieved the goal task or understanding) Analysis was conducted by aggregating scores from all classrooms and using paired-sample t-tests to compare scores on each concept from one lesson to the next Findings are grouped by the powerful idea to which they relate Note that the teacher in Classroom 1 chose not to formally teach Activity 6 so data for that Activity’s items come only from two classrooms A discussion about this choice is provided later in the paper 31 Debugging Average scores on the various debugging measures fell in the range of partial to mostly complete understanding and application of the skill (see Table 1) There was little variation in debugging scores between consecutive activities (see Fig 1) with the exception that the average score on keeping the original goal was higher in Activity 4 than in Activity 5 (marked in Table 1) In other words children’s ability to keep working on the original goal (or choose an acceptable alternative) was higher in activities that did not require the use of sensors and sensor parameters Scores on the other three components of debugging remained steady in the mid-to-upper range of the achievement scale across lessons 150 MU Bers et al / Computers & Education 72 (2014) 145–157 Repeated measures ANOVA analyses (see Table 2) were run for the four debugging skill variables across activities The analyses were run across all seven activities (or in the case of Debugging Skill 1 across the four activities where this skill was assessed) In addition a separate repeated measures ANOVA was run for each debugging skill variable for just Activities 1–5 since once classroom did not participate in Lesson 6 and the project lesson was unstructured Average debugging score did not vary significantly across activities when all lessons were considered However when removing the challenge activity and Lesson 6 where one class did not participate a repeated measures ANOVA for each debugging variable did show a change across time meaning there was perhaps variation in debugging score across the more structure lessons but this variation averaged out when children worked on their own projects 32 Powerful ideas of programming In Activities 3 through 6 and in the culminating project students completed specific programming challenges and were assessed on their ability to select instructions and put them in the order that would result in the goal behavior for the robot Activities 4–6 also used special “control flow” instructions which can tell the robot to loop through a set of actions repeatedly or to follow one “branch” of instructions or another based on sensor data 321 Choosing the correct programming instructions The overall mean score on students’ abilities to choose the correct instructions started off high in Activity 3 Scores then dropped on average over Activities 4 through 6 and returned to starting levels in the project (see Table 3 for detailed means) As mean scores fell to statistically significantly lower levels in Activity 4 and again in Activity 5 the percent of students reaching the target level of achievement also dropped Seventy-six percent of students achieved in the target range on choosing programming instructions in Activity 3 which used only action instructions In Activity 4 which introduced the first of the control flow instructions 70% of children achieved the target level as did only 46% in Activity 5 which added the use of sensors and sensor parameters and 62% in Activity 6 which used a second more challenging type of control flow instruction However 77% of children reached the target level of achievement on their projects – a similar rate to that in Lesson 3 the first activity to require choosing programming instructions (see Fig 2) 322 Control flow by sequencing Sequencing ability was also introduced in Activity 3 along with making correspondences between intended robotic actions and programming instructions when children made their robots dance the “Hokey-Pokey” Three-quarters of all students achieved in the target range in this first programming activity Sequencing was also a core component of Activities 4–6 in which children had to properly arrange Table 1 Student scores on debugging Debugging step 1 Debugging step 2 Debugging step 3 Debugging step 4 N Mean SD N Mean SD N Mean SD N Mean SD Activity 1 43 419 098 45 422 080 42 400 108 43 416 105 Activity 2 48 435 076 49 416 087 46 376 097 46 391 100 Activity 3 31 397 111 39 421 095 33 367 127 34 377 128 Activity 4 43 393 126 44 387 123 43 346 132 43 372 130 Activity 5 30 353 117 36 350 123 27 322 119 30 350 123 Activity 6 27 344 125 28 389 123 26 296 128 27 341 142 Project 28 397 092 29 442 064 27 393 092 26 408 069 Note Classroom 1 did not do Activity 6 Denotes significant differences in the mean scores of the paired items at the p < 005 level For Debugging Step 2 between Activities 4 and 5 t(28) ¼ 204 and p ¼ 005 For Debugging Step 2 between Activity 5 (the last activity completed by all classes) and the project t(19) ¼ 312 and p ¼ 001 For Debugging Step 4 from Activity 5 to the project t(15) ¼ 255 and p ¼ 002 Fig 1 Mean achievement on debugging across Activities Average debugging scores for each activity and project All four debugging components appear to follow a similar trend but only the scores for keeping the original goal and attempting to solve the problem had statistically significant changes MU Bers et al / Computers & Education 72 (2014) 145–157 151 both actions and increasingly complex control flow instructions in the correct order In these activities 59% 53% and 68% of children respectively achieved at the target level Fewer children were able to reach the target level of achievement for sequencing in these activities than in Activity 3 A comparison of mean scores on sequencing from one activity to the next revealed a statistically significant drop between Activities 3 and 4 differentiating programs with actions only from those requiring two-part control instructions as well (see Table 4) As was seen with correspondence scores the average sequencing score on children’s projects was statistically significantly higher than the average score in Activity 5 (see Fig 2) 323 Control flow by special instructions Activities 4–6 each introduced a new control flow instruction for creating looping or branching programs Students on average achieved a “partially” complete understanding of the concepts (see Table 5 for detailed means) Less than 60% of students reached the target (“mostly” complete) level of understanding on all but one of these measures (This degree of understanding was reached by 53% for looping 60% for numeric parameters 54% for sensor parameters 68% for the first half of the conditional statement and 41% for the second half of the conditional statement) There were no differences in average scores found between looping and conditional instructions or comparing the different types of parameters (see Fig 3) The only statistically significant difference in scores was between the two parts of the conditional statement (“If” versus “If Not”) That is children were on average more comfortable making the programming equivalent of the statement “If it’s dark out turn the light on” and less comfortable appending “If not turn the light off” to that first statement 33 Comparison of concepts between activities and projects Differences in children’s achievement on each of the above concepts from the introductory activities to the culminating projects were examined in two ways First children’s scores from Activity 5 (the last activity completed by all classes) were compared to children’s scores on the final project This continued the comparison of scores on consecutive activities Secondly scores from the first activity that introduced a particular concept were compared to corresponding scores from the final project For example sequencing scores from Activity 3 (the first activity using that concept) were compared to sequencing scores on the final project This comparison was done to address how children’s scores on the same concepts might change with time and exposure We should note that due to the self-selected nature of the final projects not all children employed every concept to complete them so n is relatively lower on these comparisons There were some statistically significant increases in scores from the final introductory activity completed by all classrooms to the culminating projects were seen on two overarching programming concepts choosing the correct instructions (see Table 3) and sequencing the instructions to accomplish the goal (see Table 4) as well as on two elements of debugging (see Table 1) sticking with the original goal or choosing an acceptable alternative and taking steps to attempt to solve the problem In fact after these scores had dropped over the course of the activities they returned to starting levels in the final projects (as described in the relevant sections above) Table 2 Repeated measures ANOVAs by debugging steps A repeated measures ANOVA was conducted to see if there was a significant difference in means of debugging level over time All possible activities Without Lesson 6 or project df F p df F p Debugging Step 1 Sphericity Assumed (4 16) 1559 023 (2 50) 5122 001 Debugging Step 2 Greenhouse-Geisser Correction (2 4) 5740 007 (3 68) 5157 000 Debugging Step 3 Greenhouse-Geisser Correction (2 4) 4586 010 Sphericity Assumed (4 84) 9192 000 Debugging Step 4 Greenhouse-Geisser Correction (1 3) 2682 023 Sphericity Assumed (4 88) 6404 000 Notes Classroom 1 did not do Activity 6 The Project was open-ended (children could choose to use less difficult blocks) Denotes significance at the p < 001 level Table 3 Student scores on selecting programming instructions Selecting instructions Comparison to subsequent activity N Mean SD Activity df t p Activity 3 45 424 107 – –– – Activity 4 50 388 104 3 42 247 02 Activity 5 41 334 120 4 38 277 01 Activity 6 34 365 130 5 25 073 047 Project 48 415 092 6 29 119 025 5a 35 312 00 Note Classroom 1 did not do Activity 6 Denotes significance at the p < 001 level; Denotes significance at the p < 005 level a This comparison was made as an alternative to the Activity 6-to-Project comparison as it was the last activity completed by all three classrooms prior to the project 152 MU Bers et al / Computers & Education 72 (2014) 145–157 It was anticipated that the children’s scores on the same concepts might increase with exposure so comparisons were made between children’s score on a concept in the activity that introduced it and the score on that same concept in the final project However there were no statistically significant differences seen in any such comparisons (see Table 6) In summary many children in each class reached the target level of achievement on the programming tasks over the course of the curriculum’s six activities and culminating project In the first three activities which introduced the engineering design process robotics and programming children’s levels of achievement were particularly high (75% on average reaching target level of achievement) In Activities 4–6 which introduced more sophisticated concepts and programming instructions fewer children (56% on average) attained the same level of understanding Many children achieved high scores on properly selecting and sequencing instructions when the programming activities involved only action instructions (w75% for both skills) and in the final projects Achievement was comparatively lower in activities which involved the conceptually and functionally more complicated control flow instructions and/or sensors (59% for both skills) Programs that use special control flow instructions visually appear linear but the robot does not carry out one action per programming block as it does with a program containing only actions instructions; the logical flow of the program may be a loop or forked path rather than a line This introduces a conceptual complexity to programming with control flow instructions that does not exist with action instructions alone Similarly it appears based on relative scores that using the “If” instruction was simpler than using the “If Not” instruction (68% versus 41% target achievement) The complexity of each programming concept appears to be reflected in the portion of students who reached target levels of understanding 4 Discussion The results provide critical information on the accessibility of selected concepts from the fields of robotics and computer science for kindergarten children adding clarity to developmentally appropriate learning expectations in order to revise and improve both the curricular activities and design features for early childhood robotics and programming technologies The results also shed light on some of the challenges of conducting design-based research in a classroom setting One interesting feature of the results is the trend of decreasing achievement scores across Lessons 3–6 This is possibly related to the amount of time spent on each topic Each activity in the curriculum introduced a progressively more challenging concept than the activity before it In the later lessons children were asked to build on concepts they had only recently learned While each lesson was carefully designed to teach a particular topic and provide a space for exploration of it these concepts may not have been fully ingrained or mastered yet while new material was introduced This could also help explain lower scores in the later lessons Another interesting result relates to the several concepts for which children’s average achievement scores increased from the final introductory lesson to the culminating project With statistical significance children averaged higher scores on choosing and sequencing Fig 2 Mean achievement on choosing and sequencing instructions average scores for choosing and sequencing programming instructions according to the goal The dip on both choosing instructions (marked with ) and sequencing them (marked with þ) at Activity 5 represents significantly lower scores as compared to Activity 4 and the Project The drop in score for choosing instructions at Activity 4 is also statistically significant Table 4 Student scores on using sequencing for control flow Sequencing instructions Comparison to subsequent activity N Mean SD Activity df t p Activity 3 49 423 116 – –– – Activity 4 40 369 114 3 41 279 01 Activity 5 40 350 120 4 38 107 030 Activity 6 34 374 119 5 25 053 060 Project 49 408 104 6 30 025 080 5a 35 214 04 Note Classroom 1 did not do Activity 6 Denotes significance at the p < 001 level; Denotes significance at the p < 005 level a This comparison was made as an alternative to the Activity 6-to-Project comparison as it was the last activity completed by all three classrooms prior to the project MU Bers et al / Computers & Education 72 (2014) 145–157 153 instructions during the final project than in any introductory activity except the first (and simplest) programming activity While assistant from adults remained stable throughout all aspects of the curriculum and final projects some other circumstances were different in the project compared to the lessons The improved scores might be attributed to the fact that children had more enthusiasm for these personally-selected projects that would soon be part of a show-and-tell celebration as well as more time to experiment at their own pace than in the lessons Alternatively assuming children chose projects well-matched to their level of expertise it would be reasonable to expect higher demonstrated levels of achievement as their projects likely focused on concepts children already felt more comfortable using However there were no statistically significant differences seen in comparisons of control flow instruction and sensor-related measures between the activity that introduced each concept and the culminating project It is possible that even more time exploring these concepts was needed for significant learning gains to occur Surprisingly children did not always perform better on simpler concepts than on more complex ones For example the lack of statistically significant differences between children’s understanding of looping versus conditional programs and between numeric versus sensor parameters is unexpected both theoretically and based on anecdotal observations of these activities by researchers present during the activities The concepts associated with looping and numeric parameters should in principle be more straightforward than those involved in programming with conditional statements and sensor parameters Thus at least somewhat higher levels of achievement on looping and numeric parameters had been expected compared to conditional statements and sensor parameters In some of the comparisons described above the low n (less than half the overall study sample size) may have impacted the results The statistically significant findings may have varied if for instance the students for whom researchers could not collect data tended to have above- or below-average achievement levels As the activities in the curriculum increased in difficulty the research assistants tended to provide increased support for children with questions leaving less time to equally observe and assess all children In fact it was also observed that some children who perceived an activity to be difficult refrained from attempting it resulting in no achievement scores for that activity and a lower n on those measures 41 Curriculum discussion While it is beyond the scope of this paper to fully evaluate the TangibleK robotics curriculum results indicate that the curriculum was generally engaging and developmentally appropriate for kindergarten students Results point to kindergarten teachers being able to effectively implement the curriculum and to kindergartners being both interested in and able to learn and apply many aspects of robotics programming and computational thinking However the fact that fewer children achieved the target level of understanding on more complex topics than on the introductory concepts might indicate that the curriculum should devote more time for children to build up to and fully explore the complex material in order to fully understand it In order to test this a new iteration of the curriculum is currently Table 5 Student scores on using special instructions for control flow Control flow instructions Comparison to analogous concept N Mean SD Concept df t p Looping instruction 49 361 117 – –– – Numeric parameters 50 376 117 – –– – Sensor parameters 41 359 112 Numeric parameters 38 087 042 Conditional (If) 34 374 124 Looping instruction 31 000 100 Conditional (If Not) 22 332 121 Conditional (If) 20 217 04 Looping instruction 19 065 053 Note Classroom 1 did not use conditional statements Denotes a statistically significant difference at the p < 005 level Fig 3 Mean achievement on control flow concepts A comparison of average scores for the different types of control flow instructions and parameters The only significant difference in scores was between the two conditional instructions (marked with ) 154 MU Bers et al / Computers & Education 72 (2014) 145–157 being developed that will divide the prior curriculum based on action and sensing and expand the number of lessons and amount of time spent exploring each topic (particularly the more complex ones) in both structured and free-play-based formats to provide further opportunities for students’ investigation of concepts and to reinforce their learning Additional supporting activities will also be added Kindergarteners vary widely in their levels of cognitive development and learning abilities and such adaptations to the TangibleK curriculum may address this range even more than the current format already does The results also demonstrate the complexity of assessing sophisticated learning processes in a classroom setting There was a necessary trade-off built into the study design gathering an adequately detailed picture of children’s learning had to be balanced with keeping data collection feasible given that each adult was working with several children in the context of a full classroom In some cases (particularly the later activities) a different setting such as individual-child sessions may have provided a better context for some students to demonstrate their abilities However the goal of the study was to examine the TangibleK program in a typical kindergarten classroom and this endeavor was successful Although ultimately some data could not be collected from every student on every measure information was gathered about the reality of implementing the curriculum in classroom settings and the supports necessary to meet the needs of all students 42 Limitations of the study and future directions The TangibleK curriculum was taught during regular school hours in three schools in the Greater Boston area There were both benefits and drawbacks to conducting research in a school setting rather than an experimental setting By testing the curriculum as taught by kindergarten teachers in both public and private schools we have demonstrated that given professional development in robotics education a dedicated teacher can successfully teach this content in her or his own classroom However as with any study that takes place in a school setting the present study faced several environmental limitations While each of the participating teachers taught the same curriculum it is impossible to control for all teacher classroom and school variations that may have influenced results For example the three teachers in this study were very different from one another While some teachers allowed their class to work through difficult concepts on their own others gave more step-by-step instructions Teachers were given leeway to teach the curriculum in whatever way they believed best suited the needs of their classrooms however this causes methodological issues for data analysis Further research should be conducted with a focus on how teaching styles and classroom culture serve to enhance or hinder a robotics curriculum Fig 4 An illustration of the engineering design process Table 6 Students scores on concepts in culmination project Project scores Comparison to introductory activity N Mean SD % Scoring 4þ Activity df t p Choosing instructions 48 415 092 770 3 40 070 049 Sequencing 49 408 104 735 3 40 078 044 Repeats 40 375 126 625 4 36 077 045 Numeric parameters 32 394 122 656 4 30 077 045 Sensors 18 405 073 834 5 15 094 036 Sensor parameters 20 390 085 700 5 17 036 073 Ifsa 14 357 080 786 6 (If) 13 027 079 Note Classroom 1 did not do Activity 6 a There was no separate measure for using “If Not” instructions in the projects MU Bers et al / Computers & Education 72 (2014) 145–157 155 Another drawback the study encountered was a fluctuating number of daily participants Children were fairly regularly absent temporarily out of the classroom or otherwise unable to participate in the class Other times the busy classroom and divided adult attention prevented assessments from being collected for all children particularly if an assessment required long and sustained periods of observation Teacher differences also impacted the low number of participants in some activities For example one teacher chose not to teach Lesson 6 in order to have more time to review previous concepts before the final project drastically lowering the n for that lesson Further research should be done expanding the scope of this study by gathering more participants and if possible ensuring more consistent completion of each activity The present study inspires additional research agendas While the focus of this work is on kindergartners further investigations should look at the way younger (PreK-K) and older (1st–2nd grade) students are able to learn and apply the same powerful ideas It would be important to determine whether some of the concepts that were particularly challenging to the kindergartners in this study pose less of a challenge with longer exposure or if introduced when children are older Further research will also expand the overall sample size as well as the age and experience range of the sample Other work should attempt to assess the feasibility of implementing this curriculum for a classroom teacher with typical support staff that is with minimal involvement of research assistants except for training teachers and conducting data collection In the present research participating teachers each had about three trained assistants in the classroom to help troubleshoot technology issues assess the children’s progress and provide one-on-one help as needed For this curriculum to become widespread it will be necessary to know more about what supports teachers need (modifications to the curriculum classroom management alternatives additional adult support etc) to successfully implement the curriculum Finally it is beyond the scope of this current study but a follow-up study could look at longitudinal or transfer effects of the TangibleK curriculum What concepts do the students retain? How is computational thinking having an impact in other areas of their academic and extra-curricular lives? Are children able to apply the engineering design process to other subject areas after completing this curriculum? Further research should look at the long-term benefits of incorporating programming and robotics into early childhood education It is important to note that many of the challenges that arose as part of the present study were posed by the robotics hardware itself and not the curricular activities This highlights the importance of making developmentally appropriate hardware and software specifically designed for young children Results show that for the children in this study correctly connecting robotic parts proved more challenging than understanding the function of each part or the underlying computational concept This result is not surprising since the CHERP programming interface and the curricular activities introducing the robot’s parts and their purposes were specifically developed for kindergartners as part of this research project while the robotics kit hardware was designed for older children as part of a commercially available LEGO product Furthermore children spent a significant amount of time fixing their robots which came apart frequently It was challenging for many children to assemble some of the pieces on their own and they needed adult help If children had spent the robot repair time working on their computer programs instead (and if teachers were able to spend that time providing support for learning the central concepts rather than helping re-build robots) perhaps children would have attained higher levels of achievement in their understanding of complex powerful ideas involved in computational thinking The findings from this study have informed the TangibleK Project in which early childhood teachers (pre-kindergarten through 2nd grade) will systematically implement a robotics curriculum revised according to several of the points outlined above The teachers will document their experiences and their students’ learning outcomes over the course of a school year using KIWI a developmentally appropriate robotics hardware that will replace the LEGO hardware used in this current study Despite the limitations of the study described in this paper post-study data collected from the teachers speaks to the success of the TangibleK Robotics program All the teachers said they would participate in TangibleK again if given the chance Along with the general success and enthusiasm of the children this feedback highlights the overall positive and educational nature of the experience 5 Conclusion The early childhood classroom is not typically a place where we expect to find students programming robots Yet with the availability of developmentally appropriate technologies this is increasingly possible and the result may be the advancement of technological fluency in our nation’s youth This paper explored the TangibleK Robotics Program as a viable option for classroom teachers to integrate developmentally appropriate technology education into the early childhood classroom With CHERP children spend their time building a robot planning its actions using physical wooden block or the computer screen to construct programs and iteratively improving the robot and programs according to initial goals and subsequent discoveries Because the tangible programs and robots exist off-screen children are drawn to investigate the work of other children work collaboratively and negotiate sharing materials as well as develop their fine-motor skills These artifacts serve as points of discussion and reminders of the activity content even after the computer has been turned off As the analysis presented in this paper has explored in this rich process of creation in both the physical and digital worlds children actively engage in problem-solving and learn powerful ideas from computer science and robotics including core concepts of computational thinking Research is essential to understanding the impact of new technologies on the development of children and how children are using and could be using these tools As parents educators policymakers and researchers it is our responsibility to ensure our children receive the technological education needed for healthy development and a successful future The TangibleK Robotics Program introduced in this paper shows that when given age-appropriate technologies curriculum and pedagogies young children can actively engage in learning from computer programming as applied to the field of robotics They can then take their first steps into developing computational thinking Acknowledgments The TangibleK project was supported by National Science Foundation (NSF) DRL-0735657 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation The authors would like to thank participating schools and teachers for their commitment to and participation in this project 156 MU Bers et al / Computers & Education 72 (2014) 145–157 References Barron B Cayton-Hodges G Bofferding L Copple C Darling-Hammond L & Levine M (2011) Take a giant step A blueprint for teaching children in a digital age New York The Joan Ganz Cooney Center at Sesame Workshop Barr V & Stephenson C (2011) Bringing computational thinking to K-12 what is involved and what is the role of the computer science education community? ACM Inroads 2(1) 48–54 http//dxdoiorg/101145/19298871929905 Bers M U (2008) Blocks robots and computers Learning about technology in early childhood New York Teacher’s College Press Bers M U (2010) Beyond computer literacy supporting youth’s positive development through technology New Directions for Youth Development 128 13–23 Bers M U (2012) Designing digital experiences for positive youth development From playpen to playground Oxford University Press Bers M U & Horn M S (2010) Tangible programming in early childhood revisiting developmental assumptions through new technologies In I R Berson & M J Berson (Eds) High-tech tots Childhood in a digital world (pp 49–70) Greenwich CT Information Age Publishing Bers M U Ponte I Juelich K Viera A & Schenker J (2002) Teachers as designers Integrating robotics into early childhood education Information Technology in Childhood Education Cejka E Rogers C & Portsmore M (2006) Kindergarten robotics using robotics to motivate math science and engineering literacy in elementary school International Journal of Engineering Education 22(4) 711–722 Clements D H & Gullo D F (1984) Effects of computer programming on young children’s cognition Journal of Educational Psychology 76(6) 1051–1058 http//dxdoiorg/ 101037/0022-06637661051 Clements D H & Meredith J S (1992) Research on logo effects and efficacy Retrieved from http//elmediamitedu/logo-foundation/pubs/papers/research_logohtml Cobb P Confrey J diSessa A Lehrer R & Schauble L (2003) Design experiments in educational research Educational Researcher 32(1) 9–13 Gelman R & Brenneman K (2004) Science learning pathways for young children Early Childhood Research Quarterly (Special Issue on Early Learning in Math and Science) 19(1) 150–158 Horn M S Davis P Hubbard A Keifert D Leong Z A & Olson I C (June 2011) Learning sustainability children learning and the next generation eco-feedback technology In Proc 10th international conference on interaction design and children (short paper) Ann Arbor MI International Society for Technology in Education (2007) NETS for students 2007 profiles Washington DC ISTE Retrieved from wwwisteorg/standards/nets-for-students/ nets-for-students-2007-profilesaspx#PK-2 International Society for Technology in Education and The Computer Science Teachers Association (2011) Operational definition of computational thinking for K-12 thinkingoperational-definition-flyerpdf International Society for Technology in Education and The Computer Science Teachers Association Kazakoff E & Bers M (2012) Programming in a robotics context in the kindergarten classroom the impact on sequencing skills Journal of Educational Multimedia and Hypermedia 21(4) 371–391 Kazakoff E Sullivan A & Bers M (2012) The effect of a classroom-based intensive robotics and programming workshop on sequencing ability in early childhood Early Childhood Education Journal 41(4) 245–255 Klahr D & Carver S (1988) Cognitive objectives in a LOGO debugging curriculum instruction learning and transfer Cognitive Psychology 20 362–404 Lee I Martin F Denner J Coulter B Allan W Erickson J et al (2011) Computational thinking for youth in practice ACM Inroads 2(1) 32–37 Massachusetts Department of Education (2006) Massachusetts science and technology/engineering curriculum framework Retrieved from Massachusetts Department of Education http//wwwdoemassedu/frameworks/scitech/1006pdf NAEYC & Fred Rogers Center for Early Learning and Children’s Media (2012) Technology and interactive media as tools in early childhood programs serving children from birth through age 8 Joint position statement Washington DC NAEYC Latrobe PA Fred Rogers Center for Early Learning at Saint Vincent College Retrieved from wwwnaeyc org/files/naeyc/file/positions/PS_technology_WEB2pdf Neuman S B & Dickinson D K (Eds) (2002) Handbook of early literacy research New York Guilford Press Papert S (1980) Mindstorms Children computers and powerful ideas New York Basic Books Papert S (2000) What’s the big idea? Toward a pedagogy of idea power IBM Systems Journal 39(3 & 4) 720–729 http//dxdoiorg/101147/sj3930720 Pea R D & Kurland D M (1984) On the cognitive effects of learning computer programming New Ideas in Psychology 2(2) 137–168 http//dxdoiorg/101016/0732- 118X(84)90018-7 Perlman R (1976) Using computer technology to provide a creative learning environment for preschool children Logo memo no 24 Cambridge MA MIT Artificial Intelligence Laboratory Publications Piaget J (1954) The construction of reality in the child New York Basic Books Resnick M (2003) Playful learning and creative societies Education Update 8(6) Retrieved from http//webmediamitedu/wmres/papers/education-updatepdf Rogoff B Goodman Turkanis C & Bartlett L (2001) Learning together Children and adults in a school community New York NY Oxford University Press Salomon G & Perkins D N (1987) Transfer of cognitive skills from programming when and how? Journal of Educational Computing Research 3 149–169 Sesame Workshop (2009) Sesame workshop and the PNC Foundation join White House effort on STEM education Retrieved from http//wwwsesameworkshoporg/ newsandevents/pressreleases/stemeducation_11212009 Stair R M & Reynolds G W (2003) Principles of information systems (6th ed) Boston MA Course Technology – ITP US Department of Education Office of Educational Technology (2010) Transforming American education Learning powered by technology Washington DC US Department of Education Office of Educational Technology Retrieved from http//wwwedgov/technology/netp-2010 White House (2011) Educate to innovate Retrieved from http//wwwwhitehousegov/issues/education/educate-innovate Wyeth P (2008) How young children learn to program with sensor action and logic blocks International Journal of the Learning Sciences 17(4) 517–550 Zelazo P D Carter A Reznick J S & Frye D (1997) Early development of executive function a problem-solving framework Review of General Psychology 1(2) 198–226 Zigler E F & Bishop-Josef S J (2006) The cognitive child vs the whole child lessons form 40 years of Head Start In D G Singer R M Golinkoff & K Hirsh-Pasek (Eds) Play ¼ learning How play motivates and enhances children’s cognitive and social-emotional growth (pp 15–35) New York NY Oxford University Press MU Bers et al / Computers & Education 72 (2014) 145–157 157 
Computers in Human Behavior xxx (xxxx) xxx Please cite this article as Charoula Angeli Michail Giannakos Computers in Human Behavior https//doiorg/101016/jchb2019106185 Available online 1 November 2019 0747-5632/© 2019 Elsevier Ltd All rights reserved Computational thinking education Issues and challenges ARTICLE INFO Keywords Computational thinking Digital competences Coding Technological fluency Algorithmic thinking Robotics ABSTRACT Computational Thinking is a term applied to describe the increasing attention on students’ knowledge development about designing computational solutions to problems algorithmic thinking and coding It focuses on skills children develop from practicing programming and algorithms and enables the development of qualities such as abstract thinking problem solving pattern recognition and logical reasoning Contemporary educational and infrastructural developments like “CS for All” (https//wwwcsforallorg/) ISTE’s Standards for Students in Computational Thinking (https//wwwisteorg/explore/Solutions/Computational-thinking-for-all?article id¼152) Computer Science Teachers Association’s Concepts of Computational Thinking (http//advocatecst eachersorg/2014/09/15/computational-thinking-and-beyond/) and the appearance of tools such as robotics 3D printing microprocessors and intuitive programming languages posit Computational Thinking as a very promising area to support these learning competences In this special issue of Computers in Human Behavior the Editors report four studies conducted by interdisciplinary teams The introduction to the special issue also draws attention to the great potential and need for further research in the area of Computational Thinking Education to engage students in meaningful learning so as to develop useful thinking skills and digital competences Finally the Editorspropose directions for future research and practice in Computational Thinking Education 1 Introduction Computational Thinking (CT) a term used since the 1950s describes the notion of using structured thinking or algorithmic thinking to produce appropriate output to a given input (Denning 2009) Recent efforts to revitalize the importance of CT aim at democratizing computing knowledge as an important body of knowledge that learners need to have in order to cope well with the challenges of the 21st century In 2006 Wing relaunched the term and interest in the area by defining CT as a process that involves solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science (Wing 2006) This definition has been adopted widely due to its generic nature but also created a need for a more specific definition that can be used in CT Education (CSTA & ISTE 2011; Selby & Woollard 2014) During the last years there has been an increasing interest about CT Education in K-12 schools and its role in children’s acquisition of thinking skills and digital competences In accordance with this need computational thinking and coding have in recent years become an integral part of school curricula in many countries Estonia Israel Finland and the United Kingdom are only a few examples of the growing efforts of governments to integrate coding as a new literacy and to support students in creative problem-solving tasks (Hubwieser Giannakos Berges Brinda Diethelm Magenheim & Jasute 2015) In addition Computer Science Teachers Association (CSTA 2011) International Society for Technology in Education (CSTA & ISTE 2011) Cyber Innovation Center (https//cyberinnovationcenterorg/) and National Math and Science Initiative (https//wwwnmsorg/) have developed conceptual guidelines for CT Education Similarly organizations such as “codeacademycom” offer learning environments to promote coding activities and CT Education While it is well accepted in the literature that CT involves a number of skills like problem decomposition (breaking down complex problems to simpler ones) developing algorithms (step-by-step solutions to problems) and abstraction there is still limited evidence around the several issues and challenges someone needs to be aware of in order to design appropriate learning experiences for CT competences In the issue herein the Editors present four research studies covering different aspects of CT research and discuss challenges for both research and practice in CT Education as well as raising important new research questions for the researchers in the field 2 The contributions in the special issue While CT is an area of growing significance scholarly work on CT is emerging both conceptually and empirically In response to the need for accelerating research foundations and developments in CT Education Computers in Human Behavior presents a special issue that disseminates the latest research findings The special issue consists of four contributions addressing the topic of CT from different perspectives and disciplinary backgrounds as well as covering different research areas and needs The articles provide insights about a) the importance of metaphors in CT education b) putting into practice CT activities to empower both girls and boys c) the importance of employing empirical Contents lists available at ScienceDirect Computers in Human Behavior journal homepage http//wwwelseviercom/locate/comphumbeh https//doiorg/101016/jchb2019106185 Computers in Human Behavior xxx (xxxx) xxx 2 experimentation in furthering CT Education research and d) the development of young children’s CT skills using scaffolds and educational robotics 21 Embodied metaphors for computing education In the first article Manches McKenna Rajendran and Robertson (2019 this issue) investigated elementary computing concepts using metaphors through the lens of Embodied Cognition A metaphor is a figure of speech that describes an object or action that is not literally true but helps to explain an idea or make a comparison Conceptual metaphors are extremely important in learning sciences (eg energy transfer thermodynamics and mathematics) as they offer an explanation of our ability to think and reason about abstract concepts Manches et al’s analysis showed that participants drew upon two overarching embodied metaphors in their explanations namely a) computing constructs as physical objects in which participants simulated manipulating physical objects (eg pinching) when referring to a range of computing concepts and b) computing processes as motions along a path whereby participants moved their hands along one of three body-based axes when referring to temporal sequences The authors concluded that embodiment might shape students and teachers’ CT understanding and learning In addition there may well be other examples of integrated metaphors that can be used to communicate the meaning of the construct of CT and such representations will allow us to better support CT teaching and learning techniques as well as the development of technologies and interfaces (eg embodied interfaces and interactions) for the teaching of CT 22 The use of metaphors to introduce children to programming The second article by P�erez-Marín Hijon-Neira � Bacelo and Pizarro (2019 this issue) further expanded on this notion of using metaphors to teach CT within the context of computer programming The authors put into practice a methodology called MECOPROG using metaphors such as recipe/program pantry/memory and boxes/variables to teach programming following an empirical experiment with 132 primary education students between 9 and 12 years of age Their findings validated that coupling the use of metaphors with a block-based programming environment (eg Scratch) has the potential to improve CT knowledge acquisition in primary education 23 Learning strategies as a pathway for fostering CT In the third study Papavlasopoulou Sharma and Giannakos (2019 this issue) designed and evaluated a workshop for K-12 students to learn how to code The design and development of activities that successfully scaffolded CT concepts and motivated both boys and girls proved to be critical for the teaching and learning of CT skills In this study the goal was to examine differences between boys and girls (if any) using eye-tracking as an objective measure and triangulating the findings with qualitative data coming from children’s interviews The results of their study showed no statistically significant difference between girls’ and boys’ gaze and learning gain during the CT activity Interestingly the qualitative data showed differences in the strategies and implemented practices during coding and in perceptions about those CT activities The results provided objective evidence that female students did not lack in competences or behavior (based on their gaze data) compared to boys but simply that they had a different approach/strategy during CT activities and different perspectives about coding Thus it’s important if this approach is taken into consideration during the design of CT activities and assist girls in mastering CT concepts 24 Children’s computational thinking with educational robotics an interaction effect between gender and scaffolding strategy The fourth study by Angeli and Valanides (2019 this issue) examined the effects of learning with Bee-Bot a floor programmable robot on young boys’ and girls’ computational thinking It was hypothesized that scaffolding would play a significant role in the development of children’s computational thinking skills during learning with Bee-Bot because Bee-Bot does not provide a visual representation of the commands children use to program it The two scaffolding techniques were designed taking into consideration gender differences anticipating that both genders would benefit from at least one of the two techniques The results showed statistically significant learning gains between the initial and final assessment of children’s computational thinking skills Also according to the findings while both boys and girls benefited from the scaffolding techniques a statistically significant interaction effect was detected between gender and scaffolding strategy showing that boys benefited more from the individualistic kinesthetic spatially-oriented and manipulative-based activity with the cards while girls benefited more from the collaborative writing activity The research contributes to the body of knowledge that can be used to inform the teaching of computational thinking skills In addition the study has practical significance for curriculum developers instructional leaders and classroom teachers as they can use the results of this study to design curricula and classroom activities with a focus on the broader set of computational thinking skills and not only coding 3 Challenges in Computational Thinking Education future research directions The findings from the studies suggest that in order to adopt CT as a powerful educational concept researchers need to invest further systematic research efforts in addressing several issues related to 31 Defining CT competencies for each school grade level or students’ developmental level As the contributors in this special issue discussed efforts have been made to define competencies guidelines and curricula for CT (eg CSTA ISTE) What is currently missing from the literature is how CT skills such as abstraction problem decomposition and data structures Fig 1 A five-step research plan for CT Education C Angeli and M Giannakos Computers in Human Behavior xxx (xxxx) xxx 3 might map to different abilities grade level disciplines gender and educational level Thus further work is needed in order to solve inconsistencies (Denning 2017) and to develop and validate a robust theoretical conceptualization about the construct of CT 32 The use of metaphors in teaching CT concepts efficiently and effectively According to Manches et al (2019 this issue) and P�erez-Marín et al (2019 this issue) the use of learner-centered metaphors enhance students’ understanding and learning of CT concepts While this special issue provides preliminary evidence about the importance of metaphors in teaching and understanding CT more research is needed in order to create more metaphors that can be used effectively in teaching students and teachers about CT concepts 33 The use of pedagogical strategies and technologies in teaching CT The articles by Papavlasopoulou et al (2019 this issue) and Angeli and Valanides (2019 this issue) point to the need to scaffold students’ learning during their engagement with CT activities and the importance of alignment between teaching activity and gender Considering the fact that more and more student-friendly programming environments (eg Alice Scratch BlueJay Greenfoot Kodu) hardware materials (3D printers educational robotics) and other initiatives (eg code org codeacademycom) appear as means to promote CT Education future research needs to be undertaken to investigate the interrelationship between CT skills and competencies CT representations CT activities CT tools and CT teaching practices 34 Teacher CT professional development For CT education to further develop teachers need to be systematically prepared in terms of how to design CT learning activities how to teach CT how to assess CT and how to use technologies to teach CT concepts Thus teacher professional development programs need to be implemented for in-service teachers while at the same time teacher educators need to find ways to integrate the teaching of CT in their preservice courses for the better preparation of pre-service teachers 35 Assessment of CT competencies and skills Lastly as the articles in this special issue mentioned the assessment of CT skills and competencies is well under-developed Thus there is a need for future research to identify ways about how CT can be assessed either as a holistic measure or as an array of sub-skills within the context of authentic problem-solving across all subjects and disciplines Accordingly Fig 1 presents a five-step plan about how these five research areas can be addressed in future research studies The five-step plan is presented as a cycle because it is expected that through intense research and practice progress in each area will inform one another and evolve over time The first step tackles the definition of CT competencies in order to provide a baseline and common language across different contexts (eg different countries educational levels school subjects disciplines etc) about the concept of CT The next step is that of creating powerful metaphors as a mechanism for transforming abstract CT concepts to more concrete and easier notions to understand The third step is to research the effectiveness of pedagogies and technologies in enhancing and enabling the development of CT competencies The fourth step focuses on the crucial issue of preparing teachers and instructors to teach CT as well as integrate appropriate technological tools to enable the teaching of CT in their respective teaching contexts Lastly the fifth step deals with the measurement and assessment of CT competencies an area of research that is currently in its infancy Acknowledgements We would like to thank the reviewers of this special issue for their timely reviews and the Commissioning Editor of Computers in Human Behavior Paul A Kirschner for his ongoing support and guidance during the preparation of the special issue This work was partly supported by the COMnPLAY-Science project under the European Commission’s Horizon 2020 SwafS-11-2017 Program (Project Number 787476) References Angeli C & Valanides N (2019) Developing young children’s computational thinking with educational robotics An interaction effect between gender and scaffolding strategy Computers in Human Behavior CSTA & ISTE (2011) Operational definition of computational thinking for K-12 education Available at https//idisteorg/docs/ct-documents/computational-thinkingoperational-definition-flyerpdf CSTA (2011) Operational definition of computational thinking Available at http//wwwcstaacmorg/Curriculum/sub/CurrFiles/CompThinkingFlyerpdf Denning P J (2009) Beyond computational thinking Communications of the ACM 52 (6) 28–30 Denning P J (2017) Remaining trouble spots with computational thinking Communications of the ACM 60(6) 33–39 Hubwieser P Giannakos M N Berges M Brinda T Diethelm I Magenheim J … Jasute E (2015) July) A global snapshot of computer science education in K-12 schools In Proceedings of the 2015 ITiCSE on working group reports (pp 65–83) ACM Manches A McKenna P E Rajendran G & Robertson J (2019) Identifying embodied metaphors for computing education Computers in Human Behavior Papavlasopoulou S Sharma K & Giannakos M (2019) Coding activities for children Coupling eye-tracking with qualitative data to investigate gender differences Computers in Human Behavior P�erez-Marín D Hijon-Neira � R Bacelo A & Pizarro C (2019) Can computational thinking be improved by using a methodology based on metaphors and scratch to teach computer programming to children? Computers in Human Behavior Selby C & Woollard J (2014) Computational Thinking The developing definitions In Proceedings of the 45th ACM technical symposium on computer science education SIGCSE 2014 ACM Wing J M (2006) Computational thinking Communications of the ACM 49(3) 33–35 Charoula Angeli University of Cyprus Cyprus Michail Giannakos Norwegian University of Science and Technology Norway  Corresponding author E-mail address cangeli@ucyaccy (C Angeli) C Angeli and M Giannakos 
By David Barr John Harrison and Leslie Conery Computational Thinking A Digital Age The National Science Foundation has assembled a group of thought leaders to bring the concepts of computational thinking to the K–12 classroom Agroup of high school students cluster around a computer looking at a series of graphs and charts on the screen and talking quietly but intently They are col- laborating with a group of students in South America using Skype Together they have gathered data and created a model depicting the rate of defores- tation of the rain forests around the world Today they are discussing the changes they need to make to their data representation and algorithm before running their simulation These students are engaged in what is called computational thinking What Is Computational Thinking? In a seminal article published in 2006 Jeanette Wing described computa- tional thinking (CT) as a way of “solv- ing problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science” She noted that computational thinking involves some familiar concepts such as problem decomposition data representation and modeling as well as less familiar ideas such as binary search recur- sion and parallelization She also argued that “computational thinking is a fundamental skill for everyone not just for computer scientists To reading writing and arithmetic we should add computational thinking to every child’s analytical ability” Wing’s article gave rise to an often controversial discussion and debate among computer scientists cognitive researchers and educators regarding the nature definition and applica- tion of CT While many people have proposed revisions and refinements to Wing’s original description so far no single widely accepted defini- tion of computational thinking has emerged As a result PK–12 educa- tors who recognize the importance of CT and want to help students ac- quire these skills have lacked a clear and practical definition to guide their work How Can We Make CT Accessible? In 2009 the National Science Foun- dation (NSF) funded a project titled Leveraging Thought Leadership for Computational Thinking in PK–12 Led jointly by ISTE and the Com- puter Science Teachers Association (CSTA) the project is intended to make the concepts of computational thinking accessible to educators by providing an operational definition a shared vocabulary and relevant age-appropriate examples of com- putational thinking tied to current educational objectives and classroom practices A year ago the project convened a di- verse group of educators with an interest in CT from higher education PK–12 and industry to help define a common language surrounding computational thinking articulate the challenges and opportunities of integrating it through- out PK–12 education and identify the most promising practices and strategies for moving computational thinking from concept to deep integration From that meeting a consensus emerged regarding the essential elements of CT its importance as a learning objec- tive for all students and how it might be introduced into the PK–12 educational environment The outcomes of the meet- ing were summarized and synthesized into a tentative “operational definition” of CT—that is a description of its compo- nents that educators can use to build CT skills across the curriculum through all grade levels and content areas Copyright © 2011 ISTE (International Society for Technology in Education) 18003365191 (US & Canada) or 15413023777 (Int’l) iste@isteorg wwwisteorg All rights reserved 20 Learning & Leading with Technology | March/April 2011 ©iSToCkphoToCom/DrAfTEr123 Skill for Everyone Computational thinking is a problem- solving process that includes • Formulating problems in a way that enables us to use a computer and other tools to help solve them • Logicallyorganizingandanalyzing data • Representingdatathroughabstrac- tions such as models and simulations • Automating solutions through algo- rithmic thinking (a series of ordered steps) • Identifying analyzing and imple- menting possible solutions with the goal of achieving the most efficient and effective combination of steps and resources • Generalizing and transferring this problem-solving process to a wide variety of problems These skills are supported and en- hanced by a number of dispositions or attitudes that are essential dimensions of CT including • Confidenceindealingwithcomplexity • Persistence in working with difficult problems • Tolerance for ambiguity • The ability to deal with open- ended problems • The ability to communicate and work with others to achieve a common goal or solution More than 82% of the 697 respon- dents agreed or strongly agreed that this definition captured the essential elements of CT An additional 9% confirmed that the definition would do as a means to build consensus in the PK–12 community On the basis of this survey and feedback from educators gathered through confer- ence presentations and other infor- mal data collection project leaders have begun implementing the next phase of the project which involves Learn More To learn more about how to teach the concepts and vocabulary of computational thinking in PK–12 classrooms please visit isteorg/computational-thinking or the CSTA website at http//cstaacmorg Check back in a few months to find curriculm resources vocabulary tools and a toolkit for leaders Copyright © 2011 ISTE (International Society for Technology in Education) 18003365191 (US & Canada) or 15413023777 (Int’l) iste@isteorg wwwisteorg All rights reserved March/April 2011 | Learning & Leading with Technology 21 developing examples of what CT skills look like in the classroom as well as assembling resources to sup- port and guide the implementation of computational thinking concepts in PK–12 education How Is CT Different? Many of the concepts skills and dispo- sitions listed in this operational defini- tion are not new So how is computa- tional thinking different from critical thinking or mathematical thinking? This question has given rise to much debate but as yet no widely accepted consensus The participants in the workshops sponsored by the ISTE/ CSTA project proposed that CT differs from critical thinking and mathemati- cal thinking because Computational Thinking in the Classroom Here are some scenarios developed by participants in the ISTE/CSTA practitioners workshop that illustrate how computational thinking concepts and skills play out in various grade levels and disciplines In these examples students are learning computational thinking skills in nontraditional settings so that they become internalized and can be easily transferred from one setting to another These students are developing skills that can be applied in a variety of situations—in other classes in the workplace in their hobbies—from a variety of perspectives and in an authentic setting As more and more teachers emphasize these skills students will begin to apply them naturally in new and exciting ways Mr Davis’ ninth grade language arts class is studying various literary elements such as plot point of view irony and voice They have read a number of short stories and are wrapping up the unit They are preparing to write essays that explore how a particular literary device plays a part in the essence and workings of the chosen stories These students must state their theses clearly and include at least three pieces of evidence to support the theses The skills of logically organizing and analyzing data necessary for proving a thesis with citations of strong and thorough textual evidence are also essential elements of computational thinking The CT concept of representing data through abstractions of literary elements such as plot structure setting figurative language tone and point of view is also necessary to writing a coherent essay of literary analysis with a clear thesis statement The CT ability to communicate and work with others to achieve a common goal or solution facilitates active participation in class discussions especially those guided by a seminar question As the students reflect on their unit and the skills that enable them to be effective writers they begin making connections between the skills they are using in language arts and their application to other subject areas Ms Martinez’s sixth grade social studies class is studying the Roman Empire Students will compare events in an ancient Roman child’s life to their own life experience by writing responses on the Ancient Roman Life Blog They will also identify the lifestyle of ancient Roman children and compare it to their own The teacher calls attention to the vocabulary of “modeling” and “simulation” and asks students to reflect on other activities in which they have used these concepts and skills She also asks them to reflect on where they might use them in the future including their careers These students are learning the computational thinking concepts of representing data through abstractions such as models and simulation and logically organizing and analyzing data They are also exploring ways of transferring these skills to other contexts Ms Lee’s seventh grade class is looking at a series of diagrams her students have created to portray floor plans of their school and homes In the diagrams each room is labeled as a node and each pathway out of the building is labeled as a route Students are discussing the options for escape routes in the event of a fire As the students and Ms Lee look over the diagrams you hear a conversation among the students describing how the diagrams are an abstraction of the actual rooms in a home or school building that enables them to represent all the possible escape routes The students are preparing to create an algorithm to calculate the safest and fastest routes from the buildings Mr Butler’s fifth grade music class has been studying the diatonic scale and the concept of pitch Now the students are using Scratch to create a virtual xylophone that will correctly reproduce the scale Through observation the students recognize that each bar of the xylophone behaves in the same manner but the pitch varies for each bar These students are learning the CT concepts of representing data through abstractions as well as identifying analyzing and implementing possible solutions Additionally they are experiencing the CT disposition of persistence in working with difficult problems iSToCkphoToCom/ilDogESTo iSToCkphoToCom/mSTAy Copyright © 2011 ISTE (International Society for Technology in Education) 18003365191 (US & Canada) or 15413023777 (Int’l) iste@isteorg wwwisteorg All rights reserved 22 Learning & Leading with Technology | March/April 2011 • It is a unique combination of think- ing skills that when used together provide the basis of a new and pow- erful form of problem solving • It is more tool oriented • It makes use of familiar problem- solving skills such as trial and error iteration and even guessing in contexts where they were previ- ously impractical but which are now possible because they can be auto- mated and implemented at much higher speeds Why Is CT Important? The application of computer technolo- gy to virtually every field of study has changed the way work is done today While the human mind is by far the most powerful problem-solving tool we have the ability to extend the pow- er of human thought with computers and other digital tools has become an essential part of our everyday lives and work We all need to understand how when and where computers and other digital tools can help us solve problems and we all need to know how to communicate with others who can assist us with computer-supported solutions Students already learn many ele- ments of the set of computational thinking skills in a variety of disci- plines but we need to ensure that all students have the opportunity to learn the complete set of skills so their com- bined power is available to them The NSF/ISTE/CSTA project has explored how students learn computational thinking at all grade levels and in all disciplines The long-term goal is to recommend ways that all students have the opportunity to learn these skills and to ensure that they can be transferred to different problems and used in different contexts David Barr is a retired K–12 teacher and administrator who works as an educational tech- nology consultant He serves on the ISTE NETS Leadership Team and the steering com- mittee of the NSF/ISTE/CSTA Computational Thinking project John Harrison has taught math- ematics and computer science at Princess Anne High School in Virginia Beach Virginia since 1999 He sits on the Computer Science Teachers Association board and chairs its communi- cations committee levels and a professional development specialist Leslie Conery is deputy CEO of ISTE She holds an assortment of degrees and certifications in computer science education and association management She has also been a classroom teacher at the elementary and high school This material is based on work supported by the National Science Foundation grant CNS-1030054 New online learning options In addition to NETS•T Certification we now offer courses on integration of ISTE Standards and 21st century skills—in an innovative virtual classroom environment and a convenient asynchronous format 24 hours a day 7 days a week NEW Courses • Teaching and Learning in an Online Environment (8 or 10 weeks) • Supporting Digital and Global Citizenship (4 weeks) • Technology Literacy 103 Utilizing Social Networking Tools in a Leadership Capacity (4 weeks) • Focus on STEM Instructional Technology Strategies for Science and Math (4 weeks) Upcoming Spring Courses • Survey of Emerging Technologies (4 weeks) Next session starts May 2 2011 • Research and Information Fluency (4 weeks) Next session starts May 2 2011 Where do you stand? Take our FREE online surveys jamesmadisoneducationcom Phone Email 1-877-343-2302 (toll free) info@jamesmadisoneducationcom All courses are accredited by James Madison University James Madison University® JMU® and the James Madison Logo are registered trade- marks of James Madison University used under license Integrating 21st Century Skills Through NETS•T CertificationTM Copyright © 2011 ISTE (International Society for Technology in Education) 18003365191 (US & Canada) or 15413023777 (Int’l) iste@isteorg wwwisteorg All rights reserved March/April 2011 | Learning & Leading with Technology 23 
Computational Thinking in K—12 A Review of the State of the Field Author(s) Shuchi Grover and Roy Pea Source Educational Researcher Vol 42 No 1 (JAN/FEB 2013) pp 38-43 Published by American Educational Research Association Stable URL https//wwwjstororg/stable/23360476 Accessed 29-01-2020 2128 UTC JSTOR is a not-for-profit service that helps scholars researchers and students discover use and build upon a wide range of content in a trusted digital archive We use information technology and tools to increase productivity and facilitate new forms of scholarship For more information about JSTOR please contact support@jstororg Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use available at https//aboutjstororg/terms American Educational Research Association is collaborating with JSTOR to digitize preserve and extend access to Educational Researcher This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms ßf REVIEWS/ESSAYS Computational Thinking in K—12 A Review of the State of the Field Shuchi Grover1 and Roy Pea1'2 Jeannette Wing's influential article on computational thinking 6 years ago argued for adding this new competency t every child's analytical ability as a vital ingredient of science technology engineering and mathematics (STEM) learnin What is computational thinking? Why did this article resonate with so many and serve as a rallying cry for educator education researchers and policy makers? How have they interpreted Wing's definition and what advances have been made since Wing's article was published? This article frames the current state of discourse on computational thinking K-12 education by examining mostly recently published academic literature that uses Wing's article as a springboard identifies gaps in research and articulates priorities for future inquiries Keywords computational thinking; computing education; computational literacy; computers and learning; K-12 curricula; learning environments; problem solving; STEM learning; student cognition; technology Introduction Of course the idea of CT is not new Back in the 1960s Alan Perlis argued for the need for college students of all disciplines to Six years ago Jeannette Wing's succinct and influential article learn programming and the theory of computation (Guzdial Computational Thinking appeared in the Viewpoint section 2008) However in the context of K-12 education computing of the March 2006 edition of the Communications of the ACM first gained popular traction around Seymour Papert's MIT work with the pronouncement It represents a universally applicable in the 1980s Papert pioneered the idea of children developing attitude and skill set everyone not just computer scientists procedural thinking through LOGO programming (Papert perspective on the topic and Wing's 2006 article forms a logical community Prompted by her article and a growing community of would be eager to learn and use (p 33) 1980 1991) This recent resurgence takes a fresh 21st century Wing's arguments caught the attention of a broad academic starting point for our critical examination of the current state o researchers educators and policymakers computational thinking the field of CT in K-12 education The following sections exam (or CT) as a concept and associated research agenda has witnessed ine mostly recently published salient academic literature that increasing attention and research The tailwinds in the larger envi has used Wing's article as a springboard The article will also ronment have fanned this growing interest The issue of Computer report on key efforts around computing education in K-12 Science (CS) Education in K-12 took center-stage following a Given the definitional confusion that has plagued CT as a stark report titled Running on Empty The Failure to Teach K-12 phrase and how imperative it is for school education the next Computer Science in the Digital Age (Wilson Sudol Stephenson &c section looks deeply at the varied perspectives and evolving defi Stehlik 2010) revealed precipitously low numbers for women in nitions of CT the rationale for building CT among school chi computing and that more than two thirds of the country had few dren and common criticisms against CT in schools The article computer science standards at the secondary school level Concerns then surveys recent research investigating CT (including some about these statistics deepen given projections from the Bureau of that do not use the phrase computational thinking per se but Labor Statistics (http//wwwblsgov/ooh/) that computing is one nonetheless examine computational competencies in children) of the fastest-growing job markets through 2018 This CS educa the various environments and tools that are believed to foster CT tion has dovetailed with the science policy attention to science development and studies attempting to assess CT are appraised technology engineering and mathematics (STEM) learning in the Finally the article lays out priorities for broadening the K-12 CT United States since the turn of the 21st century With CT being discourse on the basis of the gaps in current research viewed as at the core of all STEM disciplines (Henderson Cortina Hazzan & Wing 2007) it appears that computing in K-12 isStanford University School of Education Stanford CA USA idea whose time has come 2H-STAR Institute Stanford CA USA Educational Researcher Vol 42 No 1 pp 38-43 DOI 103102/0013189X12463051 © 2013 AERA http//eraeranet This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms 38 EDUCATIONAL RESEARCHER The What and Why of Computational Thinking According to Wing (2006) computational thinking involves solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science (p 33) CT's essence is thinking like a computer scientist when confronted with a problem Wing s call to action for CT in school education served as the starting point for two National Academy of Sciences workshops convening leading researchers from education learning sciences and computer science departments and leaders from the com puting industry to explore the nature of computational think ing and its cognitive and educational implications (National Research Council [NRC] 2010 p viii) and the pedagogical aspects of computational thinking (NRC 2011) In the first workshop early notions of CT that focused on procedural thinking and programming (Papert 1980 1991) though still considered valid were revisited and broadened to encompass several core concepts of computer science that take it beyond just programming The workshop however threw into sharp relief the lack of consensus that seems to have bedeviled this space Some of the central questions left unanswered by the workshop included the following How can CT be recognized? What is the best pedagogy for promoting CT among children? Can programming computers and CT be legitimately sepa rated? (NRC 2010) Some of these questions were reexamined in the follow-up workshop that focused on better defining the space by gathering and synthesizing insights from educators addressing CT in their work with K-12 teachers and learners The aim of the workshop was to share examples and best prac tices of pedagogies and environments for teaching CT and revealed a plethora of perspectives that reflected several tools and pedagogies that are legitimate candidates for use in developing these competencies Wing (2011) revisited the topic and clarified Computational thinking is the thought processes involved in formulating prob lems and their solutions so that the solutions are represented in a form that can be effectively carried out by an information-pro cessing agent Aho (2012) simplified this further by defining CT as the thought processes involved in formulating problems so their solutions can be represented as computational steps and algorithms (p 832) Recently the Royal Society (2012) also offered a succinct and tractable definition that captures the essence of CT— Computational thinking is the process of recognising aspects of computation in the world that surrounds us and applying tools and techniques from Computer Science to understand and rea son about both natural and artificial systems and processes (p 29) A valuable perspective that breaks down the meaning of CT especially for high school curricula comes from the CS Principles course being piloted by the College Board and the National Science Foundation (NSF) (http//wwwcsprinciplesorg/) The course focuses on the practices of computational thinking and is based on the seven big ideas of computing 1 Computing is a creative human activity 2 Abstraction reduces information and detail to focus on concepts relevant to understanding and solving problems 3 Data and information facilitate the creation of knowledge 4 Algorithms are tools for developing and expressing solu tions to computational problems 5 Programming is a creative process that produces computa tional artifacts 6 Digital devices systems and the networks that intercon nect them enable and foster computational approaches to solving problems 7 Computing enables innovation in other fields including science social science humanities arts medicine engi neering and business Following workshops organized by the Computer Science Teachers Association (CSTA) and the International Society for Technology in Education (ISTE) Barr and Stephenson (2011) provided a similar operational definition of CT aimed at K-12 teachers that comprised an explanatory checklist for what CT means along with an enumeration of core CT concepts and capa bilities and examples of how they might be embedded in activi ties across multiple disciplines It is worth noting here that the potent idea of computational literacy (diSessa 2000) pre-dates Wings charter for CT for all Although the essence of both concepts targets this new digital age competency diSessa separates the material tools such as pro gramming environments from the cognitive and the social aspects of computational literacy Furthermore diSessa under scores the use of computing as a medium for exploring other domains such as math and science much like Kay and Goldberg (1977) explored math science and art via programming in Smalltalk This notion is often neglected in popular definitions of CT The term computational literacy is perhaps susceptible to con fusion with earlier ones like computer literacy information literacy and digital literacy that have assumed various meanings over the years and fall well short of what diSessa demands of computational literacy Although the phrase and notion of computational thinking now seems to be preferred over computational literacy in research and practice today the two phrases are often used interchangeably Procedural literacy is another avatar of CT that was first pro posed in 1980 by B A Sheil at Xerox PARC In our reading there is little to distinguish between procedural literacy and CT applied mostly to creating video games and other computational media artifacts or more broadly the practice of CT in the context of new media art and design Researchers and CS educators for the most part now work broadly with the aforementioned recent descriptions of CT The value of abstraction as CT's keystone (distinguishing it from other types of thinking) is undisputed Abstraction is defining patterns generalizing from specific instances and a key to deal ing with complexity (Wing 2011) The following elements are now widely accepted as comprising CT and form the basis of curricula that aim to support its learning as well as assess its development • Abstractions and pattern generalizations (including models and simulations) • Systematic processing of information • Symbol systems and representations • Algorithmic notions of flow of control This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms JANUARY/FEBRUARY 2013 | 39 • Structured problem decomposition (modularizing) • Iterative recursive and parallel thinking • Conditional logic • Efficiency and performance constraints • Debugging and systematic error detection Programming is not only a fundamental skill of CS and a key tool for supporting the cognitive tasks involved in CT but a demonstration of computational competencies as well Noteworthy efforts like CS Unplugged (http//csunplugged org/) that introduce computing concepts without the use of a computer while providing valuable introductory activities for exposing children to the nature of CS may be keeping learners from the crucial computational experiences involved in CT's common practice Finally although there is broad acknowledgement that com puting pervades all aspects of the global economy its place as a mandatory part of the school curriculum is far from secure Many criticisms have revolved around these multiple interpreta tions of CT and a lack of clarity among educators on CS as a discipline Another valid concern is whether there is a compel ling rationale for all children including those who allege no interest in pursuing CS and STEM careers to develop compu tational competencies in school In the zero-sum school curricu lum map how should curriculum policymakers make room in already packed school curricula? There is also lack of agreement on whether CT should ultimately be incorporated into educa tion as a general subject a discipline-specific topic or a multi disciplinary topic (NRC 2011) Lastly there is some question whether CT is distinct enough from other forms of thinking that children are developing Advocates of CT concede that although it shares elements with mathematical engineering and even design thinking and draws on a rich legacy of related frameworks it also extends each of those thinking skills in a unique way (Lee et al 2011) Denning and Freeman (2009) observe that although the computing paradigm contains echoes of engineering science and mathematics it is distinctively dif ferent because of its central focus on information processes (p 30) and that Wing's CT interpretation embeds well into this system of practice We claim that the approach to problem solving generally described as CT is a recognizable and crucial omission from the expertise that children are expected to develop through routine K—12 Science and Math education (although CT has finally been mentioned albeit briefly in the 2012 NRC K-12 Science Education framework) If basic literacy in Math and Science can be considered essential for all children to understand how our world works why should school education not lift the hood on all-pervasive computing devices as well? We believe that those in possession of computational competencies will be better positioned to take advantage of a world with ubiquitous com puting Early experiences with this way of problem solving will not only alleviate problems in introductory CS courses undergraduates have been known to face but also generate inter est and prime students for success in this growing field rife with opportunity Recent news from media and industry suggest that the move to make programming a more commonplace skill for everyone and introducing 'rithms (short for algorithms) as the fourth r for 21 st-century literacy is gaining momentum globally Israel has long boasted an exemplary mandatory high school CS curricu lum Countries such as Russia South Africa New Zealand and Australia have already made room for CS in the K-12 curricu lum More recently the United Kingdom has piloted programs to teach computing to all schoolchildren following a bold 2012 policy charter from the Royal Society Summary of Pertinent Research on CT in K-12 With broadly agreed on definitions of CT in K-12 education focus has recently shifted to tackling the more practical questions of how to promote and assess the development of CT There is extensive literature from the last three decades tackling issues of teaching and learning programming and CS The bulk of CS education research however is set in the context of undergradu ate classrooms Although there is much to learn about CT in K-12 both from studies of kids and programming in the 1980s (using languages such as LOGO and BASIC) as well as early programming and CS experiences of college students the space constraints imposed by the essay as well as a focus on the recent resurgence of CT force the review to be limited to recent research involving 21st-century tools and school-age children Environments and Tools That Foster CT The idea of low floor high ceiling as one of the guiding prin ciples for the creation of programming environments for children has been around since the days of LOGO It essentially means that though it should be easy for a beginner to cross the threshold to create working programs (low floor) the tool should also be powerful and extensive enough to satisfy the needs of advanced programmers (high ceiling) Computationally rich environments and effective CT tools for school children must have low thresh old and high ceiling scaffold enable transfer support equity and be systemic and sustainable (Repenning Webb & Ioannidou 2010) Several programming tools fit these criteria to varying degrees Popular among these are graphical programming envi ronments such as Scratch Alice Game Maker Kodu and Greenfoot; Web-based simulation authoring tools such as Agentsheets and Agentcubes; and robotics kits and tangible media such as Arduino and Gogo Boards Graphical program ming environments are relatively easy to use and allow early expe riences to focus on designing and creating avoiding issues of programming syntax By allowing novices to build programs by snapping together graphical blocks that control the actions of different dynamic actors on a screen environments like Scratch MIT's popular offering quite literally make programming a snap Several of these introductory computational experiences use the three-stage use-modify-create progression to help the learner go from user to modifier to creator of computational arti facts (Lee et al 2011) a progression first broadly used in Apples HyperCard application in the mid-1980s to early 1990s Curricular activities such as game design and robotics have typi cally served well as a means for the iterative exploration of CT making them ideal not only for motivating and engaging school children but for introducing them to computer science Visual and tangible programming experiences are often followed by 40 J EDUCATIONAL RESEARCHER This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms exposure to high-level programming languages such as Python Java and Scheme Recommendations for engaging girls through computing in context (Margolis &C Fisher 2002; also see Cooper & Cunningham 2010) provide a compelling rationale for tools that strive to bridge the gender gap in the computing field Emerging computational environments are poised to provide more opportunities for engagement in CT in formal and infor mal settings while also engaging girls as well E-textiles and other computational craft kits that use small powerful hardware such as the Lilypad Arduino allow children to combine tradi tional arts and crafts such as sewing and sketching with compu tation and electronics MIT App Inventor a visual programming environment that uses Scratch-like graphical blocks of code for building Android mobile apps is more gender neutral and com plete than most tools It sets a low floor for allowing creative app building (something all teens including girls are eager to do) while still engaging with complex CT concepts including proce dural and data abstraction iterative and recursive thinking structured task breakdown conditional and logical thinking and debugging Despite its growing popularity for promoting many 21st century competencies in K-12 (NRC 2012) video gaming as a platform for examining CT among children has been underuti lized in recent research Holbert and Wilensky (2011) success fully developed and tested a prototype video game FormulaT which aimed to serve as a platform for learning principles of kine matics as well as systematic computational strategies FormulaT used NetLogo a computational environment for agent-based modeling The activities of abstracting pertinent behaviors into agents applying rules and evaluating the results via modeling and simulation are key ways of engaging in CT Blikstein (2010) demonstrates leveraging Netlogo computational models for sci ence learning in secondary-level classrooms Agent-based model ing however remains relatively underused in CT research Not surprisingly current computational tools vary in their effectiveness in allowing for engagement with the various compo nent elements of CT Maloney Peppier Kafai Resnick and Rusk (2008) reported demonstration of several CT elements such as conditional logic iterative and parallel thinking and data abstraction in Scratch programs created by urban youth in after school settings However Scratch lacks the means to abstract functionality into functions and procedures prompting a version called Snap from Berkeley that seeks to address this Perhaps an imperative for CS in K-12 will fuel the development of new tools built expressly for fostering CT among school-age children These should not only embody all the characteristics of effective CT tools and promote the development of all the competencies now identified as elements of CT but also be guided by recent research on commonsense human understanding of computing and how children explain their approaches to problem solving (Pane Ratanamahatana & Myers 2001; Simon Chen Lewandowski McCartney & Sanders 2007) Lastly despite the variety of environments in which current CT research is situated many promising spaces are still untapped; Fab Labs Makerspaces and DIY movements such as Maker Faire and Instructables that promote construction of tangible computational artifacts informal hacker events for kids as well as ubiquitous and powerful smartphones all present exciting pos sibilities Assessment of CT Without attention to assessment CT can have little hope of mak ing its way successfully into any K-12 curriculum Furthermore to judge the effectiveness of any curriculum incorporating CT measures that would enable educators to assess what the child has learned need to be validated Most recent research addressing questions of CT assessment such as Werner Denner Campe and Kawamotos (2012) Fairy Assessment in Alice has used either student-created or prede signed programming artifacts to evaluate students' understand ing and use of abstraction conditional logic algorithmic thinking and other CT concepts to solve problems Ideas of deconstruction reverse engineering and debugging to assess children's understanding in computational contexts have long enjoyed educational appeal Fields Searle Kafai and Min (2012) evaluated students' engineering and programming skills as they debugged prebuilt faulty e-textile projects Han Koh Basawapatna Bennett and Repenning (2010) attempted with some success to assess the thorny issue of transfer to answer ques tions like Now that the student can program Space Invaders can the student program a science simulation? In the past two decades academic talk has been leveraged for promoting and assessing math and science literacy The devel opment in the student use of the vocabulary and language of CS over the course of engaging in computationally rich activities provides an additional instrument for measuring the growth of CT (Grover 2011) Computing Education in K-12 Wilson and Guzdial (2010) maintain that although the national urgency for strengthening STEM in K-12 has translated into billions of dollars in funding research explicitly in computing education remains underfunded NSF initiatives such as CPATH BPC and most recently CE21 have gone a long way in energiz ing projects aimed at bringing CT/CS concepts to the secondary level An additional boost for guiding interested middle and high school students into CS careers comes from DARPA's initiatives such as CS-STEM and Carnegie Mellon University's FIRE (Fostering Innovation through Robotics Exploration) Although ongoing research in development of CT will help inform computing curricula throughout K-12 preparing teach ers for computing education and ensuring gender equity remain huge challenges The NSF's CS10K initiative aims to add 10000 new CS teachers in US high schools by 2015 The Georgia Computes alliance is at the forefront of nationwide efforts for teacher preparation development of CT/CS K—12 curricula as well as motivating female students in CS Georgia Tech's Guzdial argues in his blog (http//computingedwordpresscom/) that challenges to meeting the CS10K deadline include answering questions like the following What do teachers need in order to develop into successful computer science teachers? What kind of pedagogy will fit into the lives of in-service high school teachers? What is Computer Science Pedagogical Content Knowledge? In terms of curriculum besides CS Principles for AP CS the Exploring CS curriculum (http//wwwexploringcsorg) is This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms JANUARY/FEBRUARY 2013 41 intended to be a 1 -year college preparatory curriculum for high school students Other initiatives aimed at introducing CS into schools include CS4HS (http//wwwcs4hscom/) and Computing in the Core (http//wwwcomputinginthecore org/)—both of which represent collaborations between aca demia national bodies and organizations such as Microsoft and Google CSTA's Model Curriculum for K-12 Computer Science provides curricular suggestions to help build interest engage and motivate students in CS In addition Google's Exploring Computational Thinking website (wwwgooglecom/edu/ computational-thinking) has a wealth of links to CT resources on the web ACM has also recently introduced a new thread EduBits in its ACM Inroads quarterly that highlights principal educational activities within ACM and affiliated organizations Broadening the Scope of the Discourse and Priorities for Empirical inquiry It is thus quite evident that much of the recent work on CT has focused mostly on definitional issues and tools that foster CT development Some strides have been made in the realm of defin ing curricula for nurturing computational competencies and assessing their development Large gaps however still exist that call out for empirical inquiries In a view that was echoed by Alfred Aho Wing argued an application of the science of learning research in designing grade and age-appropriate curricula for computational thinking is nec essary to maximize its impact on and significance for K-12 students (NRC 2011 p 4) Barring some recent studies such as Fadjo Lu and Black (2009) and Berland and Lee (2011) few others have taken into account contemporary research in the learning sciences in socio-cultural and situated learning distrib uted and embodied cognition as well as activity interaction and discourse analyses Cognitive aspects of children and novices learning computational concepts were studied extensively in the 1980s—issues such as development of thinking skills (Kurland Pea Clement & Mawby 1986); debugging (Pea Soloway & Spohrer 1987); problems with transfer (Clements & Gullo 1984; Pea & Kurland 1984); use of appropriate scaffolds for successful transfer (Klahr & Carver 1988) to name a few That body of literature should be brought to bear on 21st-century CT research Also underinvestigated is the idea of computing as a medium for teaching other subjects—dovetailing the introduction of CT at K-12 with transfer of problem-solving skills in other domains Past work includes demonstrations of children successfully designing LOGO software to teach fractions (Harel & Papert 1990) and science (Kafai Ching & Marshall 1997) and using modeling software in science (Metcalf Krajcik & Soloway 2000) Empirical studies on CT in schoolchildren could leverage extensive research on the types of problems beginner CS under graduates face in their early programming experiences that go beyond syntactical issues Are there well-defined hurdles or targets of difficulty that exist in the path of developing some ele ments of CT in children (eg recursion)? If so what are these and how can they be addressed? Also largely untapped is the territory of dispositions for atti tudes toward and stereotypes concerning CT and CS and how they relate to the development of learner identity (Mercier Barron & O'Connor 2006) How crucial are these as we strive to provide both girls and boys with learning experiences that aim to nurture CT competencies? Recent incipient work on surveys of student attitudes toward computing represents a start in gain ing a better understanding of this Clearly much remains to be done to help develop a more lucid theoretical and practical understanding of computational competencies in children What for example can we expect children to know or do better once they've been participating in a curriculum designed to develop CT and how can this be evalu ated? These are perhaps among the most important questions that need answering before any serious attempt can be made to introduce curricula for CT development in schools at scale It is time to redress the gaps and broaden the 21st-century academic discourse on computational thinking ACKNOWLEDGMENT We gratefully acknowledge grant support of the LIFE Center from the National Science Foundation for this work (NS 0835854) REFERENCES Aho A V (2012) Computation and computational thinking Computer Journal 55 832-835 Barr V & Stephenson C (2011) Bringing computational thinking to K-12 What is involved and what is the role of the computer science education community? ACM Inroads 2 48-54 Berland M & Lee V (2011) Collaborative strategic board games as a site for distributed computational thinking International Journal of Game-Based Learning 1(2) 65-81 Blikstein P (2010) Connecting the science classroom and tangible inter faces the bifocal modeling framework In Proceedings of the 9th International Conference of the Learning Sciences Chicago IL 128-130 Clements D H & Gullo D F (1984) Effects of computer program ming on young children's cognitions Journal of Educational Psychology 76 1051-1058 Cooper S & Cunningham S (2010) Teaching computer science in context ACM Inroads 1 5-8 Denning P & Freeman P (2009) Computing's paradigm Communications of the ACM 52(12) 28-30 diSessa A A (2000) Changing minds Computers learning and literacy Cambridge MIT Press Fadjo C L„ Lu M & Black J B (2009 June) Instructional embodi ment and video game programming in an afier school program Paper presented at the World Conference on Educational Multimedia Hypermedia & Telecommunications Chesapeake VA Fields D A Searle K A Kafai Y B & Min H S (2012) Debuggems to assess student learning in e-textiles In Proceedings of the 43rd SIGCSE Technical Symposium on Computer Science Education New York NY ACM Press Grover S (2011 April) Robotics and engineering for middle and high school students to develop computational thinking Paper presented at the annual meeting of the American Educational Research Association New Orleans LA Guzdial M (2008) Paving the way for computational thinking Communications of the ACM 51(8) 25-27 Han Koh K Basawapatna A Bennett V &C Repenning A (2010) Towards the automatic recognition of computational thinking for adaptive visual language learning In Proceedings of the 2010 Conference EDUCATIONAL RESEARCHER This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms on Visual Languages and Human Centric Computing (VL/HCC 2010) (pp 59-66) Madrid Spain IEEE Computer Harel I & Papert S (1990) Software design as a learning environ ment Interactive Learning Environments I 1—32 Henderson P B Cortina T J Hazzan O and Wing J M (2007) Computational thinking In Proceedings of the 38th ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE '07) 195-196 New York NY ACM Press Holbert N R & Wilensky U (2011 April) Racing games for exploring kinematics a computational thinking approach Paper presented at the annual meeting of the American Educational Research Association New Orleans LA Kafai Y B Ching C C & Marshall S (1997) Children as designers of educational multimedia software Computers & Education 29 117-126 Pea R D & Kurland D M (1984) On the cognitive effects of learn ing computer programming New Ideas in Psychology 2 137-168 Pea R D Soloway E & Spohrer J C (1987) The buggy path to the development of programming expertise Focus on Learning Problems in Mathematics 9 5-30 Repenning A Webb D & Ioannidou A (2010) Scalable game design and the development of a checklist for getting computational thinking into public schools In Proceedings of the 41st ACM Technical Symposium on Computer Science Education (SIGCSE '10) 265-269 New York NY ACM Press Royal Society (2012) Shut down or restart The way forward for computing in UK schools Retrieved from http//royalsocietyorg/ education/policy/computing-in-schools/report/ Simon B Chen T Lewandowski G McCartney R & Sanders K (2007 March) Commonsense computing What students know before we Kay A & Goldberg A (1977) Personal dynamic media IEEEteach (Episode 1 Sorting) Paper presented at the Second International Computer 10 31—41 Workshop on Computing Education Research Canterbury UK Klahr D & Carver S M (1988) Cognitive objectives in a LOGWOerner L Denner J Campe S & Kawamoto D C (2012) The debugging curriculum Instruction learning and transfer Cognitive Fairy performance assessment Measuring computational thinking in Psychology 20 362-404 middle school In Proceedings of the 43rd ACM Technical Symposium Kurland D M Pea R D Clement C & Mawby R (1986) A study on Computer Science Education (SIGCSE '12) 215-220 New York of the development of programming ability and thinking skills in highNY ACM school students Journal of Educational Computing Research 2 429—Wilson C & Guzdial M (2010) How to make progress in computin 458 Lee I Martin E Denner J Coulter B Allan W Erickson J  Werner L (2011) Computational thinking for youth in practice ACMInroads232-37 Maloney J Peppier K Kafai Y B Resnick M & Rusk N (2008) ProgrammingbychoiceUrbanyouthlearningprogrammingwith Scratch In Proceedings of SIGCSE '08 New York NY ACM Press Margolis J & Fisher A (2002) Unlocking the clubhouse Women in computing Cambridge MIT Press Mercier E M Barron B & O'Connor K M (2006) Images of self and others as computer users The role of gender and experience Journal of Computer Assisted Learning 22 335-348 Metcalf J S„ Krajcik J & Soloway E (2000) Model-It A design retrospective In M J Jacobson & R B Kozma (Eds) Innovations in science and mathematics education (pp 77-115) Mahwah NJ Lawrence Erlbaum National Research Council (2010) Committee for the Workshops on Computational Thinking Report of a workshop on the scope and nature of computational thinking Washington DC National Academies Press National Research Council (2011) Committee for the Workshops on Computational Thinking Report of a workshop of pedagogical aspects of computational thinking Washington DC National Academies Press National Research Council (2012) A framework for K-12 science educa tion Practices crosscutting concepts and core ideas Washington DC National Academies Press Pane J E Ratanamahatana C A & Myers B A (2001) Studying the language and structure in non-programmers' solutions to program ming problems InternationalJournal of Human-Computer Studies 54 237-264 Papert S (1980) Mindstorms Children computers and powerful ideas New York NY Basic Books Papert S (1991) Situating constructionism In I Harel & S Papert (Eds) Constructionism (pp 1—11) Norwood NJ Ablex education Communications of the ACM 53(5) 35-37 Wilson C Sudol L A Stephenson C &Stehlik M (2010) Runnin on empty The failure to teach K-12 computer science in the digital ag New York NY The Association for Computing Machinery and th Computer Science Teachers Association Wing J (2006) Computational thinking Communications of the ACM 49(3) 33-36 W ing J (2011) Research notebook Com putational thinking— W h and why? The Link Magazine Spring Carnegie Mellon University Pittsburgh Retrieved from http//linkcscmuedu/articlephp?a=60 AUTHORS SHUCHI GROVER is a doctoral candidate at Stanford Universi School of Education 485 Lasuen Mall Stanford CA 94305-309 shuchig@stanfordedu Her research focuses on helping children becom computationally literate—studying social cultural and cognitive p cesses that help in developing computational competencies—and tools and environments that nurture such development ROY PEA is the David Jacks Professor of Education & Learnin Sciences at Stanford University School of Education and Compute Science (Courtesy) and Director of the H-STAR Institute Wallenber Hall 450 Serra Mall Bldg 160 Stanford CA 94305; roypea@stanfor edu His work in the learning sciences focuses on advancing theorie findings tools and practices of technology-enhanced learning of co plex domains Manuscript received April 14 2012 Revisions received June 13 2012 and July 19 2012 Accepted September 6 2012 JANUARY/FEBRUARY 2013 This content downloaded from 1422317828 on Wed 29 Jan 2020 212838 UTC All use subject to https//aboutjstororg/terms 
Computational Thinking The Developing Definition Cynthia C Selby University of Southampton Highfield Southampton UK 44 (0) 2380 593475 CSelby@sotonacuk ABSTRACT Since Jeanette Wing’s use of the term computational thinking in 2006 various discussions have arisen seeking a robust definition of the phrase With little consensus having been found in the intervening years there are even suggestions that a definition is not important Perhaps focus should be on how computational thinking is taught and how its acquisition might be observed However in order to facilitate consistent curriculum design and appropriate assessment it is argued that a definition should still be sought In order to contribute to the discussions surrounding a definition of computational thinking this review of literature spans the years since 2006 The most frequently occurring terms descriptions and meanings are identified Consideration is given to the motivation for inclusion or exclusion of a term by each individual author Where possible if a description has been given an associated term is supplied Criteria are developed for the objectives of a computational thinking definition in accordance with the needs identified in the literature Using the criteria as a guide and the collected terms as the vocabulary a definition of computational thinking is proposed which encompasses the thought processes of abstraction decomposition algorithmic design evaluation and generalization Categories and Subject Descriptors K32 [Computers and Education] Computers and Education Curriculum General Terms Standardization Theory Keywords Computational thinking definition abstraction decomposition algorithmic thinking algorithmic design generalization evaluation 1 INTRODUCTION The term “computational thinking” when used by Jeanette Wing [19] in her call to make thinking like a computer scientist a fundamental skill for everyone excited educators (1 2 3 4 5 8 11 14 15) and academics (6 7 9 10 12 13 16 17 20) This presented an opportunity to promote computer science to a wider Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page To copy otherwise or republish to post on servers or to redistribute to lists requires prior specific permission and/or a fee Conference’10 Month 1–2 2010 City State Country Copyright 2010 ACM X-XXXXX-XXX-X/XX/XXXX $1500 John Woollard University of Southampton Highfield Southampton UK 44 (0) 2380 592998 JWoollard@sotonacuk audience but it also introduced a challenge Wing did not precisely define the term and state exactly what “computational thinking” is for everyone Since then there have been attempts by authoritative individuals and groups [1 16 9 6] to derive a definition for computational thinking The aim of this investigation is to shed new light on the discussions that attempt to develop a definition of computational thinking with the objectives including to define more narrowly not more broadly; to bring an order to the criteria not necessarily to accommodate all viewpoints; to refine the definition to facilitate assessment; to retain the validity of work that has been done previously such as the development of curriculums; to separate a definition from those activities that might promote acquisition of computational thinking skills; and to separate a definition from those artifacts and activities that evidence the use of those skills 11 Method A selection of literature relating to the topic of computational thinking was examined using the following literature analysis method An Internet search engine query using the criteria “Jeannette Wing” AND “computational thinking” was initially executed The entries of the first four pages were checked for applicabilityoftitle Alldocumentsidentifiedashavingapplicable titles indicating a focus on computational thinking were individually inspected This resulted in six documents The ACM Digital Library was searched using the term “Jeannette Wing” The articles were filtered according to the abstract/introduction text and being dated post 2005 This led to the identification of thirteen items In addition articles describing proposed or current computer science curriculum designs (in Israel [8] Germany [3] New Zealand [2] India [14] England [5] and the USA [1]) were identified This gave 7 more documents Because of repetition of comments by the same author 4 of the original 26 articles were discarded In an attempt to contribute to the development of a definition the publications were analyzed in chronological order to discern the development over time of the phrase computational thinking Descriptions and suggested definitions of computational thinking were identified in each publication The terminology common across descriptions and definitions was collated Where equivalences allowed similar terms were grouped together The most frequently occurring individual terms and groups are presented in the following sections From this basic collection of terms a definition of computational thinking is formulated and proposed Justification for the inclusion or exclusion of terms is presented on a term-by-term basis Justification is based on consistency of usage andconsistencyofinterpretationacrosstheliterature Theresulting definition reflects much of the consensus found in the literature while removing the less well-defined terms 2 EVIDENCEFROMLITERATURE Some authors/papers/commentaries may assert that a precise definition of computational thinking is not required [10 13] However the discussion presented in this paper is driven by a perceived need to support professionals working in the field of computer science education and the developing computing curriculums This need for definition is supported in the literature [1 10 17 16] Guzdial [10] has suggested that a very broad definition is acceptable Such acceptance could shift the focus away from what computational thinking is to how computational thinking should be taught and how evidence of its acquisition might be observed in learners Professor of Computer Science Chenglie Hu [13] supports this by citing that teachers are confident that the teaching of computer science does promote computational thinking Even though they may not know exactly how this mechanism works teachers recognize that the more learners practice computation in terms of computer science the better at computational thinking they become This same argument is expressed by some of those who design or influence the design of computer science curriculums Several curriculums [5 4 2 3] while acknowledging the vagueness of a computational thinking definition continue to include a focus on concepts and techniques from computer science In presenting these concepts and techniques the curriculums include terminology often found in descriptions of computational thinking Some of this terminology will be explored in more detail below Jan Cuny suggests that if computational thinking is included in a curriculum it requires assessment Without agreement on a common definition of computational thinking it will be difficult if not impossible to develop appropriate assessment tools that actually measure the ability to think computationally [16] So a rigorous and agreed definition might ensure that computational thinking in these new curriculums for the K-12 years will be more than as Joyce Malyn-Smith argued “ just a bunch of examples that are placed into the curriculum at the discretion of individual teachers” [17 p33] The balance of argument is still in favor of searching for a robust definitionofcomputationalthinking Althoughitmaybepossible without a robust definition to identify examples of the practice of computational thinking the ability to measure computational thinking may be hampered by that same lack 3 CONSENSUSTERMS Three terms appear consistently throughout the literature reviewed here There appears to be a consensus that a definition of computational thinking should include the idea of a thought process the concept of abstraction and the concept of decomposition 31 AThoughtProcess When introducing the term computational thinking Wing [19] described it as a way that humans think about solving problems It incorporates the set of mental tools used in computer science These tools are used to transform a difficult problem into one that can be solved more easily In adding his voice to Wing’s calling for the explicit teaching of computational thinking Guzdial [9] refers to computational thinking as a way of thinking about computing Participants in the workshop on the scope and nature of computational thinking [16] although not tasked with defining computational thinking nevertheless agreed that it incorporates a range of mental tools and concepts from computer science This idea is extended to represent problems as information processes and solutions as algorithms [7] Al Aho [7] picks up the idea of problem transformation when he describes computational thinking as the thought processes in formulating problems and solutions that can be expressed as algorithms These thought processes do have focus; frequently that focus is described as problem solving Finally Wing expresses these refinements by defining computational thinking as “ the thought processes involved in formulating problems and their solutions so that the solutions are represented in a form that can be effectively carried out by an information-processing agent” (Cuny Snyder Wing 2010 cited in [22] p20) Because of this consensus a definition of computational thinking should include the concept of a thought process 32 Abstraction Although the idea of abstraction hiding complexity as being part of computational thinking is introduced by Wing in her original article [19] the definition develops over the subsequent years She amends the definition to include simultaneous consideration for multiple layers of abstraction and consideration for defining the interfaces between the layers [20] Even Peter Denning [18] acknowledges that abstraction plays an important part in computing including programming However he points out that the act of abstracting is not unique to computer science The next year Wing [21] defines abstraction as the cornerstone of computational thinking Several participants in the workshop on the scope and nature of computational thinking (NRC) concur that computational thinking has a focus around the process of abstraction creating them and defining the relationships between them [16] More recently in their report on workshops sponsored by the Computer Science Teachers Association (CSTA) and the International Society for Technology in Education (ISTE) to incorporate computational thinking into the K-12 curriculum Barr and Stephenson [1] also include the ability to abstract in a definition of computational thinking The concept of abstraction is explored by L’Heureux et al [15] where it is one of six aspects of their information technology approach to computational thinking Because of this consensus a definition of computational thinking should include the concept of abstraction 33 Decomposition Breaking problems down by functionality is identified by Wing [19 20] as part of computational thinking Decomposition is required when dealing with large problems complex systems or complex tasks The participants in the first NRC workshop also identify the need for problem decomposition [16] In the next workshop focusing on pedagogy participants extend this idea Robert Tinker views the core of computational thinking as breaking down big problems [17] Danny Edelson points out that the creation of solutions requires breaking problems down into chunks of particular functionality and sequencing the chunks [17] Most recently in refining his own definition of computational thinking Guzdial [11] includes the use of tools including abstraction and decomposition In light of this consensus a definition of computational thinking should include the concept of decomposition Three terms are proposed for inclusion in the definition of computational thinking Inclusion of a thought process abstraction and decomposition is supported by a consensus found in the reviewed literature These terms are used consistently across the literature Their use does not reflect any discrepancy in perceived meaning of the terms Although consensus has been demonstrated for these terms others receive less support and more varied interpretation Some of these additional terms and their applicability for inclusion in a definition of computational thinking are discussed below 4 POSSIBLETERMS Although less consistently than the terms above several different termsandideasdorecuracrosstheliteraturereviewedhere Even if a term or idea recurs its interpretation is not always consistent across articles Several ideas proposed as part of a definition for computational thinking are broad and high-level A lack of specific interpretation may make inclusion of these terms in a definition difficult The terms identified fall into these four areas thinking problem solving computer science and imitation terms There are two descriptions of thinking three general terms associated with problem solving three terms associated with computer science concepts and three terms associated with the concept of imitation or representation The specific terms are logical thinking and algorithmic thinking; problem solving analysis and generalization; systems design automation and more general computer science concepts; and modeling simulation and visualization Support for inclusion or exclusion of these terms in a definition of computational thinking is presented in this section Justification is based on consistency of usage and consistency of interpretation across the literature 41 ThinkingTerms Although the idea that computational thinking represents a cognitive process attracts consensus there are suggestions that severalspecifictypesofthinkingshouldalsobeincluded These specific types of thinking are logical thinking algorithmic thinking engineering thinking and mathematical thinking This section explores the viability of incorporating these types of thinking into the definition of computational thinking The concept of logical thinking although not specifically defined occurs several times in the literature spanning these years Albeit not perceived exactly as equivalent terms to describe similar types of thinking are grouped into this category These include mathematical thinking engineering thinking and heuristic thinking In her original article Wing [19] indicates that computational thinking incorporates heuristic reasoning to devise a solution In addition to abstraction and decomposition Guzdial [11] also includes heuristic reasoning as an appropriate tool to use when engaging in computational thinking Computational thinking is equivalent to the logical reasoning used by people [12] Logical reasoning is included by Iyer et al [14] in their model computer science curriculum in order to promote high-level thinking skills that are not necessarily subject specific L’Heureux et al [15] in detailing an aspect of their information technology approach to computational thinking define logical thinking as the ability to develop and test hypotheses Computational thinking also intersects with engineering because computer systems interact with the real world However computational thinkers can design and create virtual worlds not limited by physical reality [20] Although Wing [20] states that computer science relies on mathematics as a foundation Gerald Sussman [16] affirms that mathematical thinking revolves around abstract structures while computational thinking revolves around abstract methodology Computational thinking could be viewed as bringing science and engineering together It could be viewed as a meta-science concerned with studying methods of thinking that are applicable to many different disciplines [16] While the ability to think logically mathematically heuristically and from an engineering perspective are certainly capabilities that a computational thinker may exhibit references to these terms in this literature are not well expanded Although the term logical thinking as described above may not be suitable to include in a definition of computational thinking the potentially analogous term algorithmic thinking requires further investigation In her original article Wing [19] does not use the term algorithmic thinking preferring the word heuristic instead However by 2011 she extends her definition of computational thinking to include algorithmic and parallel thinking [22] David Moursund [16] suggests that computational thinking is related to the idea of procedural thinking as proposed by Seymour Papert in Mindstorms He defines a procedure as a step-by-step set of instructions that can be carried out by a device The same theme is continued by Gerald Sussman [16] who defines computational thinking as a way of devising explicit instructions for accomplishing tasks Inclusion of algorithmic thinking in a curriculum for high schools appears prior to Wing’s contribution In the Israeli computer science curriculum Gal-Ezer et al [8] placed an emphasis on inclusion of the study of algorithmic processes There appears to be a consensus that computational thinking incorporates aspects of algorithmic thinking and algorithmic design The term algorithm is interpreted as a step-by- step procedure for accomplishing tasks not just in computer science but in other disciplines It is evidenced through the creation of algorithms – algorithmic design Because of its wide acceptance and appropriate definition algorithmic thinking may be applicable for inclusion in a definition of computational thinking Not all of the types of thinking proposed for inclusion in the definition of computational thinking bring further refinement to the term Tying a definition of computational thinking to other terms such as logically or heuristically with their open-ended interpretation or to specific disciplines such as mathematics or engineering may not help advance the development of K-12 curriculums and may not aid in the development of computational thinking assessment instruments For these reasons terms expressing the idea of logical thinking or equivalence may dilute a definition of computational thinking On the other hand algorithmic thinking is represented consistently in literature and its interpretation does not vary Of all the potential terms associated with thinking algorithmic thinking is the only possible term which may be suitable for inclusion in a definition for computational thinking 42 ProblemSolvingTerms The idea that computational thinking has some relationship to problem solving appears frequently in the cited literature The specific terms problem solving analysis and generalization are most frequently employed in discussions of general problem- solving skills This section explores the interpretation of these terms and the viability of incorporating them into the definition of computational thinking Problem solving in one form or another appears frequently in the literature presented here There is agreement for describing computational thinking as a problem-solving activity However the literature does not illuminate problem solving in detail Wing [19 21] of course incorporates solving problems using computer science concepts in her definition of computational thinking The broadness of the problem-solving skills employed in computational thinking in opposition to specific technical skills is pointed out by Larry Snyder [16] A requirement for a computing device is introduced by Barr and Stephenson [1] who state that the essence of computational thinking is solving problems in a way that can be implemented with a computer Peter Henderson [17] concisely describes computational thinking as a type of generalized problem solvingwithconstraints ProblemsolvingisemphasizedbyMarcia Linn [16] who includes in the qualities of a successful computational thinker the ability to engage in sustained investigative processes to generate problem solutions Although there appears to be a consensus that computational thinking is a type of problem solving the term may not be sufficiently specific to define it Due to the broadness of the term problem solving may not be suitable for inclusion in a definition of computational thinking The term analysis is included by some commentators in the definition of computational thinking Interestingly the term appears in relation to both problems and solutions as in analyze a problem and analyze a solution Analyze in the context of problems fits the category of problem solving as defined above However analyze in the context of solutions could be interpreted as the comparable term evaluate In her initial article Wing [19] expresses the need for a computational thinker to make trade-offs by evaluating the use of time and space power and storage This evaluation of algorithmic processes including their power and limitations is foreshadowed by Gal-Ezer et al [8] Application of the term to user interfaces is evidenced in the second objective of the New Zealand proposed curriculum as part of designing programs [2] In their IT approach L’Heureux et al [15] include the ability to evaluate processes in terms of efficiency and resource utilization and the ability to recognize and evaluate outcomes Although the term analyze attracts some agreement for inclusion in a definition of computational thinking descriptions of the term found in this literature imply an evaluative process Therefore because of interpretative consensus in the description the term evaluate may be suitable for inclusion in a definition of computational thinking A specific term that appears sparingly in the literature definitions is generalization It is the ability to move from specific to broader applicability for example understanding how to draw a square by defining internal angles then applying the same algorithm to produce an approximation of a circle The ability to recognize parts of solutions that have been used in previous situations or that might be used in future situations is included by Kolodner in a definition of computational thinking [17] These parts or functional pieces can be used to solve the current problem or combined in different ways to solve new problems [17] The term generalization itself is described in a proposed curriculum as recognizing common patterns and by sharing common features [5] The idea moves forward from decomposition described above Generalization is the step of recognizing how small pieces may be reused and reapplied to similar or unique problems Although the exact term generalization is used sparingly in the literature the idea of recognizing and reusing common parts of a solution is a possibility for inclusion in a definition of computational thinking Possible terms examined in this section include problem solving analysis and generalization Problem solving is a broad term which although used consistently throughout the literature is not well defined Analysis used in the context of a problem is also a broad term often incorporating the ideas of abstraction and decomposition as discussed above Analysis used in the context of a solution is analogous to evaluation and is used consistently in the literature Although the term generalization is used infrequently in the literature there are descriptions of analogous processes Therefore from this set of possible terms the ones used most consistently with the least disparity of interpretation and which may be suitable for inclusion in a definition of computational thinking are evaluation and generalization 43 ComputerScienceTerms The authors cited here concede that computational thinking has a deep relationship with computer science Some suggest specific computer science terminology to be included in a definition of computer science The specific terms include systems design automation and more general computer science concepts such as recursionandrecoverythroughredundancy Thissectionexplores the viability of incorporating these terms into the definition of computational thinking Systems design although not mentioned frequently is still used to describe computational thinking Designing systems based on concepts used in computer science is mentioned by Wing [19] Again this inclusion is foreshadowed by Gal-Ezer et al [8] who incorporates the study of the design and implementation of computing systems in their curriculum One of Peter Denning’s Great Principles of Computing includes a category based on the design and building of software systems [6] He goes further in describing systems as one of the four core practices in which computing professionals engage along with programming modeling and innovating [18] The focus in each of these cases is systems design as a product oriented process It is evidence of the ability to think computationally not necessarily a definition of it Therefore the term systems design may not be suitable for inclusion in a definition of computational thinking Another term popularized by Wing in defining computational thinking is automation She connects the term to that of abstraction when discussing the mechanization of abstraction layers and the relationships between them [20] Even Denning acknowledges that this is what happens when programming [18] Later a stronger connection is made by Wing [21] when defining computing as the “automation of our abstractions” (p 3718) This introduces the need for a computational device to interpret the abstractions the need for a computer to execute a program The process or processes required in the creation of these automations may be possible terms for defining computational thinking On the other hand a program artifact similar to system design as discussed above is only evidence that computational thinking has taken place Previously a consensus was presented that emphasized the thought process aspect of computational thinking Based on that consensus automation interpreted as a program artifact may not be a useful addition to the definition of computational thinking Throughout the literature terms closely related to the general content of computer science studies appear in descriptions of computational thinking Wing [20] herself introduces computer science concepts such as thinking recursively interpreting code as data and data as code type checking prevention detection recovery through redundancy damage containment error correction prefetching and caching Additional concepts such as parallel processing testing debugging search strategies algorithmic complexity and pattern matching are recognized in the NRC report [16] Barr and Stephenson [1] include the abilities to think iteratively and recursively Closer analysis reveals that not all of these concepts are unique to the field of computer science For example mathematicians think iteratively and engineers plan for recovery through redundancy While each of these concepts may be mastered by computational thinkers none of them uniquely defines or helps narrow a definition of computational thinking Therefore terms interpretable as computer science content may not be helpful in defining computational thinking A thought process Include Consensus found in the literature Abstraction Include Consensus found in the literature Decomposition Include Consensus found in the literature Logical thinking Exclude Broad term not-well defined Algorithmic thinking Include Well-defined across multiple disciplines Problem solving Exclude Broad term evidences the use of skills; develops acquisition of skills Evaluation Include Well-defined across multiple disciplines Generalization Include Well-defined concept although the term may not be familiar Systems design Exclude Evidences the use of skills Automation Exclude Evidences the use of skills Computer science content Exclude Evidences the use of skills Modeling simulation and Exclude Evidences the use of skills in their creation; manipulation develops acquisition of skills Possible terms examined in this section include systems design automation and more general computer science concepts such as recursion and recovery through redundancy Systems design resulting in a product is evidence of the use of computational thinking skills not a definition of it Again automation as a product or program evidences the use of computational thinking skills Finally those terms that are interpretable as computer science content do not bring focus to the definition of computational thinking Therefore none of the suggested terms discussed in this section appears suitable to be included in a definition of computational thinking 44 ImitationTerms Three additional terms also used in discussions of computational thinking are modeling simulation and visualization These terms appear frequently in the cited literature This section explores the viability of including these terms in a definition of computational thinking Wing [19] began by defining computational thinking as modeling the appropriate parts of a problem to facilitate a solution Later Brian Blake [16] insists that the definition of computational thinking should include modeling and visualizations Brinda Puhlmann and Schulte [3] have identified as one achievable curriculumstandardtheprocessesinvolvedinmodelingdata On the other hand Edward Fox and Janet Kolodner [16] point out that it is the manipulation of abstractions (models simulations and visualizations) that contribute to the development of computational thinking skills Observing the results of changing variable values forming hypotheses finding anomalies in data and identifying invariants can all be achieved by interacting with models simulations and visualizations The manipulation of these representations are agreed to enhance the development of computational thinking skills but do not necessarily define it Although these tools are effective aids in developing computational thinking skills they may not be suitable for inclusion in a definition of computational thinking  The following section based on the term’s consistency of use and consistency of interpretation across the literature summarizes the arguments presented above and suggests a definition of computational thinking 5 PROPOSEDDEFINITION The intent of this investigation is to shed new light on the discussions that attempt to develop a definition of computational thinking The objectives for such a definition as stated above are to define more narrowly not more broadly; to bring an order to the criteria not necessarily to accommodate all viewpoints; to refine the definition to facilitate assessment; to retain the validity of work that has been done previously such as the development of curriculums; to separate a definition from those activities that might promote acquisition of computational thinking skills; and to separate a definition from those artifacts and activities that evidence the use of computational thinking skills Justification for inclusion or exclusion is based on consistency of usage and consistency of meaning across the literature The resulting definition reflects much of the consensus found in the literature while removing the less well-defined terms Table 1 summarizes the justification for each prospective term’s inclusion in or exclusion from a proposed definition of computational thinking Table 1 Computational Thinking Definition Terminology As supported by the preceding arguments computational thinking is an activity often product oriented associated with but not limited to problem solving It is a cognitive or thought process that reflects  the ability to think in abstractions  the ability to think in terms of decomposition  the ability to think algorithmically  the ability to think in terms of evaluations and  the ability to think in generalizations This proposed definition attempts to incorporate only those terms for which there is a consensus in the literature or those terms that are well defined across disciplines The intent is to focus on the thinking aspect of the original phrase In other words computational thinking is a focused approach to problem solving incorporating thought processes that utilize abstraction decomposition algorithmic design evaluation and generalizations 6 CONCLUSION There is a genuine need for a robust and agreed definition of computational thinking The definition can facilitate the development of computer science curriculums in line with Wing’s original vision to encourage computational thinking for all The definition may also ensure that the K-12 curriculums will not become just a collection of interesting resources presented at teachers’ discretions The definition may ensure that appropriate assessment tools can be developed which measure computational thinking skills The description narrows the definition by excluding some proposed terms It separates the practice of skills and the results or evidence of the application of skills from the activity of thinking However it does not invalidate the curriculum designs especially as they often focus on the doing or evidence of doing Term Status Justification computational thinking It leaves open the possibilities to develop assessment tools to measure the ability to think computationally Of course the discussions of a definition for computational thinking are not yet concluded It may well be that the definition changes as understanding of computational thinking develops over the coming years This is especially true as younger learners are exposed to the concepts in fulfillment of Wing’s original vision of computational thinking for all This review of the literature simply attempts to inform these discussions 7 REFERENCES [1] Barr V & Stephenson C 2011 Bringing computational thinking to K-12 what is Involved and what is the role of the computer science education community? ACM Inroads 2 48-54 [2] Bell T Andreae P & Lambert L 2010 Computer Science in New Zealand high schools Proceedings of the Twelfth Australasian Conference on Computing Education - Volume 103 Brisbane Australia Australian Computer Society Inc [3] Brinda T Puhlmann H & Schulte C 2009 Bridging ICT and CS educational standards for computer science in lower secondary education Proceedings of the 14th annual ACM SIGCSE conference on Innovation and technology in computer science education Paris France ACM [4] Computer Science Teachers Association Task Force 2011 K–12 Computer Science Standards New York ACM [5] Computing at School Working Group 2012 Computer Science A curriculum for schools Available http//wwwcomputingatschoolorguk/data/uploads/Computi ngCurricpdf [Accessed 26-12-2012] [6] Denning P J 2007 Computing is a natural science Commun ACM 50 13-18 [7] Denning P J 2011 Ubiquity symposium What have we said about computation? closing statement Ubiquity 2011 1-7 [8] Gal-Ezer J Beeri C Harel D & Yehudai A 1995 A high school program in computer science Computer 28 73-80 [9] Guzdial M 2008 Education Paving the way for computational thinking Commun ACM 51 25-27 [10] Guzdial M 2011 A Definition of Computational Thinking from Jeannette Wing Computing Education Blog [Online] Available from http//computingedwordpresscom/2011/03/22/a-definition- of-computational-thinking-from-jeanette-wing/ [Accessed 22-03-11] [11] Guzdial M 2012 A nice definition of computational thinking including risks and cyber-security Computing [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] Education Blog [Online] Available from http//computingedwordpresscom/2012/04/06/a-nice- definition-of-computational-thinking-including-risks-and- cyber-security/ [Accessed 06-04-12] Henderson P B Cortina T J & Wing J M 2007 Computational thinking Proceedings of the 38th SIGCSE technical symposium on Computer science education Covington Kentucky USA ACM Hu C 2011 Computational thinking what it might mean and what we might do about it Proceedings of the 16th annual joint conference on Innovation and technology in computer science education Darmstadt Germany ACM Iyer S Baru M Chita V Khan F & Vishwanathan U 2010 Model Computer Science Curriculum for Schools Available http//wwwcseiitbacin/~sri/papers/CSC- April2010pdf [Accessed 28-12-2012] L'Heureux J Boisvert D Cohen R & Sanghera K 2012 IT problem solving an implementation of computational thinking in information technology Proceedings of the 13th annual conference on Information technology education Calgary Alberta Canada ACM National Research Council 2010 Report of a Workshop on the Scope and Nature of Computational Thinking Available http//wwwnapedu/catalogphp?record_id=12840 [Accessed 10-05-2011] National Research Council 2011 Report of a Workshop of Pedagogical Aspects of Computational Thinking Available http//wwwnapedu/catalogphp?record_id=13170 [Accessed 10-10-2011] Ubiquity 2007 An Interview with Peter Denning on the great principles of computing Ubiquity 2007 1-1 Wing J 2006 Computational thinking Commun ACM 49 33-35 Wing J 2007 Computational Thinking [Online] Available http//wwwcscmuedu/afs/cs/usr/wing/www/Computational _Thinkingpdf [Accessed 14-12-12] Wing J 2008 Computational thinking and thinking about computing Philosophical Transactions of The Royal Society A 366 3717-3725 Wing J 2011 Research Notebook Computational Thinking - What and Why? The Link Pittsburgh PA Carneige Mellon 
Review Demystifying computational thinking Valerie J Shute a  Chen Sun a Jodi Asbell-Clarke b a Florida State University USA b TERC USA articleinfo abstract Educational Research Review 22 (2017) 142e158 Contents lists available at ScienceDirect Educational Research Review journal homepage wwwelseviercom/locate/edurev Article history Received 4 March 2017 Received in revised form 17 July 2017 Accepted 14 September 2017 Available online 20 September 2017 Keywords Computational thinking Computational literacy Problem solving Programming Contents This paper examines the growing field of computational thinking (CT) in education A review of the relevant literature shows a diversity in definitions interventions assess- ments and models After synthesizing various approaches used to develop the construct in K-16 settings we have created the following working definition of CT The conceptual foundation required to solve problems effectively and efficiently (ie algorithmically with or without the assistance of computers) with solutions that are reusable in different contexts This definition highlights that CT is primarily a way of thinking and acting which can be exhibited through the use particular skills which then can become the basis for performance-based assessments of CT skills Based on the literature we categorized CT into six main facets decomposition abstraction algorithm design debugging iteration and generalization This paper shows examples of CT definitions interventions assess- ments and models across a variety of disciplines with a call for more extensive research in this area © 2017 Elsevier Ltd All rights reserved 1 Introduction143 11 Definitionsofcomputationalthinking   143 12 Goalsandfocus   144 2 Method 144 21 Procedure 144 22 Inclusionandexclusioncriteria   144 3 Resultsfromtheliteraturereview   145 31 Characteristicsofcomputationalthinking 145 311 ComponentsofCT  145 312 DifferencesbetweenCTandothertypesofthinkingskills  145 313 RelationshipofCTwithcomputerscienceandprogramming  146 32 Interventionstodevelopcomputationalthinking 147 321 ResearchonCTusingprogrammingtools 147 322 Researchusingrobotics  148 323 Research using game design and other intervention tools                        148 324 CTskillsundergirdingprogrammingroboticsandgamedesign   149  Corresponding author E-mail address vshute@fsuedu (VJ Shute) https//doiorg/101016/jedurev2017090 03 1747-938X/© 2017 Elsevier Ltd All rights reserved VJ Shute et al / Educational Research Review 22 (2017) 142e158 143 33 Assessmentofcomputationalthinking  149 331 Scratch-basedassessments  149 332 Game/simulation-basedassessment 150 333 ValidatedCTscalesforgenericusage  150 34 Computationalthinkingmodels   150 4 Ourcomputationalthinkingdefinitionandframework   151 41 Comparisonwithothermodels  152 42 ExamplesofemergingmodelsofK-12CT 152 5 Discussion154 Acknowledgements 157 References 157 1 Introduction In the middle ages only select groups of people (eg priests and scribes) could read and write But as the world evolved increasingly more people needed these skills Today the rapid onset of computers in the 20th century is forcing an analogous revolution where digital literacy is now an essential skill to succeed in our complex digital 21st century world And although we don't all need to become software engineers the majority of us do use computers daily and need to understand how to communicate with them to most effectively harness their computing power Successful communication along these lines is called computational thinking (CT) Over the past decade CT has become a very hot topic in educational research and practice Thousands of entries appear on a general Google search regarding its definition instructional interventions and assessment Many of these entries suggest that CT relates to coding or programming but considering CT as knowing how to program may be too limiting According to the National Research Council (2010) everyone should acquire CT not only programmers CT skills include managing infor- mation effectively and efficiently with technologies in our data-driven era (Burke O'Byrne & Kafai 2016; Kim Kwon & Lee 2014; Lu & Fletcher 2009; Sanford & Naidu 2016; Wing 2010) A workforce with individuals possessing CT skills increases the competitiveness of the United States in the world economic market (NRC 2010) Although many programs claim to teach coding skills rarely do they look deeply at the ways of thinking used in CT Analogous to inquiry as a way of thinking scientifically CT is a set of practices that are entwined with ways of looking at problems that result in CT skills and understandings Yet there is no existing curriculum building a CT foundation of un- derstanding for young learners as there is in Math or Science Models are needed that help highlight CT within current classroom practices because there are too few opportunities to fit new content within existing school curricula Many problems presented in current curricula however can be approached with CT Possessing good CT skills may be a motivator for students to pursue computer science (Allan Barr Brylow & Hambrusch 2010) and other STEM-related majors (Sneider Stephenson Schafer & Flick 2014) CT has also been linked to creativity and innovation (Mishra Yadav & the Deep-Play Research Group 2013; Repenning et al 2015) and it has important applications in other STEM areas (Barr & Stephenson 2011; Sengupta Kinnebrew Basu Biswas & Clark 2013) An exact definition of CT however remains elusive (Barr Harrison & Conery 2011; Grover & Pea 2013) In this paper we discuss the various definitions of CT emerging from different disciplines and we present a definition of CT in terms of how K-12 educators might think of building a solid foundation for CT in young learners We break down CT into the components most often cited in the literature and propose a model for embedding CT learning and assessment within K-12 curricula 11 Definitions of computational thinking Computational thinking (CT) stems back to the constructionist work of Seymour Papert (Papert 1980 1991) and was first coined as a term in a seminal article by Wing (2006) She explained that CT entails “solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science” (Wing 2006 p 33) As such it represents an ability to analyze and then solve various problems Her arguments provided a fresh perspective on the re- lationship(s) between humans and computers and gave rise to a wave of research on CT The most oft-cited definition of CT comes from Cuny Snyder and Wing (2010) noting that CT is a thinking process where “ solutions are represented in a form that can be effectively carried out by an information-processing agent” (as cited in Wing 2010 p 1) This relates not only to well-structured problems but also ill-structured problems (ie complicated real-life problems whose solutions are neither definite nor measurable) Other researchers have come up with their own definitions relative to their particular research areas For instance Barr et al (2011) concluded that in K-12 CT involves problem-solving skills and particular dispositions such as confidence and persistence when confronting particular problems Berland and Wilensky (2015) defined CT as “the ability to think with the computer-as-tool” (p 630) and suggested using “computa- tional perspectives” as an alternative to “computational thinking” to emphasize that CT can be constrained by contexts 144 VJ Shute et al / Educational Research Review 22 (2017) 142e158 Additionally CT has been defined as “ students using computers to model their ideas and develop programs” (Israel Pearson Tapia Wherfel & Reese 2015 p 264) explicitly linking CT to programming skills As described above CT definitions vary in their operationalization of CT in certain studies and are not particularly generalizable (eg Berland & Wilensky 2015; Ioannidou Bennett Repenning Koh & Basawapatna 2011; Israel et al 2015) The definition of CT is evolving as researchers begin to aggregate knowledge about CT 12 Goals and focus In this paper we intend to explore the scope and complexity of CT and establish a clear definition and framework that will aid in the development of CT pedagogy and assessment particularly for K-12 At the end we provide current research examples and ideas for future research Our review addresses the following questions (1) What are the major charac- teristics and components of CT? (2) What interventions are (or may be) used to train/enhance CT? (3) What types of measures are used to assess CT? and (4) What are the main theoretical frameworks/models of CT? Again our main goal is to derive a general model of CT that may be used as a framework towards assessing and supporting CT Our model is derived from an extensive literature review and serves to guide the development of CT pedagogy and assessment in educational settings 2 Method 21 Procedure We began by collecting research papers relevant to CT including peer-reviewed publications and proceedings plus one academic report from a national workshop on CT We searched various databases using the keywords “computational thinking” (quotation marks included) and specified that the term occurred either in the title or in the abstract The following online databases and web sites were employed in this search-collection effort o ERIC The Educational Resources Information Center (ERIC) consists of Resources in Education Index and Current Index to Journals in Education ERIC is a broad and popular database containing educational reports evaluations and research o PsycINFO This site is hosted by the American Psychological Association which carries citations and summaries of scholarly journal articles book chapters books and dissertations in psychology and related disciplines o JSTOR A database of back issues of core journals in the humanities social sciences and sciences The gap between the most recently published issue of any journal and the date of the most recent issue available in JSTOR is from 2 to 5 years o Google Scholar This web site was employed to search for and acquire specific references Google Scholar is a web site providing peer-reviewed papers theses books abstracts and articles from academic publishers professional societies preprint repositories universities and other scholarly organizations We started the timeline in 2006 when Wing published her seminal article on CT signaling the beginning of a corpus of research and projects on the topic After collecting relevant papers we screened the articles again sorting them into con- ceptual papers and empirical studies Conceptual papers discussed the general features of CT providing a theoretical framework or suggesting instructional practices to integrate CT into education Empirical studies tended to test and justify specific interventions and measure(s) of CT via qualitative and quantitative research designs Finally we integrated the findings from the literature review with empirical research to create our competency model1 for CT aiming to facilitate and assess CT in educational settings 22 Inclusion and exclusion criteria In all approximately 70 documents e empirical as well as theoretical papers e were initially collected From this set a total of more than 45 documents met the criteria for inclusion in the literature review The inclusion criteria consisted of relevancy of the documents to the research topics in this article (eg computational thinking skills–characteristics and processes models assessments and interventions) Both experimental and non-experimental studies were included We created a table summarizing the full set of 70 papers collected then deleted papers from the list for the following reasons (a) poor quality research described in the paper (eg excessive statements and assumptions presented with inadequate support) (b) tangential or no focus specifically on CT (c) empirical papers that measured something other than CT as the outcome and (d) pilot studies that were low quality and/or reported a small sample size 1 A competency model refers to a collection of knowledge skills and other attributes that comprise a particular construct (such as CT) It answers the question What do you want to say about the person at the end of the assessment? Variables in the competency model are usually called “nodes” and describe the set of variables on which inferences are based VJ Shute et al / Educational Research Review 22 (2017) 142e158 145 3 Results from the literature review Our review consists of four main parts We begin by addressing the distinct characteristics of CT Next we examine in- terventions to support CT followed by CT assessments used in K-12 and higher education We end with a summary of CT research models 31 Characteristics of computational thinking In this section we define CT and distinguish it from other types of thinking (eg systems thinking and mathematical thinking) We also discuss CT's relationship with computer science 311 Components of CT Wing (2006) argued that CT does not mean to think like a computer; but rather to engage in five cognitive processes with the goal of solving problems efficiently and creatively These include 1 Problem reformulation e Reframe a problem into a solvable and familiar one 2 Recursion e Construct a system incrementally based on preceding information 3 Problem decomposition e Break the problem down into manageable units 4 Abstraction e Model the core aspects of complex problems or systems 5 Systematic testing e Take purposeful actions to derive solutions Abstraction is the main element undergirding CT (Wing 2008) where people glean relevant information (and discard irrelevant data) from complex systems to generate patterns and find commonalities among different representations (Wing 2010) Abstraction has layers so one must define each layer and clarify the relationships between layers This involves (a) abstraction in each layer (b) abstraction as a whole and (c) interconnection among layers For instance defining an algorithm is one kind of abstractiondthe “abstraction of a step-by-step procedure for taking input and producing some desired output” (Wing 2008 p 3718) In addition to abstraction and problem reformulation Barr et al (2011) argued that CT also consists of data organization and analysis automation efficiency and generalization Automation is making a process or system operate automatically; efficiency means creating optimal solutions; and generalization involves applying CT strategies to solve new problems Barr and colleagues also included certain dispositions important to CT such as confidence persistence in relation to solving complex tasks and the ability to work well in teams Similarly CT described by Bers Flannery Kazakoff and Sullivan (2014) includes abstraction generalization and trial and error activities They particularly emphasize the importance of debugging (ie identifying and fixing errors when solutions do not work as expected) In a comprehensive report by the National Research Council CT consists of five elements essential and universal across domains (NRC 2010) (1) hypothesis testing (2) data management (3) parallelism (4) abstraction and (5) debugging When solving a complex problem in any domain one should generate and test hypotheses systematically to understand how the system works It is impossible to test all possibilities so selecting the right parameters to test is important Data management involves gathering data from various sources processing data patterns and representing data in a meaningful way Paral- lelism refers to simultaneously processing information from multiple sources or dimensions Abstraction focuses on modeling the workings of a complex problem/system Finally debugging refers to finding and fixing errors after building up particular models Recently Anderson (2016) explicated five CT components (1) problem decomposition (2) pattern recognition (3) abstraction (ie generalization of repeated patterns) (4) algorithm design for solutions and (5) evaluation of solutions (ie debugging) Based on the foregoing review researchers have come up with similar CT constituent skills The components common among researchers are decomposition abstraction algorithms and debugging In our competency model CT similarly consists of decomposition abstraction algorithms debugging as well as iteration and generalization (see detailed defini- tions subcategorizations and justifications in Section 4) 312 Differences between CT and other types of thinking skills Researchers are also studying the differences and similarities between CT and other types of thinking (eg Barr et al 2011; Grover & Pea 2013) In this section we compare CT with mathematical engineering design and systems thinking Mathematical thinking involves the application of math skills to solve math problems such as equations and functions (Sneider et al 2014) Harel and Sowder (2005) defined mathematical thinking as global across many problems and “ governs one's ways of understanding” (p 31) Mathematical thinking consists of three parts beliefs about math problem solving processes and justification for solutions The main commonality between CT and mathematical thinking is problem solving processes (Wing 2008) Fig 1 shows the full set of shared concepts of computational and mathematical thinking problem solving modeling data analysis and interpretation and statistics and probability Engineering involves skills needed to build or transform things in the world in order to construct better lives (Bagiati & Evangelou 2016) as well as “applied science and math solving problems and making things” (Pawley 2009 p 310) The 146 VJ Shute et al / Educational Research Review 22 (2017) 142e158 Fig 1 Similarities and differences between CT and mathematical thinking Adapted from Sneider et al (2014) overlap between CT and engineering includes problem solving along with understanding how complex systems work in the real world (Wing 2008) However unlike engineering CT is intended to help humans understand complex phenomena through simulations and modeling which can transcend physical constraints (Wing 2010) To summarize CT mathematical thinking and engineering stem from different disciplines Their differences lie in specific applications in their own domain Design thinking requires one to solve problems by thinking as a designer (Razzouk & Shute 2012) Computational thinking and design thinking both focus on problem solving Design thinking like engineering focuses on product specification and the requirements imposed by both the human and the environment (ie practical problems) Again CT is not limited by physical constraints enabling people to solve theoretical as well as practical problems Systems thinking refers to the ability to understand various relationships among elements in a given environment (Shute Masduki & Donmez 2010) According to the competency model developed by Shute et al (2010) people with system thinking skills should be able to (a) define the boundaries of a problem/system (b) model/simulate how the system works conceptually (c) represent and test the system model using computational tools and (d) make decisions based on the model Although CT and systems thinking both involve understanding and modeling systems CT is broader than systems thinking which focuses on identifying and understanding the workings of a system as a whole CT aims to solve problems efficiently and effectively going beyond modeling and understanding to include algorithmic design automation and generalization to other systems/problems In conclusion CT is an umbrella term containing design thinking and engineering (ie efficient solution design) systems thinking (ie system understanding and modeling) and mathematical thinking as applied to solving various problems 313 Relationship of CT with computer science and programming Another area in need of clarification involves the relationships among CT computer science and programming (Czerkawski & Lyman 2015) And although CT originates from computer science (Wing 2006) it differs from computer science because it enables people to transfer CT skills to domains other than programming (Berland & Wilensky 2015) CT skills are not the same as programming skills (Ioannidou et al 2011) but being able to program is one benefit of being able to think computationally (Israel et al 2015) For instance Shute (1991) examined the relationships among programming skills prior knowledge and problem-solving skills within 260 college and technical school students Participants who had no prior programming experience learned programming skills via an intelligent tutoring system Several assessments were administered to measure learners' incoming knowledge (ie math and word knowledge) cognitive skills (ie working memory and information processing speed) and particular aspects of problem-solving skills (eg problem identification sequencing and decomposition) In addition a criterion test was used to measure learners’ programming skills and knowledge after the intervention Results from a factor analysis and hierarchical regression showed that working memory problem identification and sequencing solutions are the best predictors of programming skill acquisition Thus CT and programming skills as well as problem solving are closely related In general the field of computer science is broader than just learning about programming and CT is broader than com- puter science (NRC 2010; Wing 2006) in that CT includes a way of thinking about everyday activities and problems In line with this perspective Lu and Fletcher (2009) proposed that teaching CT should not even use programming languages; instead the language should be based on notions that are familiar to most students to engender the acquisition of concepts like VJ Shute et al / Educational Research Review 22 (2017) 142e158 147 abstraction and algorithms Like with most of the research targeting CT its particular relationship to computer programming is evolving 32 Interventions to develop computational thinking Researchers have attempted to leverage programming tools robotics games/simulations and non-digital interventions to teach CT knowledge and skills in various educational contexts The target population ranges from kindergarten to un- dergraduates Table 1 summarizes all of the research studies we reviewed arrayed by intervention tools 321 Research on CT using programming tools Due to its close relationship with computing and programming CT skills appear to be improved via computational tools such as Scratch (MIT 2003) Regarding the equivalence of programming skills to CT skills Cetin (2016) compared the effects of employing Scratch (experimental group) with C language (control group) to teach programming concepts to pre-service IT teachers This experiment lasted for six weeks and the participants (n 1⁄4 56) completed pre- and posttests relative to their achievement on and attitudes toward programming Additionally nine participants per group were randomly selected to attend semi-structured interviews Results showed the experimental group performed significantly better than the control group in terms of programming knowledge and skills but there were no between group attitudinal differences To promote algorithmic thinking via Scratch Grover Pea and Cooper (2015) designed a seven-week Scratch-based CT course for 7th and 8th graders (n 1⁄4 54) Similar to Cetin’s (2016) study CT gain was measured as pretest to posttest improvement on programming skills The aim of this quasi-experiment was to see which approach (face-to-face instruction vs face-to-face plus online) supported deep learning relative to computational concepts such as algorithms loops condi- tionals and decomposition The two conditions were matched in terms of receiving comparable instruction for the same duration of time (ie four days per week 55 min per day across seven weeks) Findings revealed that both approaches lead to significantly higher CT gains and students in the face-to-face plus online group performed significantly better than those in the face-to-face group Moreover both groups successfully transferred their programming knowledge and skills to text-based programming tasks The strength of Scratch is to help young people learn to think creatively reason systematically and work collaboratively and thus is suitable to facilitate CT It is easy to use with its drag-and-drop programming method and provides a meaningful learning environment where learners engage in specific contexts Alice (Carnegie Mellon University 1999) functions similarly equipped with ready-made code blocks Compared with Scratch it focuses on creating 3D programming projects It also can be utilized to train CT For example Denner Werner Campe and Ortiz (2014) randomly assigned 320 middle school students to either a dyadic work group or individual programming Students' CT skills were measured by their ability to accomplish Alice tasks during one semester's course Results demonstrated that students working collaboratively achieved significantly higher CT scores than students working alone And collaboration was especially beneficial to students with minimal Table 1 Articles reviewed sorted by intervention tools Study Cetin 2016 Grover et al 2015 Denner et al 2014 Werner et al 2012 Atmatzidou & Demetriadis 2016 Berland & Wilensky 2015 Basu et al (2017) Bers et al 2014 Kim et al 2013 Yadav et al 2014 Setting Higher education Middle school Middle school Middle school High school Middle school Middle School Kindergarten Middle school Higher education Higher education Participants 56 Undergrads (pre-service teachers) 54 7th and 8th graders 320 students 311 students 164 students 78 8th graders 98 6th graders 53 students 51 students 110 sophomores (pre-service elementary teachers) 141 undergrads Intervention Program Scratch; C language Scratch Alice (solo vs pairs) Alice (solo vs pairs) Lego Mindstorms Robotics Lego vs virtual robotics CTSiM platform TangibleK Robotics Snap; Small Basic PPS CT module Duration 6 weeks 7 weeks One semester One semester One year 5 days 13 days 20 h 3h 15 weeks One week Content Computer science CT course Programming Programming CT course Science Ecology CT CT course Poem Computer science Educational psychology Measures Multiple-choice; open- ended questions; surveys; interviews Multiple-choice; quizzes; assignments; text-based coding; projects Surveys; tasks Surveys; tasks Questionnaires; think- aloud; interviews Log files; tests; questionnaires Questions; explanations; constructing algorithms Questionnaires Fill-in-the-blanks; questions; Multiple-choice; surveys Questionnaires 148 VJ Shute et al / Educational Research Review 22 (2017) 142e158 programming experience These findings are consistent with those reported in an earlier experiment conducted by Werner Denner Campe and Kawamoto (2012) testing 311 middle school students Basu Biswas and Kinnebrew (2017) similarly viewed CT constructs as programming-related concepts such as sequencing loops and variables; and they considered iteration problem decomposition abstraction and debugging as CT practices They designed the CTSiM platform to integrate ecology and CT learning for 6th graders Basu et al employed a pretest/posttest design to test the effectiveness of scaffolding provided by a virtual agent embedded in CTSiM Both the experimental (n 1⁄4 52) and control (n 1⁄4 46) groups learned CT and ecology via CTSiM but only the experimental group received scaffolding That is when students failed a given task 3e5 times scaffolding was triggered In that case the virtual agent provided conversation prompts and the students answered by choosing one of the options which in turn triggered a response from agent Agent- student conversations were pre-programmed to help struggling students In the control group such functionality was disabled The ecology tests required students to choose correct answers and provide rationales for their answers The CT tests required students to predict outcomes after reading program segments and build algorithms with CT constructs to model scenarios Pre- and posttests showed significant gains in both groups on ecology and CT And when pretest scores were used as a covariate the experimental group (with scaffolding) significantly outperformed the control group in ecology learning gains and CT skills with effect sizes of 036 and 031 respectively 322 Research using robotics Another fruitful area in which to develop CT skills is robotics which is also closely related to programming Lego robotics is particularly popular For example Lego Mindstorms (http//wwwlegocom/en-us/mindstorms) was used to improve high school students’ (n 1⁄4 164) CT skills for a year (Atmatzidou & Demetriadis 2016) The 44 two-hour sessions focused on developing the following CT skills decomposing problems abstracting essential information generalizing the solution to different problems creating algorithms and automating procedures Solving robot programming problems revealed students’ CT skills which were measured via rubrics related to the quality of problem-solving performance Quantitative data showed that all participants regardless of their age or gender improved similarly on their CT skills following the intervention Qualitative data generated from interviews and think-aloud protocols confirmed the effectiveness of robotics to develop CT concepts and solve problems effectively Lego robotics is a physical activity Berland and Wilensky (2015) compared the effects of Lego robotics (n 1⁄4 34) versus virtual robotics (n 1⁄4 44) among 8th graders Pre- and posttests on pseudo-code programming measured CT gains Both groups of students significantly improved their CT skills and there was no significant posttest difference between the two groups It is interesting to note that the two groups perceived the problems differently That is the virtual robotics group tended to perceive the problem as a whole and then attempt to decompose the problem down to its details; while the physical robotics group initially focused on the constituent parts How early can children learn CT skills? One study looked at teaching kindergarten students (n 1⁄4 53) CT skills (Bers et al 2014) These researchers developed the TangibleK Robotics curriculum (http//asetuftsedu/DevTech/tangiblek/) which included 20 h of instruction and one final project to measure students' development of CT in terms of debugging sequencing loops and conditionals However repeated measures between tasks did not reveal any linear CT development in kindergarten students The researchers speculated that either (a) kindergarten students are simply too young to develop CT skills or (b) the robotics intervention was too difficult for them (Bers et al 2014) Therefore it is important to teach CT concepts in a way suitable for students’ developmental stages 323 Research using game design and other intervention tools AgentSheets is an authoring tool that uses game design to teach CT as well as to promote students' interest and skills in computer science (see Ioannidou et al 2011 for details) AgentSheets provides a low entry bar for inexperienced students yet does not restrain students with advanced abilities from creating complex game systems In one study teachers and com- munity college students in two summer workshops learned how to animate interactions among objects via programming using five AgentSheets design tasks (Basawapatna Koh Repenning Webb & Marshall 2011) Unlike other studies this research measured CT based on students' knowledge of relevant patterns defined as object interactions such as collision and absorption These CT patterns represent the intersection of games and science simulations After two weeks of intervention the authors tested the participants’ CT skills with eight questions each representing a phenomenon sharing CT patterns across the five games (eg sledding collision) Participants needed to identify and justify usage of the CT patterns to create simulations of the phenomena Generally all participants did very well in correctly identifying CT patterns as indicated by the percent correct of their responses However the authors noted that the results do not necessarily mean that students could transfer CT knowledge from game design to simulations of scientific phenomena Teaching CT does not necessarily require digital tools A paper-and pencil programming strategy (PPS) was created for non-computer science majors (n 1⁄4 110) (Kim Kim & Kim 2013) It enabled participants (n 1⁄4 55) in one group to choose their preferred way to visualize and represent programming ideas (eg via concept maps tables words or symbols) Its effects were compared to another group who engaged in typical course instruction (n 1⁄4 55) for 15 weeks Typical instruction in this case refers to the regular programming course using LOGO (Softronics Inc 2002) Pre- and posttests revealed that students using the paper-and-pencil programming strategy showed significantly better understanding of CT and more interest in CS than those learning via typical course instruction The authors therefore argued that teaching CT without computers might be effective and efficient for non-computer science majors VJ Shute et al / Educational Research Review 22 (2017) 142e158 149 A lecture-based CT instructional module could also change pre-service teachers’ understanding of and attitudes toward integrating CT in their classrooms (Yadav Mayfield Zhou Hambrusch & Korb 2014) The researchers tested a 100-min module focused on CT concepts such as decomposition abstraction algorithms and debugging After training participants completed questionnaires with open-ended questions related to CT and its connections with various disciplines Compared to the no-treatment control group (n 1⁄4 154) a higher percentage of those in the experimental group (n 1⁄4 141) who received the CT training considered CT a way of thinking to solve problems with or without the help of computers Moreover they realized that CT was not restricted within the field of computer science Conversely the control group viewed CT narrowlydas using computers to complete specific computing tasks and restricted to subjects involving computers like computer science and math 324 CT skills undergirding programming robotics and game design The rationale for using programming robotics and game design to improve CT skills is because each one of these areas emphasizes various CT components For instance writing computer programs requires the analysis of the problem (eg determining the goal to achieve) and then breaking the problem down to its constituent processes (eg identifying sub-goals and associated steps to achieve the goal) Writing efficient programs requires abstraction and generalization For instance if one step needs to be repeated four times an efficient solution involves looping the step rather than writing the same code four times Additionally part of the programming code may be reused within similar problems with minor adjustments rather than rewriting a new program from scratch And to test the correctness and efficiency of a program debugging is necessary That is why programming is frequently used to promote CT skills Similarly robotics provides learners with tactile experiences to solve problems via CT skills Learners need to identify the general problem/goal for the robot then decompose the problem (eg figuring out the number of steps or sub-goals to accomplish the goal) Towards this end learners develop algorithms for the robot so that it can follow the instructions and act accordingly When the robot does not act as expected debugging comes into play Debugging requires the iterative processes of systematic testing and modifying Finally as with programming and robotics game design and gameplay entail various goals for players to solve These can be smaller goals represented within levels of the game and larger goals represented by boss levels and/or part of the narrative To succeed players need to derive solution plans and if a plan fails then a modified plan is developed By sys- tematically testing various plans players find the most effective strategy to overcome challenges in the game Moreover skillful players are able to adopt strategies used before to solve new problems Thus problem decomposition systemic testing and debugging generalization and iteration are skills required in gaming and are important components of CT 33 Assessment of computational thinking Because of the variety of CT definitions and conceptualizations it's not surprising that accurately assessing CT remains a major weakness in this area There is currently no widely-accepted assessment of CT This makes it difficult to measure the effectiveness of interventions in a reliable and valid way (Grover & Pea 2013; Kim et al 2013; Settle et al 2012) Having no standard CT assessment also makes it very difficult to compare results across various CT studies Researchers tend to develop and apply their own CT measures in various studies depending on their particular operationalization of CT (Kim et al 2013) Questionnaires and surveys are the most commonly used measure for knowledge of and/or attitudes towards CT (eg Atmatzidou & Demetriadis 2016; Denner et al 2014; Yadav et al 2014) For instance Cetin (2016) used surveys to measure preservice teachers' conceptual understanding of programming constructs like arrays and loops as well as attitudes towards computer science Yadav et al (2014) similarly used surveys to examine pre-service teachers' understanding of CT and their attitudes toward integrating CT into their teaching in the future Kim et al (2013) designed questionnaire items to specifically measure college sophomores’ logical thinking as well as conceptual understanding of and interest in computer science Viewing CT as the core of computational literacy Jun Han Kim and Lee (2014) administered questionnaires on computational literacy among elementary school students Other researchers have conducted interviews and observations with participants to understand the development of CT skills (eg Cetin 2016; Israel et al 2015) Some of the researchers assessed CT skills through projects and related tasks For instance Denner et al (2014) and Werner et al (2012) developed a performance-based assessment to measure CT by letting middle schoolers complete projects such as a three-stage task designed with Alice Students needed to solve particular problems (eg saving a fairy from a magic forest) Other researchers tested learning gains of subject area knowledge after incorporating CT into disciplinary instruction (eg Cetin 2016; Sengupta et al 2013) 331 Scratch-based assessments Several groups of researchers have used Scratch to develop systematic CT assessments Brennan and Resnick (2012) claimed that Scratch-based projects could support long-term learning by making learning meaningful within a particular context They also argued for a dynamic measure to assess Scratch users' (8e17 years old) CT abilities over time revealing the progression of learning and measuring both conceptual understanding and application of CT skills Their CT assessment included formative analysis interviews and design projects The formative analysis involved evaluating users’ portfolios to see the development of CT via projects completed over time Interviews allowed the researchers to dig deeper into the thinking processes of users There were also three sets of design projects varying in difficulty which were employed as 150 VJ Shute et al / Educational Research Review 22 (2017) 142e158 performance measures Each set included two tasks of the same difficulty level but with different representations Users had to choose one task from each set to describe and debug To align with a particular Scratch-based CT course for middle schoolers Grover et al (2015) designed a system of formative and summative assessments to support and measure CT skills Multiple-choice items and quizzes throughout the course resembled the pseudo code in Scratch The items were used to consolidate students’ knowledge of programming concepts with timely feedback serving to explain various ideas and procedures Course assignments were completed using Scratch and were evaluated by specific rubrics The summative measure was a final test with multiple-choice items plus open-ended questions along with a final project that was completed with a partner In addition the researchers developed a test based on AP programming exams to test whether students could transfer what they had learned to real text-based pro- gramming code Another Scratch-based assessment is called PECT (progression of early computational thinking) designed for elementary school students (Seiter & Foreman 2013) This represents a guideline to measure three facets of CT The first facet included evidence variables which were collected directly from the command categories embedded in Scratch (eg operators and conditionals) The second facet was pattern variables (eg motion and interactivity) which are broader than the specific evidence from the pseudo code library in Scratch The last facet was CT concepts such as decomposition abstraction and algorithms Students’ proficiency levels (ie basic developing and proficient) per facet were measured according to rubrics 332 Game/simulation-based assessment Other researchers have proposed assessing CT via CT pattern analysis (CTPA) in K-12 schools CT patterns are abstract programming concepts related to object interactions that students use to develop games and simulations (Basawapatna et al 2011; Ioannidou et al 2011) Building object interactions in games required 12 CT patterns defined by Ioannidou et al (2011) Repenning et al (2015) subsequently refined those 12 patterns to nine aspects to measure transfer of CT from gaming to modeling scientific phenomena in STEM courses CTPA is used to generate spider web-like graphic reports of the nine pat- terns by comparing students' products with exemplars This type of report provides visual information about the nature and degree of students' abilities and which aspects need improvement Reports over time can demonstrate students’ progression of CT skills Thus teachers could provide instructional support given access to such graphic reports 333 Validated CT scales for generic usage The aforementioned assessments were designed solely for the purpose of a particular study based on a specific inter- vention Recently researchers have developed a scale to measure CT (Roman-Gonzalez Perez-Gonzalez & Jimenez- Fernandez 2017) This scale includes 28 items and takes about 45 min to complete It focuses on computational concepts like directions and sequences loops if conditionals and simple functions The reliability of this scale is 079 The authors tested its validity among 1251 Spanish students from 5th to 10th grades The results showed significant correlations with other standardized tests on mental abilities and problem-solving skills The problem-solving test explained 447% of the variance in the CT scale while the mental ability test explained 27% Thus the authors concluded that CT is more similar to problem solving skills and less aligned with reasoning spatial and verbal abilities Similar efforts have been conducted and reported by Korkmaz Çakir and O€zden (2017) The researchers developed a CT scale comprised of 29 items measuring five factors (ie creativity cooperation algorithmic thinking critical thinking and problem solving) They first conducted exploratory factor analysis (n 1⁄4 726) and then confirmatory factor analysis (n 1⁄4 580) among Turkish college students The results showed good data fit indices and evidence that the items measured targeted constructs The reliabilities for the five factors ranged from 073 to 087 This scale measures CT differently from the previous one because the researchers operationalized CT differently based on their own CT framework (described in Section 34) In conclusion this review of CT assessments showcases the pressing need for a reliable and valid assessment of CT skills across educational settings so that researchers can determine whether their CT interventions are effective or not rather than just looking at learning gains or attitudinal changes via homegrown measures The assessment of CT also calls for dynamic information that can reflect learners’ abilities and progression over time 34 Computational thinking models Having reviewed CT components interventions and assessments this section examines theoretical frameworks of CT As with CT definitions and assessments there are no agreed-upon models or frameworks for CT (Atmatzidou & Demetriadis 2016) In this section we examine four CT models proposed by researchers First Atmatzidou and Demetriadis (2016) presented a simple descriptive CT model based on their operationalization of CT in previous studies The model consists of five facets abstraction generalization algorithms modularity and decom- position It also provides examples of behaviors that students should demonstrate as evidence for each facet (see Atmatzidou & Demetriadis 2016 p 664 for details) Briefly abstraction means distilling the core patterns from complicated systems; generalization involves applying problem-solving strategies to different contexts; algorithms refer to ordered steps/in- structions to implement solutions; modularity means the automation of problem-solving solutions; and decomposition entails the breakdown of complex systems/things into manageable pieces The second model consists of CT concepts and abilities that should be incorporated into K-12 courses like math science social studies and language arts (see Barr & Stephenson 2011 p 52) It defines core CT facets (ie data collection data VJ Shute et al / Educational Research Review 22 (2017) 142e158 151 analysis data representation decomposition abstraction algorithms automation parallelism and simulation) across various disciplines These CT facets should have different representations in different subjects (eg representing data with charts or tables in math and representing linguistic patterns in language arts) However the specific demonstrations of CT facets within particular disciplines are not clearly stated in the paper Moreover the provided examples of teaching practices are too vague for teachers to actually employ them For example abstraction in science class is described only as modeling a physical entity The weakness of this model stems from (a) no clear definitions per CT facet making operationalization very difficult and (b) failure to distinguish concepts from abilities (eg abstraction is both a concept and an ability) Thus this model has room for improvement before serving as a guideline for teachers in K-12 education Brennan and Resnick (2012) presented a CT framework within the context of using Scratch to facilitate CT They catego- rized CT into three areasdconcepts practices and perspectives Table 2 shows our summary of their framework A review paper on integrating CT in K-12 settings by Lye and Koh (2014) was based on the Brennan and Resnick framework Later Zhong Wang Chen and Li (2016) revised that model (see p 565 for details) by adding instruction into the CT concepts and iteration into the CT practices They also rephrased CT perspectives to emphasize creativity and collaboration However they did not elaborate on those modifications which makes it hard to interpret the revised model A fourth recent model aims to merge CT and regular classroom instruction (Weintrop et al 2016) The researchers analyzed 34 lesson plans for high school math and science courses by coding teaching practices that related to CT facets Then they categorized the specific facets into broader CT practices and refined the categorization after consulting with lesson plan designers in-service high school teachers and experts in CT and curriculum design Finally they came up with a taxonomy containing four CT categories with 22 CT practices (see Table 3) Their taxonomy is based on specific classroom activities and presented concrete examples of CT classroom activities showing how lesson plans can be designed by following the tax- onomy This model is tailored to STEM courses in high school and shows promise with regard to integrating CT in secondary education However more research is needed to validate this model Lacking a consistent model might cause problems in designing interventions to support CT learning and in assessing CT knowledge and skills in various educational settings This leads to the next part of this paper; namely our proposed com- petency model of CT which can be used to guide assessment and support of CT skills 4 Our computational thinking definition and framework Drawing from the aforementioned definitions and models we define CT as the conceptual foundation required to solve problems effectively and efficiently (ie algorithmically with or without the assistance of computers) with solutions that are reusable in different contexts As stated earlier the components of CT that arise most often in the literature are abstraction decomposition algorithms and debugging Our model attempts to understand the cognitive processes underlying each of these CT facets and the associated behaviors that can help us develop a competency model that can be used for the assessment of CT We additionally identify iteration and generalization as two more skills that are important in the devel- opment of CT Our model of CT emphasizes the importance of approaching problems in a systematic way Problem decomposition involves breaking a complex problem into smaller parts and using systematic processes to tackle each of those smaller problems Iterative systematic debugging ensures that each part of the smaller problems is solved efficiently and with no loose ends Abstraction is the act of finding patterns within problems and solutions and thus being in a position to generalize solutions for sets of similar problems Finally algorithm design allows the development of re-usable tools/procedures for solving classes of problems Based on prior research we have categorized CT into six main facets decomposition abstraction algorithms debugging iteration and generalization The six facets of our CT model are described in Table 4 This framing of CT underpins and may be evidenced through a variety of K-12 subject areas including Mathematics Science and even English Language Arts Table 2 Summary of CT framework proposed by Brennan and Resnick (2012) CT Concepts CT Practices CT Perspectives Sequences Instructions for computer to execute behaviors Loops Repeat the same instruction for a specified number of times Parallelism Concurrence of multiple instructions Events Triggers for certain actions to happen to create interactive environments Conditionals Constraints on execution of instructions allowing for different outcomes Operators Mathematical and string operations Data Data storage retrieval and update Being incremental and iterative Iterative processes to design and implement solutions step by step Testing and debugging Trial and error processes to test and remove malfunctions as warranted Reuse and remix Building reusable instructions; building new products on others' work Abstraction and modularity Modeling complex systems with basic elements Expressing Perception of computation as a way of expression and creation Connecting Perception of computation as a way of interacting and working with others Questioning Raising questions and using technology to solve real life problems 152 VJ Shute et al / Educational Research Review 22 (2017) 142e158 Table 3 Taxonomy of CT in STEM courses adapted from Weintrop et al (2016) CT Category Data Practices Modeling and Simulation Computational Problem Solving Systems Thinking 41 Comparison with other models CT Practice Data collection Data creation Data manipulation Data analysis Data visualization Conceptual understanding Testing solutions Model assessment Model design Model construction Solution preparation Programming Tools selection Solution evaluation Solution development Abstraction Debugging System investigation Understanding relationships Multilayered thinking Communication System management Definition Gather data using multiple computational tools Generate data for large and complex systems Reorganize data in a meaningful way Use computational tools to analyze data and draw valid conclusions Communicate and present data in multiple ways Understand concepts deeply through modeling Solve problems through hypothesis testing Evaluate the effectiveness of models Select essential elements for models Implement new models or extend existing models Decompose and reframe problems using suitable computational tools Possess basic programming knowledge and skills Evaluate pros and cons of plausible computational tools Assess pros and cons of possible solutions Develop solutions that can be applied to a wide range of problems Distill the most relevant information from a problem Identify and fix errors Understand system functions as a whole Understand the operation and interrelationship of elements in a system Think from multiple perspectives and levels Convey information effectively and efficiently Define scope of systems and manage complexity Our model focuses on the underlying conceptual foundation required to approach problems via a CT perspective and how that kind of CT perspective can be highlighted and supported in current K-12 subjects This is in contrast to models that focus on just one specific subject area such as Brennan and Resnick (2012) who limit their model of CT to concepts related to coding The three facets in their model are hierarchical with the foundation comprised of programming concepts like loops and conditionals Their next layer relates to computing practices built on the conceptual knowledge whereas the highest layer represents perspectives on computing (eg a way of expression creation and communication) Weintrop et al ’s 2016 model is derived from high school teaching practices that occur in STEM courses The four facets in their model represent a collection of possible classroom activities from which teachers can select the most relevant ones to facilitate CT acquisition Thus their model is restricted to high school STEM course settings where we feel that a foundational basis for CT starts much earlier analogous to scientific inquiry or mathematic reasoning 42 Examples of emerging models of K-12 CT Our competency-based model of CT knowledge and skills strives to inform assessment methods to measure the foun- dational understandings of CT in K-12 learners Several research groups are just starting attempts to measure CT in K-12 settings Here we present several examples ending with an illustration of the co-authors’ assessment-related work on the conceptual foundation of several important CT facets; namely problem decomposition abstraction and algorithm design As noted earlier several research groups are studying learners’ coding in Scratch A tool called Dr Scratch (http//www drscratchorg/) is currently in Beta test and used as the basis to analyze Scratch code by quantifying the usage of loops sequences and other logistical facets of coding outlined by Brennan and Resnick (2012) Researchers at SRI (Grover et al 2015) designed and implemented a middle school curriculum called Foundations for Advancing Computational Thinking (FACT) FACT strives to get a comprehensive picture of students’ CT skills by examining cognitive interpersonal and intrapersonal variables FACT uses pedagogical strategies to support transfer from block-based to text-based programming along with formative and summative assessments (including quizzes and tests as well as open- ended programming assignments) related to the acquisition of computational thinking skills Their findings show that stu- dents ages 11e14 using the FACT curriculum experience improved algorithmic learning understanding of computing and transfer of skills from Scratch to a text-based programming context Building on this research Grover (2017; see http// stemforall2017videohallcom/presentations/872) suggests a framing of Variables Expressions Loops and Algorithms (VELA) to prepare young learners for CT Research underway by EdGE at TERC2 involves studying the development of CT within the logic puzzle game Zoombinis EdGE studies how game-based behavior can predict implicit knowledge and help teachers support explicit STEM learning in 2 TERC is a non-profit studying math and science education innovations since 1966 In 2009 the Educational Gaming Environments group (EdGE) was founded to study STEM learning in digital games Table 4 Summary of our CT facets and their definitions VJ Shute et al / Educational Research Review 22 (2017) 142e158 153 Facet Decomposition Abstraction Algorithms Debugging Iteration Generalization Definition Dissect a complex problem/system into manageable parts The divided parts are not random pieces but functional elements that collectively comprise the whole system/problem Extract the essence of a (complex) system Abstraction has three subcategories (a) DatacollectionandanalysisCollectthemostrelevantandimportantinformationfrommultiplesourcesandunderstandthe relationships among multilayered datasets; (b) Pattern recognition Identify patterns/rules underlying the data/information structure; (c) Modeling Build models or simulations to represent how a system operates and/or how a system will function in the future Design logical and ordered instructions for rendering a solution to a problem The instructions can be carried out by a human or computer There are four sub-categories (a) Algorithm design Create a series of ordered steps to solve a problem; (b) Parallelism Carry out a certain number of steps at the same time; (c) Efficiency Design the fewest number of steps to solve a problem removing redundant and unnecessary steps; (d) Automation Automate the execution of the procedure when required to solve similar problems Detect and identify errors and then fix the errors when a solution does not work as it should Repeat design processes to refine solutions until the ideal result is achieved Transfer CT skills to a wide range of situations/domains to solve problems effectively and efficiently the classroom (Rowe Asbell-Clarke & Baker 2015) Implicit knowledge refers to knowledge that may not yet be formalized or expressed by a learner but may be evident through actions and behaviors In Zoombinis players engage in many cycles of CT strategy development that can be evidenced by their patterns of activity in the game In the game players are challenged to sort Zoombinis according to underlying logic rules (eg the puzzle named Allergic Cliffs will reject Zoombinis with certain features or a combination of features in upper levelsdsee Fig 2) Players typically move from trial-and-error (testing arbitrary Zoombinis) to a systematic testing pattern where they use problem-solving strategies some of which researchers can identify as evidence of CT For instance players may consistently test if Zoombinis with one or more common features (eg those with glasses) help the student identify a pattern to solve the Fig 2 Screen capture of the “Allergic Cliffs” level in Zoombinis 154 VJ Shute et al / Educational Research Review 22 (2017) 142e158 puzzle This change from trial-and-error to systematic testing provides evidence of problem decomposition As players accumulate evidence they may see common patterns and start testing towards a partial solution eventually demonstrating their ability to abstract the patterns into an underlying rule of the puzzle Successful players exhibit repeated strategies or algorithms implemented over a collection of puzzles For example once players adopt the strategy of trying one variable at a time and then implementing singular pieces of information into a final solution that pattern can be observed across multiple puzzles (and other problem-solving situations) To validate student learning of these facets of CT as a function of playing Zoombinis EdGE and Empirical Games have designed a set of online assessment items that focus on several of the fundamental facets of CT problem decomposition abstraction and algorithm design Researchers are currently completing a validation study with 300 elementary and middle school learners The assessments were conceptually and structurally the same for both elementary and middle school stu- dents but differed in terms of difficulty (eg based on number of variables to consider in a pattern and size of the array for abstraction problems) The example items shown in this paper are from the elementary school version of the assessment The assessment for problem decomposition uses a series of progressively harder puzzles similar to the game called Mastermind (the board game developed by Meirowitz in 1970; see https//boardgamegeekcom/boardgame/2392/ mastermind) where learners must use feedback from the game to figure out which values per graphical feature (color and/or shape and/or pattern) are required to solve a puzzle (see Fig 3; left side is the initial problem and right side is receiving feedback on the current test) The learner needs to drag one object at a time into the test box to find the correct color (and in more difficult levelsdalso shape and pattern) in as few tries as possible Incorrect choices are placed in the “not solutions” box Feedback per object is represented by a green check per correct color/shape/pattern and a red X for an incorrect attribute For abstraction pattern-matching puzzles require learners to identify an underlying rule The learners drag objects from a pool on the right into the gray cells on the left to complete the pattern and thus applying the inferred rule Each colored shape can only appear once in the solution See Fig 4 For algorithm design players must align a sequence of arrows (in advance) to guide a character along a path in a maze that fits specified criteria In Fig 5 the sequencing task requires the learner to insert directional arrows along with the number of iterations as warranted to guide a leprechaun to a pot of gold in the fewest steps possible while avoiding certain obstacles Finally the CT assessment for the Zoombinis study includes a set of general pattern recognition items (Raven's Progressive Matrices RPM; Raven 1981) as a baseline of learners' ability to infer and apply different patterns in increasingly complex situations Raven (2000) pointed out that the RPM focuses on two components of general cognitive abilityeeductive and reproductive ability Eductive ability involves making sense out of chaos and generating high-level schema to handle complexity Reproductive ability is the ability to recall and reproduce information that has been explicated Rule application in general is the behavior of following the basic rules of a problem in order to solve the problem It is an outward expression of the solvers' perception of the problems' features via both eductive and reproductive abilities An example is shown in Fig 6 For each item learners click and drag the correct option among the eight possible options at the bottom to complete the pattern at the topdwhere the solution applies horizontally vertically and diagonally These assessments strive to examine the fundamental cognitive underpinnings of CT in an abstract and non-contextual manner EdGE is using these assessments in combination with Educational Data Mining of game behaviors in Zoombinis and observations of classroom CT learning to get a full picture of CT learning of students in grades 3e8 5 Discussion In this review we analyzed existing definitions of CT with a focus on literature that could help describe the conceptual foundation of CT that should guide learning and assessment in K-12 settings We discussed how CT is similar to and distinct from other ways of thinking (eg mathematical thinking and systems thinking) and described the relationships between CT Fig 3 Simple item in CT assessment for problem decomposition VJ Shute et al / Educational Research Review 22 (2017) 142e158 155 Fig 4 Example item in CT assessment for abstraction Fig 5 Simple sequencing/algorithmic design item in CT assessment and computer science We reviewed interventions and assessments used to develop and measure learners’ CT skills ranging from kindergarten to college level Finally we presented examples of research striving to measure the development CT in experiences for K-12 learners Our goal with this review paper was to synthesize the literature in order to provide a general framework of CT including its definition facets and elaboration per facet to develop a model of CT that guides K-12 CT learning and assessment 156 VJ Shute et al / Educational Research Review 22 (2017) 142e158 Fig 6 Example CT assessment item from Raven's for pattern identification This review of the literature has shed light on a number of gaps in CT research For instance a generally agreed-upon definition of CT is missing in the literature along with a specification of its components (Wing 2008) Inconsistent term usage occurs in many papers such as conflating computer science computer programming and CT (Czerkawski & Lyman 2015; Israel et al 2015) The immaturity of the field that results in this ambiguity is compounded when looking at education Teachers are generally unfamiliar with CT and have difficulty finding connections between CT and their current curricula Designing and developing a reliable and valid CT assessment is key to successful education of CT embedded in multiple disciplines (Grover & Pea 2013) But lacking a standard definition to operationalize CT consequently leads to research where measurements vary greatly across studies which makes the results less convincing and certainly difficult to compare Another issue that needs to be resolved concerns the difficulty in judging whether in-class CT interventions actually achieve their desired results (Settle et al 2012) Again researchers have pointed out the difficulty of assessing CT in class- rooms and have called for real-time assessment to provide learning progression data per student to support teachers’ in- struction (Bers et al 2014; Wolz Stone Pearson Pulimood & Switzer 2011) The framework we have proposed can be a guideline to develop assessment tasks that elicit evidence for specific CT skills The examples we present of how CT is being measured in Scratch Zoombinis and FACT are intended to highlight these possibilities Studies on transfer of CT are also needed (Bers et al 2014) One problem is how to identify the application of CT in other domains (Czerkawski & Lyman 2015) Efforts have been made by a few researchers such as Ioannidou et al (2011) who tried to examine the transfer of CT acquired from games to math and science courses Similarly Repenning et al (2015) aimed to investigate transferred CT skills from games to the creation of simulations of scientific phenomena Grover et al (2015) found that students could apply computational concepts learned from Scratch to specific text-based programming languages which is quite promising In any case the long-term retention of CT skills along with the application of CT skills to other contexts and domains is under-researched A final area deserving research attention involves gender differences in the development of CT Females are often un- derrepresented in STEM related subjects particularly once they reach college Researchers may consider utilizing CT to motivate learners especially females to major in science fields (eg Grover & Pea 2013; Kazimoglu Kiernan Bacon & Mackinnon 2012; Repenning et al 2015) However the results of studies examining gender differences are inconsistent Atmatzidou and Demetriadis (2016) reported that girls’ CT skills improved significantly after intervention and that ultimately girls and boys reached the same skill level Girls tend to spend significantly more time learning online after school resulting in VJ Shute et al / Educational Research Review 22 (2017) 142e158 157 better performance than boys (Grover et al 2015) However no gender differences were reported by Werner et al (2012) and Yadav et al (2014) Computational thinking needs to be demystified (eg Barr & Stephenson 2011) Towards this end we have developed a definition and shown examples of a model that (a) considers CT as a logical way of thinking not simply knowing a pro- gramming language; (b) particularly focuses on conceptual development required to engage in problem decomposition abstraction algorithmic design debugging iteration and generalization; (c) examines performance-based competencies related to each of these facets of CT and (d) can be strengthened and emphasized within existing (eg STEM) curricula Our CT model presented in this paper is intended to be broadly applicable while specific enough to inform measurement of CT learningdoverall and at the facet level (for diagnostic purposes) Current research is in progress to validate this claim We anticipate the next few years will bring many empirical studies to help refine this model for use across wide-ranging contexts Acknowledgements This research did not receive any specific grant from funding agencies in the public commercial or not-for-profit sectors Co-Author XXX gratefully acknowledges funding from the US National Science Foundation and intellectual support from the EdGE at TERC team This work is most closely related to grant NSF/DRL/DRK12/#0150228 References Allan V Barr V Brylow D & Hambrusch S (2010 March) Computational thinking in high school courses In Proceedings of the 41st ACM technical symposium on computer science education (pp 390e391) ACM Anderson N D (2016) A call for computational thinking in undergraduate psychology Psychology Learning & Teaching 15 226e234 http//dxdoiorg/10 1177/1475725716659252 Atmatzidou S & Demetriadis S (2016) Advancing students' computational thinking skills through educational robotics A study on age and gender relevant differences Robotics and Autonomous Systems 75 661e670 http//dxdoiorg/101016/jrobot201510008 Bagiati A & Evangelou D (2016) Practicing engineering while building with blocks Identifying engineering thinking European Early Childhood Education Research Journal 24(1) 67e85 http//dxdoiorg/101080/1350293X20151120521 Barr D Harrison J & Conery L (2011) Computational thinking A digital age skill for everyone Learning & Leading with Technology 38(6) 20e23 Barr V & Stephenson C (2011) Bringing computational thinking to K-12 What is involved and what is the role of the computer science education community? ACM Inroads 2 48e54 http//dxdoiorg/101145/19298871929905 Basawapatna A Koh K H Repenning A Webb D C & Marshall K S (2011 March) Recognizing computational thinking patterns In Proceedings of the 42nd ACM technical symposium on computer science education (pp 245e250) ACM Basu S Biswas G & Kinnebrew J S (2017) Learner modeling for adaptive scaffolding in a computational thinking-based science learning environment User Modeling and User-adapted Interaction 27(1) 5e53 Berland M & Wilensky U (2015) Comparing virtual and physical robotics environments for supporting complex systems and computational thinking Journal of Science Education and Technology 24 628e647 http//dxdoiorg/101007/s10956-015-9552-x Bers M Flannery L Kazakoff E & Sullivan A (2014) Computational thinking and tinkering Exploration of an early childhood robotics curriculum Computers & Education 72 145e157 http//dxdoiorg/101016/jcompedu20131002 Brennan K & Resnick M (2012 April) New frameworks for studying and assessing the development of computational thinking In Proceedings of the 2012 annual meeting of the American educational research association (Vancouver Canada) Burke Q O'Byrne W I & Kafai Y B (2016) Computational participation Understanding coding as an extension of literacy instruction Journal of Adolescent & Adult Literacy 59 371e375 http//dxdoiorg/101002/jaal496 Cetin I (2016) Preservice teachers' introduction to computing Exploring utilization of scratch Journal of Educational Computing Research http//dxdoiorg/ 101177/0735633116642774 Advance online publication Cuny J Snyder L & Wing J M (2010) Demystifying computational thinking for non-computer scientists Unpublished manuscript referenced in http//www cscmuedu/~CompThink/resources/TheLinkWingpdf Czerkawski B C & Lyman E W III (2015) Exploring issues about computational thinking in higher education TechTrends 59(2) 57e65 http//dxdoiorg/ 101007/s11528-015-0840-3 Denner J Werner L Campe S & Ortiz E (2014) Pair programming Under what conditions is it advantageous for middle school students? Journal of Research on Technology in Education 46 277e296 http//dxdoiorg/101080/153915232014888272 Grover S (2011 April) Robotics and engineering for middle and high school students to develop computational thinking In Paper presented at the annual meeting of the American educational research association New Orleans LA Grover S & Pea R (2013) Computational thinking in Ke12 A review of the state of the field Educational Researcher 42(1) 38e43 http//dxdoiorg/10 3102/0013189X12463051 Grover S Pea R & Cooper S (2015) Designing for deeper learning in a blended computer science course for middle school students Computer Science Education 25 199e237 http//dxdoiorg/101080/0899340820151033142 Harel G & Sowder L (2005) Advanced mathematical-thinking at any age Its nature and its development Mathematical Thinking and Learning 7(1) 27e50 http//dxdoiorg/101207/s15327833mtl0701_3 Ioannidou A Bennett V Repenning A Koh K H & Basawapatna A (2011 April) Computational thinking patterns In Paper presented at the annual meeting of the American educational research association New Orleans LA Israel M Pearson J Tapia T Wherfel Q & Reese G (2015) Supporting all learners in school-wide computational thinking A cross-case qualitative analysis Computers & Education 82 263e279 http//dxdoiorg/101016/jcompedu201411022 Jun S Han S Kim H & Lee W (2014) Assessing the computational literacy of elementary students on a national level in Korea Educational Assessment Evaluation and Accountability 26 319e332 http//dxdoiorg/101007/s11092-013-9185-7 Kazimoglu C Kiernan M Bacon L & Mackinnon L (2012) A serious game for developing computational thinking and learning introductory computer programming Procedia-social and Behavioral Sciences 47 1991e1999 Kim B Kim T & Kim J (2013) Paper-and-pencil programming strategy toward computational thinking for non-majors Design your solution Journal of Educational Computing Research 49 437e459 http//dxdoiorg/102190/EC494b Kim Y C Kwon D Y & Lee W G (2014) Computational modeling and simulation for learning an automation concept in programming course Inter- national Journal of Computer Theory and Engineering 6 341e345 http//dxdoiorg/107763/IJCTE2014V6886 Korkmaz O€ Çakir R & O€zden M Y (2017) A validity and reliability study of the computational thinking scales (CTS) Computers in Human Behavior 72 558e569 Lu J J & Fletcher G H (2009 March) Thinking about computational thinking ACM SIGCSE Bulletin 41(1) 260e264 158 VJ Shute et al / Educational Research Review 22 (2017) 142e158 Lye S & Koh J (2014) Review on teaching and learning of computational thinking through programming What is next for K-12? Computers in Human Behavior 41 51e61 http//dxdoiorg/101016/jchb201409012 Mishra P & Yadav A (2013) Of art and algorithms Rethinking technology & creativity in the 21st century TechTrends 57(3) 10e14 National Research Council (2010) Committee for the Workshops on Computational Thinking Report of a workshop on the scope and nature of computational thinking Washington DC National Academies Press Papert S (1980) Mindstorms Children computers and powerful ideas New York Basic books Papert S (1991) Situating constructionism In S Papert & I Harel (Eds) Constructionism Cambridge MA MIT Press Pawley A (2009) Universalized narratives Patterns in how faculty members define engineering Journal of Engineering Education 98 309e319 Raven J C (1981) Manual for Raven's progressive matrices and vocabulary scales Research supplement No1 The 1979 british standardisation of the standard progressive Matrices and mill hill vocabulary scales together with comparative data from earlier studies in the UK US Canada Germany and Ireland San Antonio TX Harcourt Assessment Raven J C (2000) The Raven's progressive matrices Change and stability over culture and time Cognitive Psychology 41 1e48 Razzouk R & Shute V (2012) What is design thinking and why is it important? Review of Educational Research 82 330e348 Repenning A Webb D C Koh K H Nickerson H Miller S B Brand C  Repenning N (2015) Scalable game design A strategy to bring systemic computer science education to schools through game design and simulation creation ACM Transactions on Computing Education (TOCE) 15(2) 1e31 http//dxdoiorg/101145/2700517 Roman-Gonzalez M Perez-Gonzalez J C & Jimenez-Fernandez C (2017) Which cognitive abilities underlie computational thinking? Criterion validity of the computational thinking test Computers in Human Behavior 72 678e691 Rowe E Asbell-Clarke J & Baker R S (2015) Serious games analytics to measure implicit science learning In C S Loh Y Sheng & D Ifenthaler (Eds) Serious games analytics Methodologies for performance measurement assessment and improvement (pp 343e360) Switzerland Springer International Publishing Sanford J F & Naidu J T (2016) Computational thinking concepts for grade school Contemporary Issues in Education Research (CIER) 9(1) 23e31 http// dxdoiorg/1019030/cierv9i19547 Seiter L & Foreman B (2013 August) Modeling the learning progressions of computational thinking of primary grade students In Proceedings of the ninth annual international ACM conference on international computing education research (pp 59e66) ACM Sengupta P Kinnebrew J S Basu S Biswas G & Clark D (2013) Integrating computational thinking with K-12 science education using agent-based computation A theoretical framework Education and Information Technologies 18 351e380 http//dxdoiorg/101007/s10639-012-9240-x Settle A Franke B Hansen R Spaltro F Jurisson C Rennert-May C et al (2012 July) Infusing computational thinking into the middle-and high-school curriculum In Proceedings of the 17th ACM annual conference on innovation and technology in computer science education (pp 22e27) ACM Shute V J (1991) Who is likely to acquire programming skills? Journal of Educational Computing Research 7(1) 1e24 Shute V J Masduki I & Donmez O (2010) Conceptual framework for modeling assessing and supporting competencies within game environments Technology Instruction Cognition and Learning 8 137e161 Sneider C Stephenson C Schafer B & Flick L (2014) Computational thinking in high school science classrooms The Science Teacher 81(5) 53e59 Weintrop D Beheshti E Horn M Orton K Jona K Trouille L et al (2016) Defining computational thinking for mathematics and science classrooms Journal of Science Education and Technology 25(1) 127e147 http//dxdoiorg/101007/s10956-015-9581-5 Werner L Denner J Campe S & Kawamoto D C (2012 February) The fairy performance assessment Measuring computational thinking in middle school In Proceedings of the 43rd ACM technical symposium on computer science education (pp 215e220) ACM Wing J M (2006) Computational thinking Communications of the ACM 49(3) 33e35 Wing J M (2008) Computational thinking and thinking about computing Philosophical Transactions of the Royal Society a Mathematical Physical and Engineering Sciences 366 3717e3725 http//dxdoiorg/101098/rsta20080118 Wing J M (2010) Computational thinking What and why? Unpublished manuscript Pittsburgh PA Computer Science Department Carnegie Mellon University Retrieved from https//wwwcscmuedu/~CompThink/resources/TheLinkWingpdf Wolz U Stone M Pearson K Pulimood S M & Switzer M (2011) Computational thinking and expository writing in the middle school ACM Transactions on Computing Education (TOCE) 11(2) 1e22 Yadav A Mayfield C Zhou N Hambrusch S & Korb J T (2014) Computational thinking in elementary and secondary teacher education ACM Trans- actions on Computing Education (TOCE) 14(1) 1e16 http//dxdoiorg/101145/2576872 Zhong B Wang Q Chen J & Li Y (2016) An exploration of three-dimensional integrated assessment for computational thinking Journal of Educational Computing Research 53 562e590 http//dxdoiorg/101177/0735633115608444 
Developing computational thinking in the classroom a framework June 2014 Working group of authors Prof Paul Curzon Queen Mary University of London School of Electronic Engineering and Computer Science Teaching London Computing Project (http//wwwteachinglondoncomputingorg/) funded by the Mayor of London and Department of Education through the London School's Excellence Fund Mark Dorling BCS The Chartered Institute for IT and Computing At School Network of Excellence project (http//wwwcomputingatschoolorguk) funded by the Department for Education industry partners and awarding bodies Digital Schoolhouse London Project (http//wwwdigitalschoolhouseorguk) funded by the Mayor of London and Department of Education through the London School's Excellence Fund Thomas Ng West Berkshire Council School Improvement Adviser (ICT & Assessment) Dr Cynthia Selby Bay House School and Sixth Form Gosport Hampshire Southampton Education School University of Southampton Dr John Woollard Southampton Education School University of Southampton BCS Chartered Institute for IT Barefoot Computing project (http//wwwbarefootcasorguk) funded by the Department for Education © Copyright 2014 Computing At School This work is licensed under the Creative Commons Attribution-Non Commercial license; see http//creativecommonsorg/licenses/by-nc/30/ for details Introduction Computational thinking sits at the heart of the new statutory programme of study for Computing “A high quality computing education equips pupils to use computational thinking and creativity to understand and change the world” (Department for Education 2013 p 188) This document aims to support teachers to teach computational thinking It describes a framework that helps explain what computational thinking is describes pedagogic approaches for teaching it and gives ways to assess it Pupil progression with the previous ICT curriculum was often demonstrated through ‘how’ (for example a software usage skill) or ‘what’ the pupil produced (for example a poster) This was partly due to the needs of the business world for office skills Such use of precious curriculum time however has several weaknesses Firstly the country’s economy depends on technological innovation not just on effective use of technology Secondly the pace of technology and organisational change is fast in that the ICT skills learnt are out of date before a pupil leaves school Thirdly technology invades all aspects of our life and the typically taught office practice is only a small part of technology use today In contrast the new Computing curriculum has an enriched computer science element Computer science is an academic discipline with its own body of knowledge that can equip pupils to become independent learners evaluators and potentially designers of new technologies In studying computer science pupils gain not only knowledge but also a unique way of thinking about and solving problems computational thinking It allows the pupils to understand the digital world in a deeper way just as physics equips pupils to better understand the physical world and biology the biological world Simon Peyton-Jones gives an account of why learning computer science and computational thinking is a core life and transferable skill in a talk filmed at TEDxExeter (Peyton-Jones 2014) To prepare our pupils to understand the consequences of technological change adapt when using technologies develop new technologies or even to work in jobs that haven't yet been invented not only does the ‘what?’ and ‘how?’ of the subject need to be taught pupils also need to develop techniques to ask and be able to answer the question ‘why?’ Computational thinking supports doing so Computational thinking skills are the set of mental skills that convert “complex messy partially defined real world problems into a form that a mindless computer can tackle without further assistance from a human” (BCS 2014) Today however there is an interpretation led by the popular media implying that the new computing curriculum focuses on ‘coding’ (Crow 2014; Nettleford 2013) This gives a misleading message especially to those new to the discipline In contrast our framework presented below aims to support teachers’ understanding of computational thinking across the full breadth and depth of the subject of Computing and offers a way to easily and effectively integrate it into classroom practice The framework There are four interconnected stages of development to our computational thinking framework Stage 1 Definition Stage 2 Concepts Stage 3 Classroom techniques Stage 4 Assessment We overview each in the subsequent sections Stage 1 Definition To support the sharing of curriculum materials and classroom practices an agreed definition that is suitable for the classroom is needed We use the interpretation forwarded by Professor Jeannette Wing who originally popularised the idea of computational thinking She defines it as “… the thought processes involved in formulating problems and their solutions so that the solutions are represented in a form that can be effectively carried out by an information-processing agent” (Cuny Snyder Wing 2010 cited in Wing 2011 p20)  “these solutions can be carried out by any processing agent whether human computer or a combination of both” (Wing 2006) We chose this definition because it is based on Wing’s original definition and has gained consensus amongst academics Its emphasis is on pupils performing a thought process not on the production of artefacts or evidence It therefore fits the direction of change in the current curriculum development Stage 2 Concepts The next stage is to define the core concepts involved in computational thinking Based on a review of academic references Selby and Woollard (2013) suggest the following are key ■ algorithmic thinking ■ evaluation ■ decomposition ■ abstraction ■ generalisation We outline these concepts with examples below giving linked classroom techniques in the next section Algorithmic thinking is a way of getting to a solution through clear definition of the steps - nothing happens by magic Rather than coming up with a single answer like 42 the pupils develop a set of instructions or rules that if followed precisely (whether by a person or a computer) leads to answers to that and similar problems For example we all learn algorithms for doing multiplication at school If we (or a computer) follow the rules we were taught precisely we can get the answer to any multiplication problem Once we have the algorithm we don’t have to work out how to do multiplication from scratch every time we are faced with a new problem Evaluation is the process of ensuring an algorithmic solution is a good one that it is fit for purpose Various properties of algorithms need to be evaluated including whether they are correct are fast enough are economic in the use of resources are easy for people to use and promote an appropriate experience Trade-offs need to be made as there is rarely a single ideal solution for all situations There is a specific and often extreme focus on attention to detail in computational thinking based evaluation For example if we are developing a medical device to deliver drugs to patients in hospital we need to be sure that it always delivers the amount of drug set and that it does so quickly enough once start is pressed However we also need to be sure that nurses will be able to set the dose quickly and easily without making mistakes and that it won’t be frustrating or irritating for patients and nurses to use There is likely to be a trade-off to be made between speed of entering numbers and helping avoid mistakes being made when doing so The judgement about it being quick and easy has to be made systematically and rigorously Decomposition is a way of thinking about problems algorithms artefacts processes and systems in terms of their parts The separate parts can then be understood solved developed and evaluated separately This makes complex problems easier to solve and large systems easier to design For example if we are developing a game different people can design and create the different levels independently provided key aspects are agreed in advance Through decomposition of the original task each part can be developed and integrated later in the process A simple arcade level might also be decomposed into several parts such as the life-like motion of a character scrolling the background and setting the rules about how characters interact Abstraction is another way to make problems or systems easier to think about It simply involves hiding detail - removing unnecessary complexity The skill is in choosing the right detail to hide so that the problem becomes easier without losing anything that is important It is used as a way to make it easier to create complex algorithms as well as whole systems A key part of it is in choosing a good representation of a system Different representations make different things easy to do For example when we play cards we use the word ‘shuffle’ Every player understands that ‘shuffle’ means putting the cards in a random order The word is an abstraction The same type of abstraction works when programming Implementing ‘shuffle’ in a computer game means giving a way to randomise the cards We can refer to shuffling throughout the program and understand what is meant without having to think about how it is actually done by the program All that is needed is that the program does include a description somewhere of how shuffling is to be done As an example illustrating the difference the representation can make consider an art project Pupils studying Monet could take a digital picture of a Haystack painting in a gallery In doing so they have created a representation of it on the computer as pixels They can then easily manipulate this digital representation in ways that would be very hard with a different representation or in the real world For example the colours could be changed by an algorithm In this way a series of different but related versions of the painting could be created Generalisation is a way of quickly solving new problems based on previous problems we have solved We can take an algorithm that solves some specific problem and adapt it so that it solves a whole class of similar problems Then whenever we have to solve a new problem of that kind we just apply this general solution For example a pupil uses a floor turtle to draw a series of shapes such as a square and a triangle The pupil writes a computer program to draw the two shapes They then want to draw an octagon and a 10-sided shape From the work with the square and triangle they spot that there is a relationship between the number of sides in the shape and the angles involved They can then write an algorithm that expresses this relationship and uses it to draw any regular polygon In summary each of the above techniques fits into the well-established system design life cycle of computing projects in the business academic and scientific communities In practice they are used together in a rich and interdependent way to solve problems The emphasis in these concepts is on practical techniques or thought processes not on the production of artefacts or evidence Stage 3 Classroom Techniques The descriptions of the concepts above are high-level Although important on their own they don't explain how computational thinking can be embedded into the classroom and integrated into pedagogy Therefore our next step (Table 1) is to identify learner behaviours associated with each Concept Examples of Techniques Algorithmic Thinking Writing instructions that if followed in a given order (sequences) achieve a desired effect; Writing instructions that use arithmetic and logical operations to achieve a desired effect; Writing instructions that store move and manipulate data to achieve a desired effect; (variables and assignment) Writing instructions that choose between different constituent instructions (selection) to achieve a desired effect; Writing instructions that repeat groups of constituent instructions (loops/ iteration) to achieve a desired effect; Grouping and naming a collection of instructions that do a well-defined task to make a new instruction (subroutines procedures functions methods); Writing instructions that involve subroutines use copies of themselves to achieve a desired effect (recursion); Writing sets of instructions that can be followed at the same time by different agents (computers or people) to achieve a desired effect (Parallel thinking and processing concurrency); Writing a set of rules to achieve a desired effect (declarative languages); Using a standard notation to represent each of the above; Creating algorithms to test a hypothesis; Creating algorithms that give good though not always the best solutions (heuristics); Creating algorithmic descriptions of real world processes so as to better understand them (computational modelling); Designing algorithmic solutions that take into account the abilities limitations and desires of the people who will use them; Evaluation Assessing that an algorithm is fit for purpose; Assessing whether an algorithm does the right thing (functional correctness); Designing and running test plans and interpreting the results (testing); Assessment whether the performance of an algorithm is good enough; Comparing the performance of algorithms that do the same thing; Making trade-offs between conflicting demands; Assessment of whether a system is easy for people to use (usability); Assessment of whether a system gives an appropriately positive experience when used (user experience); Assessment of any of the above against set criteria; Stepping through algorithms/code step by step to work out what they do (dry run / tracing); Using rigorous argument to justify that an algorithm works (proof); Using rigorous argument to check the usability or performance of an algorithm (analytical evaluation); Using methods involving observing a system in use to assess its usability or performance (empirical evaluation); Judging when an algorithmic solution is good enough even if it is not perfect; Assessing whether a solution meets the specification (criteria); Assessing whether a product meets general performance criteria (heuristics) Decomposition Breaking down artefacts (whether objects problems processes solutions systems or abstractions) into constituent parts to make them easier to work with; Breaking down a problem into simpler but otherwise identical versions of the same problem that can be solved in the same way (Recursive and Divide and conquer strategies) Table 1 Computational thinking concepts and associated techniques Examples of algorithmic thinking evaluation decomposition generalisation and abstraction are found at all stages; it is the context that determines the relevance and challenge of the activity We have therefore tried not to attribute computational concepts and learner behaviours to particular key stages (phases of education) because doing so would imply that they are age-dependent in a way that they are not they are capability dependent It is also important to emphasise that computational thinking concepts are not the content for the subject of ‘Computing’ The subject content is set out in the national curriculum programme of study Computational thinking skills enable learners to access parts of that subject content Stage 4 Assessment The final stage needed is a way to assess the increasing competence of pupils in computational thinking This can be done using an adapted version of the existing subject framework for the computing subject itself To support classroom teachers Computing At School published an assessment framework called ‘Computing Progression Pathways’ (Dorling and Walker 2014a) It sets out the major knowledge areas of computing and gives specific indicators of increasing levels of mastery of the subject in those areas This assessment framework was produced by a small team of authors and reviewers (all teachers and academics) based on their classroom experiences It is an interpretation of the breadth and depth of the content in the 2014 national curriculum for the computing programme of study This breadth affords an opportunity to view the subject of computing as a whole rather than the separate subject strands of computer science digital literacy and information technology proposed by the Royal Society (2012) The assessment framework identifies the dependencies and interdependencies between concepts and principles as well as between the three subject strands Abstraction Reducing complexity by removing unnecessary detail; Choosing a way to represent artefacts (whether objects problems processes or systems) to allow it to be manipulated in useful ways; Hiding the full complexity of an artefact whether objects problems processes solutions systems (hiding functional complexity); Hiding complexity in data for example by using data structures; Identifying relationships between abstractions; Filtering information when developing solutions; Generalisation Identifying patterns and commonalities in problems processes solutions or data Adapting solutions or parts of solutions so they apply to a whole class of similar problems; Transferring ideas and solutions from one problem area to another Separate pathways are given for the areas of algorithms programming & development data and data representation hardware & processing communication & networks and information technology For example the pathway around the subject area of algorithms at its lowest level involves understanding of what an algorithm is and an ability to express simple linear algorithms with care and precision It then moves through levels of being able to express more complicated algorithms using selection and loops to at the highest level being able to design algorithms that make use of recursion as well as having an understanding that not all problems can be solved computationally The assessment framework is also presented where the learning outcomes are organised by the separate subject strands of computer science digital literacy and information technology (Dorling and Walker 2014b) A further version has been developed to incorporate provision for the concepts of computational thinking (Selby Dorling and Woollard 2014) It now includes a description of how it can be used to acknowledge progression and reward performance in mastering both the content of the computing programme of study and the ideas of computational thinking (Dorling Walker 2014c) For example algorithmic thinking is demonstrated not just in the Algorithms and Programming & Development pathways but also in constructing appropriate search filters (Data & Data Representation) and in demonstrating understanding of the fetch-execute cycle (Hardware & Processing) See Figure 1 as an example of what you can expect to see in Computing Progression Pathways with computational thinking Figure 1 Mapping the learning outcomes from Computing Progression Pathways to the concepts (from Stage 2) of computational thinking Using the framework to plan lessons When planning and teaching a scheme of work in any subject teachers refer to the planning-teaching-evaluating cycle Computational thinking can be included in the planning stage in four steps within the planning phase of each lesson in the planning-teaching-evaluating cycle see Figure 2 Step 1 Determine the ‘why’ at the start of the unit of study (Stage 1) as well as the possible topics (the column header names from the Progression Pathways Assessment Framework) that the scheme of work will be covering Repeat steps 2 - 4 when planning each lesson in a unit of study Step 2 Decide ‘what’ the learning outcomes are for the lesson from the Computing Progression Pathways Assessment Framework (Stage 4) which enable the pupils to move closer to completing or achieving the ‘why’ Step 3 Use the predefined mapping in the Computing Progression Pathways Assessment Framework to identify the possible associated computational thinking concepts (Stage 2) Step 4 Use the computational thinking concepts to identify possible techniques ‘how’ to incorporate into and highlight as part of the chosen classroom activities (Stage 3) Figure 2 Mapping the 4 stages of the framework to ‘why’ ‘how’ and ‘what’ It is important to note that the most important step in this process is the last step (step 4) Just because pupils can evidence learning in the Computing Progression Pathways Assessment Framework and that the learning outcome is mapped to computational thinking it does not necessarily mean that the pupils will have performed computational thinking Completion of an activity in itself is not evidence that computational thinking has occurred A Case Study Below we illustrate the application of the above framework with a case study based around a lesson one of the authors (Dorling) has used in his classroom In the sub-section of each activity we highlight how different parts of the activity draw on the computational thinking concepts (CT) In the classroom these concepts could be drawn out explicitly in for example a discussion at the end where the pupils reflect on the computational thinking skills they have used through the activity Topic Networking & Communications - using a binary protocol to transfer information Why I first lead a group discussion aiming to draw out why networks are important We discuss the applications pupils use on a regular basis such as a search engine or network file shares and how these applications have completely changed the way we do things I lead pupils to ask “what actually happens in the wire to make information go back and forth?” How Activity 1) Recap - I remind the pupils that they have previously studied and understood the different layers involved in computer architecture applications the operating system and the hardware ■ (CT) Abstraction of functionality ■ As we move from hardware to operating system to applications we move through increasing layers of system abstraction as each hides the messy details of the level below Activity 2) I introduce the pupils to the layers of network architecture application transport and network and point out the similarity to the computer architecture layers ■ (CT) Abstraction of functionality ■ In a similar way we move up through similar layers of abstraction from the network to transport layer to applications as each hides the messy details of the level below ■ (CT) Generalisation of solution (applying the same technique to a similar problem) ■ We have transferred the technique of analysis by layers from computer architecture to network architecture Activity 3) I remind pupils of their understanding of denary (decimal) numbers stored as binary numbers that is denary numbers are an abstraction of the binary code They hide the detail of how the numbers are actually stored I suggest that they could use this knowledge to invent their own transportation layer protocol ■ (CT) Abstraction of data ■ Denary numbers conceal the complexity of the binary representation Activity 4) I give the pupils a simple circuit ie a battery wires and a lamp and ask them to transfer a decimal number across the room to a friend using the lamp It is up to the learners to perform the conversion into binary and transfer it across the room I encourage them to think of the different tasks involved The sender and receiver do different though related things The recipient will receive the number assemble the string of binary and convert the binary back into a denary number ■ (CT) Decomposition of a problem ■ Identification of the high-level steps necessary to accomplish the whole task ■ (CT) Algorithmic thinking ■ Development of the ordering of the high-level steps necessary to accomplish whole task and working out the detailed steps for each Obviously without an agreed protocol there is complete mayhem Pupils have to work together to agree a protocol for 1 (light on) and 0 (light off) The confusion continues until the pupils realise the time or clock element that is needed so the start point is known and the light is either on or off for two seconds with a one second pause between each on or off ■ (CT) Evaluation of functional correctness ■ Pupils reflect on the problems (even mayhem) of initial solutions and realise the need to improve them ■ (CT) Algorithmic thinking ■ The trial and feedback development loop used between pupils is the heuristic development of an algorithm An alternative activity for pupils who have not yet fully grasped binary is to have them look at historical communication methods they have heard of such as Morse code or smoke signals with a view to identifying similarities between them and the current challenge ■ (CT) Generalising a solution from one problem to another ■ Identifying that in each case one representation (a letter) is transformed into another (Morse code) recognising a pattern in the solutions Activity 5) A standard protocol is agreed amongst the whole class this was achieved through a discussion of the problems of interoperability if every pair has chosen a different way of communicating They are then given a series of numbers the first two identifying the person (eg table-individual) and the next two being the message to that person (rather than an actual IP address at this stage of learning) ■ (CT) Abstraction of data ■ Understanding that an IP address is a name for a machine Pupils again struggle with this as it can be difficult with a long string of binary so they are likely to come up with an idea to chunk or group the binary This is analogous to a packet ■ (CT) Abstraction of data ■ Inventing the concept of a chunk or packet with chunks being sent received and reassembled ■ (CT) Algorithmic thinking ■ Working out the detailed instructions to make the chunking work Activity 6) Having mastered these concepts we discuss IP addressing as analogous to the UK post code system ■ (CT) Generalising a solution from one problem area to another ■ Recognising a pattern in the solutions to network packet sending and sending a letter by post Future learning opportunities can be built on these foundations For example visual packet tracing tools can be used to consider the location of web servers around the world Digital literacy questions can be posed about breaking the law when using the Internet and considering in which country a crime may have been committed What From the activities discussed here the pupils have had opportunities to use techniques associated with computational thinking concepts as indicated in order to demonstrate their understanding of the programme of study content Depending upon the level of understanding expressed or observed in the pupil behaviours it is possible to award progress in the subject content from the computing pathways at the following levels Pink Level ■ Algorithms Understands what an algorithm is and is able to express simple linear (non-branching) algorithms symbolically; Demonstrates care and precision to avoid errors ■ Information Technology Talks about their work and makes changes to improve it Yellow Level ■ Algorithms Designs simple algorithms using loops and selection ie if statements; uses logical reasoning to predict outcomes; detects and corrects errors ie debugging in algorithms ■ Information Technology Talks about their work and makes improvements to solutions based on feedback received Orange Level ■ Algorithms Recognises that some problems share the same characteristics and use the same algorithm to solve both ■ Data & Data Representation Understands the difference between data and information ■ Communications & Networks Understands the difference between the internet and internet service for example world wide web ■ Information Technology Makes appropriate improvements to solutions based on feedback received and can comment on the success of the solution Blue Level ■ Algorithms Designs solutions by decomposing a problem and creates a sub-solution for each of these parts Purple Level ■ Data & Data Representation Understands how bit patterns represent numbers and images; knows that computers transfer data in binary ■ Communications & Networks Understands data transmission between digital computers over networks including the internet ie IP addresses and packet switching ■ Algorithms Can identify similarities and differences in situations and can use these to solve problems ■ Information Technology Uses criteria to evaluate the quality of solutions can identify improvements making some refinements to the solution and future solutions Summary To engage pupils in lessons and so get the best out of them it is important that they understand why they are learning topics Some materials supporting the previous ICT curriculum focused on what was being taught (perhaps a skill) and what the pupils produced (perhaps a spreadsheet model) Thinking about ‘what’ and ‘how’ the pupils were producing an artefact but ‘why’ they were learning a given skill were secondary considerations The ‘why’ was often an assessment objective or a qualification examination instead of a real-world reason Criticism of this approach identified a lack of focus on understanding the deeper ‘how’ and ‘why’ (problems are solved systems are made …) (Royal Society 2012) The four-step framework we have set out gives a practical way to both understand computational thinking and introduce the ideas into the classroom context It can be used both to support the planning of activities to increase the opportunities for pupils to develop computational thinking skills and to assess their progress in doing so This can be achieved by considering the ‘why’ of the challenge they are setting for the learners at the outset Pupils should then employ a variety of their computational thinking abilities as described in Table 1 (the ‘how’) to develop understanding or solve the problem in hand The ‘what’ is expressed in the evidence of the actual subject learning This could be what the pupils produce (artefact) what the pupils understand or express (write test verbalise) or what behaviour is observed (generalising) The ‘what’ matches the learning outcome statements from the Computing Progression Pathways Assessment Framework Figure 3 maps the four stages of development described above to the notion of focusing on the ‘why’ ‘how’ and ‘what’ Figure 3 Mapping the 4 stages of the framework to ‘why’ ‘how’ and ‘what’ References BCS The Chartered Institute for IT 2014 Call for evidence - UK Digital Skills Taskforce Available http//policybcsorg/sites/policybcsorg/files/BCS%20response%20to%20UKDST%20call%20for%20evidence%20finalpdf [Accessed 26-06-2014] Department for Education 2013 The National Curriculum in England Framework Document Available http// wwweducationgovuk/nationalcurriculum [Accessed 23-06-2014] Dorling M & Walker M 2014a Computing Progression Pathways Available http//communitycomputingatschoolorguk/resources/1692 [Accessed 23-06-2014] Dorling M & Walker M 2014b Computing Progression Pathways grouped by CS IT and DL Available http// communitycomputingatschoolorguk/resources/1946 [Accessed 23-06-2014] Dorling M & Walker M 2014c Computing Progression Pathways with Computational Thinking Available http//communitycomputingatschoolorguk/resources/2324 [Accessed 27-06-2014] Nettleford W 2013 Primary School Children Learn to Write Computer Code Available http//wwwbbccouk/ news/uk-england-london-23261504 [Accessed 23-06-2014] Peyton-Jones S 2014 Teaching Creative Computer Science Available http//tedxexetercom/2014/05/06/simon-peyton-jones-teaching-creative-computer-science [Accessed 23-06-2014] Royal Society 2012 Shut down or restart? The way forwards for computing in UK schools Available https// royalsocietyorg/~/media/education/computing-in-schools/2012-01-12-computing-in-schoolspdf [Accessed 23- 06-2014] Selby C Dorling M & Woollard J 2014 Evidence of Assessing Computational Thinking https//eprintssotonacuk/366152 [Accessed 23-06-2014] Selby C & Woollard J 2013 Computational Thinking The Developing Definition Available http//eprintssotonacuk/356481 [Accessed 23-06-2014] Wing J 2006 Computational Thinking Commun ACM 49 3 33-35 Available http//dlacmorg/citationcfm? id=1118215 [Accessed 23-06-2014] Wing J 2011 Research Notebook Computational Thinking - What and Why? The Link Pittsburgh PA Carneige Mellon Available http//wwwcscmuedu/link/research-notebook-computational-thinking-what-andwhy [Accessed 23-06-2014] 
How Kids Code and How We Know An Exploratory Study on the Scratch Repository Efthimia Aivaloglou Felienne Hermans eaivaloglou@tudelftnl ffjhermans@tudelftnl ABSTRACT Block-based programming languages like Scratch Alice and Blockly are becoming increasingly common as introductory languages in programming education There is substantial research showing that these visual programming environ- ments are suitable for teaching programming concepts But what do people do when they use Scratch? In this paper we explore the characteristics of Scratch programs To this end we have scraped the Scratch public repository and retrieved 250000 projects We present an analysis of these projects in three different dimensions Initially we look at the types of blocks used and the size of the projects We then investigate complexity used abstractions and programming concepts Finally we detect code smells such as large scripts dead code and duplicated code blocks Our results show that 1) most Scratch programs are small however Scratch programs consisting of over 100 sprites exist 2) programming abstrac- tion concepts like procedures are not commonly used and 3) Scratch programs do suffer from code smells including large scripts and unmatched broadcast signals Keywords Scratch; block-based languages; programming practices; code smells; static analysis 1 INTRODUCTION Scratch [20] is a programming language developed to teach children programming by enabling them to create games and interactive animations The public repository of Scratch programs contains over 14 million projects Scratch is a block-based language users manipulate blocks to program Block-based languages have existed since the eighties [9] but have recently found adoption as tools for programming education In addition to Scratch also Alice [4] Blockly1 1 https//developersgooglecom/blockly/ Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full cita- tion on the first page Copyrights for components of this work owned by others than ACM must be honored Abstracting with credit is permitted To copy otherwise or re- publish to post on servers or to redistribute to lists requires prior specific permission and/or a fee Request permissions from permissions@acmorg ICER ’16 September 08-12 2016 Melbourne VIC Australia ⃝c 2016ACMISBN978-1-4503-4449-4/16/09$1500 DOI http//dxdoiorg/101145/29603102960325 and App Inventor [23] are block-based and aimed at novice programmers Several studies have shown that block-based languages are powerful as tools for teaching programming [15 18 5 19] Previous works involving static analysis of Scratch programs have evaluated the application of various programming con- cepts in Scratch projects [12 16] Recent works have focused on bad programming practices within Scratch programs [14] and automated quality assessment tools have been proposed for identifying code smells [8] and bad programming prac- tices [2 16] In a recent controlled experiment we found that long scripts and code duplication decrease a novice program- mer’s ability to understand and modify Scratch programs [10] The goal of this paper is to obtain an understanding of how people program in Scratch by analyzing their program- ming artifacts ie the saved and shared Scratch projects With this we aim to quantitatively evaluate the use of pro- gramming abstractions and concepts Moreover knowing that bad programming habits and code smells can be harm- ful [10] we also want to explore whether they are common To address this goal we answer the following research ques- tions RQ1 What are the size and complexity characteristics of Scratch programs? RQ2 Which coding abstractions and programming concepts and features are commonly used when programming in the Scratch environment? RQ3 How common are code smells in Scratch programs? Our study is based on data from the Scratch project repos- itory By scraping the list of recent projects2 we have ob- tained 250166 public Scratch projects and performed source code analysis on them To the best of our knowledge this is the first large-scale exploratory study of Scratch programs The contributions of this paper are as follows • Apublicdatasetof233491non-emptyScratchprojects (Section 31) • An evaluation of the data set in terms of size com- plexity programming concepts and smells (Section 4) • A discussion of the implications of our findings for ed- ucational programming language designers (Section 5) 2https//scratchmitedu/explore/projects/all/ Software Engineering Research Group Delft University of Technology Mekelweg 4 2628 CD Delft the Netherlands rAloeCwtaMiontshaaecrknsnotonowedxloecdlsugoseisvfoetrhraGotoytvahelitrsyn-cmforennetrtripibguhrtitpotnosepwsuaobsnlilasyuhthoorredprorduccoe-atuhtihsoaretidclbey oarntoemal- ployee contractor or affiliate of a national government As such the Government 53 2 RELEVANT SCRATCH CONCEPTS Scratch is a block-based programming language aimed at children developed by MIT Scratch can be used to create games and interactive animations and is available both as a stand-alone and as a web application The main concepts in the Scratch programming environment are (we refer the reader to [3] for an extensive overview) Sprites Scratch code is organized by ‘sprites’ two dimen- sional pictures each having their own associated code Scratch allows users to bring their sprites to life in var- ious ways for example by moving them in the plane having them say or think words or sentences via text balloons but also by having them make sounds grow shrink and switch costumes Scripts Sprites can have multiple code blocks called scripts It is possible for a single sprite to have multiple scripts initiated by the same event In that case all scripts will be executed simultaneously Events Scratch is event-driven all motions sounds and changes in the looks of sprites are initiated by events called Hat blocks3) The canonical event is the when Green Flag clicked activated by clicking the green flag at the top of the user interface In addition to the green flag there are a number of other events possible including key presses mouse clicks and input from a computer’s microphone or webcam Signals Events within Scratch can be user-generated too users can broadcast a message for example when two sprites touch each other All other sprites can then react by using the when I receive Hat block Custom blocks Scratch users can define their own blocks which users can name themselves called custom blocks The creation of custom blocks in Scratch is the equiv- alent of defining procedures in other languages [16] Because the term ‘procedures’ is common in related work we will refer to custom blocks as ‘procedures’ in the remainder of this paper Procedure parameters can be textual numeric or boolean When a user defines a procedure a new Hat block called define appears which users can fill with the implementation of their procedure 3 RESEARCH DESIGN AND DATASET The main focus of this study is to understand how peo- ple program in Scratch by analyzing the characteristics of Scratch projects To answer our three research questions we conducted an empirical quantitative evaluation of project data we collected from the Scratch project repository In the following paragraphs we describe the dataset the pro- cess and the tools we used for analyzing it and the methods we followed for detecting code smells 31 Dataset In order to collect the set of Scratch projects in the dataset we built a web scraping program The scraping program called Kragle starts by reading the Scratch projects page2 and thus obtains the project identifiers of projects that were 3http//wikiscratchmitedu/wiki/Hat Block most recently shared Subsequently Kragle retrieves the JSON code for each of the listed projects We ran Kragle on March 2nd 2016 for 24 hours and during that time it obtained a little over 250000 projects Out of the 250166 we failed to parse and further analyze 2367 projects due to technical difficulties with the JSON files Kragle as well as all scraped projects and our analysis files are available4 Once we obtained the Scratch projects we parsed the JSON files according to the specification of the format5 This resulted in a list of used blocks per project with the sprites and the stage of the project We also cross referenced all blocks with the Scratch wiki to determine the shapes and the category of all blocks For example When Green Flag Clicked is a Hat block from the Events category 32 Data analysis All scraped project data including the list of used blocks and parameters were imported in a relational database We used SQL queries which are also made available4 for filter- ing aggregating and extracting all statistical data required to address our three research questions We also randomly sampled and manually inspected edge cases in the results for example empty or overly complex projects Data for these cases are provided as part of the dataset4 To answer RQ1 we measured the size of projects based on the number of blocks in scripts and sprites and we cal- culated descriptive statistics which are presented in Section 41 For measuring the complexity of the scripts we used the McCabe cyclomatic complexity metric [13] a quantita- tive measure of the number of independent paths through a program’s source code This is commonly calculated per script by counting the number of decision points in the script plus one The decision points that Scratch supports are the if and the if else blocks For RQ2 we used the data on the code blocks and their categories to perform statistical analysis of applied program- ming abstractions and concepts Similarly to [6] and [12] we consider the use of certain blocks to indicate that a pro- gramming abstraction or concept is being used in a certain project In Section 42 we present the results related to the utilization of procedures variables loops conditional state- ments user interactivity and synchronization For RQ3 we focused on four types of code smells dupli- cated code dead code large script and large sprite In the duplicated code smell analysis our first step was to define what we consider a code clone in the context of Scratch pro- gramming a script that is composed of a set of blocks of the same type connected in the same way and is repeated within or across sprites of the same project For the identi- fication of clones we did not take into account the values of the parameters that may be used in the blocks so that two blocks that only differ in the values of parameters are con- sidered to be equal We also investigated the case of clones with the same parameter values and we refer to them as ex- act clones The next step in the analysis was to determine the minimum size of the scripts that are considered clones instead of incidentally similar We examined the number of detected clones for different script sizes and present the results in Figure 1 Based on this distribution we opted to 4 https//githubcom/TUDelftScratchLab/ScratchDataset 5http//wikiscratchmitedu/wiki/Scratch File Format (2 0) 54 1000000 100000 80000 50000 10000000 1000000 100000 10000 1000 100 10 1 1 45000 40000 35000 30000 25000 20000 15000 10000 70000 10000 60000 1000 40000 100 30000 10 11101001000 0 Clones across sprites Clones within sprites Figure 1 Number of cloned scripts of different block sizes across and within sprites Number of cloned scripts Number of sprites with code Figure 3 Number of sprites in the analyzed projects 10 Number of sprites Number of scripts 10000 5000 0 Figure 2 Size of sprites and scripts in number of blocks adopt the number also used by the authors in [16] which is a minimum size of five blocks per script In the context of Scratch we consider the long method and the large class smells as large script and large sprite smells respectively For these two smells we use the number of blocks as the size metric Figure 2 presents the number of blocks in scripts and sprites of our dataset We used these statistics to split the dataset and retrieve the top 10% largest scripts and sprites as is commonly done in both source code analysis [1] and analysis of end-user programming artifacts like spreadsheets [11] Using that strategy we set the thresh- olds for the calculation of the large script and large sprite 18 blocks and 59 blocks respectively The results we obtained using these thresholds are presented in Section 43 4 RESULTS In the following sections for each of the research ques- tions we describe the results obtained through the analysis of the 247798 Scratch projects in our dataset 41 Program Size and Complexity The dataset contains a relatively small number of projects without any code 14307 (577%) Through random man- ual sampling we found that in some cases these projects con- tains only sprites and costumes but no code while other projects were entirely empty apart from the Scratch cat added by default Since these projects are empty in terms of code we excluded them from further analysis leaving the final number of analyzed non-empty projects to 233491 5000 0 100 1000 Number of blocks Number of scripts (in all sprites) Figure 4 Number of scripts in the analyzed projects 50000 45000 40000 35000 30000 25000 20000 15000 10000 Number of blocks Figure 5 Number of blocks in the analyzed projects 10000000 1000000 100000 10000 1000 100 10 1 Figure 6 McCabe cyclomatic complexity of the 4049356 analyzed scripts 55 20000 10000 Scripts Projects Projects Projects 1024 2048 4096 8192 16384 32768 More 16 32 64 128 256 512 1248 Number of blocks in script 1 2 4 8 16 32 64 128 256 More Cyclomatic complexity mean min Q1 median Q3 max Size Complexity Procedures Programming concepts Sprites with code per project Scripts per project Number of blocks per project Blocks in Stage per project Blocks in Sprites per project Blocks in Procedures per project McCabe Cyclomatic Complexity (CC) per script McCabe CC per procedure script Procedures per project with procedures Arguments per Procedure Numerical arguments per procedure with arguments Text arguments per procedure with arguments Boolean arguments per procedure with arguments Calls per procedure Scripts with calls per procedure Variables per project Scripts utilizing variable Lists per project Conditional statements per project Loop statements per project User input blocks per project Broadcast-receive statements per project 568 1 1 1735 1 2 15455 1 12 480 0 0 11557 0 10 2 5 525 5 12 3038 29 76 34622 0 3 2613 26 68 34613 3417 0 0 0 158 1 1 1 375 1 1 2 1150 1 1 2 095 0 0 0 173 0 1 1 028 0 0 0 013 0 0 0 214 0 1 1 113 0 1 1 206 0 0 0 497 1 1 3 055 0 0 0 1002 0 0 0 765 0 1 2 477 0 0 1 857 0 0 0 0 20552 1 246 4 183 6 847 1 53 2 22 1 24 0 14 2 526 1 59 1 340 5 1127 0 319 3 5950 5 2503 4 1889 2 2460 Table 1 Summary statistics of the dataset of 233491 non-empty Scratch projects In Table 1 we summarize the statistics for the analyzed metrics We use the mean value and the five-number sum- mary to describe the dataset in terms of the number of sprites with code per project (including the stage sprite) and the number of scripts and blocks per project Figures 3 4 and 5 plot the distribution of these size metrics We find that the majority of Scratch projects are small; 75% of the projects have up to 5 sprites 12 scripts and 76 blocks while one fourth of the projects have up to 12 blocks On the other end 5% of the projects (11712) have more than 18 sprites and 48% (11214) consist of more than 500 blocks The analysis also highlighted some surprisingly large projects 135 with more than 300 sprites and even 30 projects with more than 20000 blocks whose Scratch identifiers are made available for further inspection4 The number of blocks metric was further analyzed to un- derstand code organization in more depth The majority of Scratch code—7478% out of 36085654 blocks—is written within sprites An additional 31% of the total blocks are found in the stage class More interestingly the remain- ing 2211% are blocks within defined procedures which are found in only 77% (17979) of the pro jects The pro jects that contain procedures use them a lot; almost half of their total blocks (4881%) are within procedures We further analyzed the utilization frequency of the dif- ferent block shapes and categories as defined in the Scratch documentation Figures 7 and 8 present the results in terms of number of blocks from the total 36085654 blocks in the dataset projects The most commonly used blocks are from the Control and Data categories The Others category in- cludes the blocks related to procedure calls and arguments To understand the complexity of the Scratch projects in our dataset we use the McCabe cyclomatic complexity The results of this metric per script are plotted in Figure 6 The majority (7833%) of 4049356 scripts contain no decision points while 1308% have a cyclomatic complexity of 2 con- Figure 7 Number of blocks from each category in the analyzed projects Figure 8 Number of blocks of each shape in the analyzed projects 8000000 7000000 6000000 5000000 4000000 3000000 2000000 1000000 0 Stack Reporter Hat Cap C Boolean 0 5000000 10000000 15000000 20000000 56 7000 6000 5000 4000 3000 2000 1000 0 1 2 4 8 16 32 64 128 256 512 More Number of procedures Retrieved Analyzed Non-empty (used for statistics) Projects with Procedures 17979 Recursive procedures 1052 Variables 73577 Lists 9358 Number of pro jects 250166 247798 233491 % 770% 045% 3151% 401% 3981% 5624% 7718% 1359% 2957% 2554% 1014% 212% 2593% 1181% 087% 2816% 2977% 1368% Conditional statements User input blocks Loop statements repeat until <condition> broadcast - receive Cloned scripts across sprites Cloned scripts within sprites Cloned procedures Cloned blocks across sprites Exact clones across sprites Exact clones within sprites Dead code Large scripts Large sprites 92959 131314 180210 31739 69039 59634 23671 4945 60554 27574 2043 65760 69521 31954 Figure 9 Number of procedures for the 17979 projects that include at least one procedure 1000000 100000 10000 1000 100 10 1 0 1 2 4 8 16 32 64 More Number of arguments Table 2 Elements and characteristics of the projects in the dataset taining exactly one decision point The complexity is higher over 4 for 367% of the scripts The analysis also highlighted 209 scripts with a cyclomatic complexity over 100 and up to 2464 Cyclomatic complexity was greater (mean value of 332) in defined procedures with 5646% of the procedures having at least one decision point 42 Programming Abstractions and Concepts The first method for abstraction that we investigate are procedures In the dataset we found 206799 procedures in 17979 (77%) projects As summarized in Table 1 the projects that contain procedures have an average of 115 procedures with 5359% of these projects having up to 2 Figure 9 shows the distribution of procedures in projects Regarding procedure arguments we found that 5557% have no arguments and 1948% have only one (shown in Figure 10) The majority of procedure arguments (8059%) are nu- meric and the least used argument type is the boolean one— 623% of the total procedure arguments found in 532% of the procedures The use of procedures in projects was further investigated through the use of procedure calls summarized in Figure 11 Most procedures are called exactly once (6232% of them) or twice (1430%) and from exactly one script (8592% of them) Examining the origin of procedure calls we ob- served that most of the calls (5609%) originate from other procedures and 106% even originate from the same proce- dure making them recursive calls These recursive proce- Figure 10 Number of arguments of the procedures in the dataset dures are found in 1052 projects whose identifiers are made available4 As shown in Table 2 almost one-third of the projects use variables and a small number (401%) use lists The num- ber of variables that is being used is also limited with only 748% of the projects having five or more variables The distribution of variable and list utilization is shown in Fig- ure 12 Exceptional cases exist the analysis highlighted 842 projects with more than 100 variables and with a maximum of 340 Examining the initialization of variables through the set <variable> to <value> blocks we found that for 483% of all variables this was missing While failing to ini- tialize a variable in Scratch will not result in a runtime error as in some other programming languages correctly setting the initial state of the program is important [2] Regardingprogramcontrolfeaturesconditionals(if <con- RQ1 The majority of Scratch projects are small and sim- ple 75% of the projects have up to 5 sprites 12 scripts and 76 blocks The majority (78%) of scripts contain no decision points Most code is written in sprites There exist surprisingly large and complex projects 1000000 100000 10000 1000 100 10 1 Procedure calls 57 Figure 11 Number of calls of each procedure in the dataset Procedures (log scale) Procedures (logarithmic scale) Projects 1000000 100000 10000 1000 100 10 1 Number of variables and lists 1000000 100000 10000 1000 100 10 1 0 1 2 4 8 16 32 64 128 256 More Number of cloned scripts across sprites exact clones across sprites within sprites Figure 12 Number of used variables and lists Figure 13 Cloned scripts in the dataset projects 100000 10000 1000 100 10 1 2 4 8 16 32 64 128 256 512 1024More Number of copies of cloned scripts across sprites exact clones across sprites within sprites Block when <> key pressed when this sprite clicked (Sensing) key <> pressed? (Sensing) ask <> and wait (Sensing) mouse down? (Sensing) <attrib> of <> (Sensing) mouse X (Sensing) mouse Y when <sensor> > <value> (Sensing) video <> on <> Projects Occurrences 71096 39179 37919 19039 9115 9068 5977 3940 705 434 294771 198342 291657 66850 54079 155468 27321 22035 1570 1397 Figure 14 Number of copies of the identified clones RQ2 A small number of projects (8%) use procedures but they use them a lot and for more complex code Most procedures are called once or twice from a single script which in more than half of the cases is another proce- dure Recursive procedure calls exist in 1052 (05% of the total) pro jects One third of the pro jects use vari- ables sometimes without initializing them 40% of the projects contain conditional statements and 77% contain loops but conditional loops are rarely used More than half of the pro jects are interactive 30% of the pro jects use broadcast and receive blocks Table 3 Frequency of use of user input blocks in the 233491 projects of the dataset dition> then and if <condition> then else blocks) are used by 3981% of the projects Loops (blocks repeat <tim- es>foreverandrepeat until <condition>)aremorecom- mon used by 7718% of the projects The most common of the three is the forever block accounting for 5186% of all loops and the least common one is the repeat until <con- dition> block accounting for 1157% of all loops and used in 1359% of the total projects Investigating user interactivity functionality we found that 5624% of the projects in the dataset contain user input blocks—an average of 848 blocks per such project Table 3 lists the frequency of use of user input controls We do not include the when Green flag pressed block here as this is just used to start a Scratch program and hence cannot be considered input into the program The most commonly used user input block is the when key pressed found in 71096 (3045% of the total) projects The most frequently used parameter for the key attribute is the space key fol- lowed by the arrows and then the letters and numbers As detailed in Section 2 users can define their own events using the blocks broadcast broadcast and wait and when I receive These blocks are used in 2957% of the projects broadcast and wait is rarely used in 387% of the projects 43 Code smells The duplicated code smell is the first smell that we exam- ine As explained in Section 32 we use 5 as the minimum number of blocks for the identified clones In total in the dataset we found 170532 scripts cloned across sprites in 59634 (2554% of the total non-empty) projects 726316 copies of these scripts were found making each clone being copied an average of 426 times Figure 13 plots the distri- bution of clones across pro jects The ma jority of pro jects contain up to two cloned scripts Figure 14 plots the num- ber of copies of the identified clones It is of interest that 79378 (4655%) of the identified clones are copied three or more times and even in 585 cases from 411 projects they are copied more than 50 times and up to 9744 We further inspected which of the identified clones were duplicated within the same sprite 63682 (3734% of the total) clones in 1014% of all pro jects 212% of the pro jects contain cloned procedure definitions which were measured to 12878 (755% of the total) clones Exact clones were found in 1181% of the total projects Their total number 58 Clones (log scale) Projects Projects (log scale) was 66750 (3914% of the total) clones Exact clones in the same sprite were rare found in 087% of the projects Apart from whole scripts we also examined cases where scripts differ only in the first (Hat) block This way we exam- ine if Scratch programmers assign the same functionality to handle different types of events Cloned functionality blocks are found to be rare without considering the first block only 2243 additional clones were found in 920 projects The second smell that we examine is the dead code smell We identify four types of dead code (1) procedures that are not invoked (2) unmatched broadcast-receive messages (3) code that is not invoked and (4) empty event scripts ie scripts that contain an event block alone Investigat- ing the first type we find that a significant number of the defined procedures (13036 or 506%) are not called in the projects This is also shown in Figure 11 and it occurs in 2079 projects For the second type we examined the broadcast-receive messages and found that they are not al- ways synchronized 333% of the when I receive blocks were found to wait for a message that is never being broad- casted while 44% of the broadcast blocks broadcast a mes- sage that is not being received This lack of syncronization occurs in 18669 (799% of the total) projects The third and fourth cases are incomplete scripts Those are either never invoked due to the lack of a starting when <trigger> block from the Scratch Events or Control cat- egory or are comprised of only a when <trigger> block without any functionality A total of 322475 scripts like that were found in 56890 (2436% of the total) projects The majority of these scripts (866%) are scripts missing a Hat block Examining the size of these dead scripts 7234% are composed of a single block However some dead scripts are considerably large; 2358 dead scripts in 1553 different projects have more than 30 blocks and up to 26104 The number of projects exhibiting the dead code smell considering all four types of dead code combined is 65760 (2816% of the total projects) Finally we examine the large script and the large sprite smells The thresholds we use for the identification of large scripts and large sprites are 18 blocks and 59 blocks respec- tively as explained in Section 32 The number of projects exhibiting the large script smell ie containing at least one script with 18 or more blocks is 69521 (2977% of the total projects) and the number of projects with the large sprite smell is 31954 (1368%) 5 DISCUSSION 51 Implications We believe a large scale study of programs like the cur- rent can help language designers to tailor their language In this section we highlight directions in which our study could support language design There are many other implications to be considered which is why we have made our dataset public 511 Popularity of different block types Our analysis shows that some categories of blocks are rarely used like the ‘Pen’ blocks of which only 194885 oc- cur within 19090 (817% of the total) programs Hence in future changes to the language ‘Pen’ blocks might be less important to users to support or maintain 512 Dead code In our analysis we find that more than one quarter of the Scratch projects contain dead scripts In a sense the dead scripts are harmless as they are not executed How- ever they do cause ‘visual clutter’ and might be distracting to novice programmers as it might be hard to see which scripts are dead In contrast to other visual educational languages Scratch does not indicate scripts that are dead LEGO Mindstorms for example does give the user feedback on dead blocks by making them gray Looking at the number of unconnected blocks we hypoth- esize that Scratch programmers have a need for a separate workspace to store unconnected blocks temporarily We en- vision that would be like the ‘backpack’ a Scratch feature meant to move scripts across sprites In order to help novice programmers keep their code clean the programming inter- face could actively encourage users to move unconnected blocks to that workspace when they exit the environment 513 Exact clones between sprites With occurrences in 11% of the Scratch projects in our dataset the use of exactly identical clones between sprites is relatively common In a sense the Scratch users are not to blame for that as Scratch does not support procedure calls between sprites only within them So in many cases there is no way to share the functionality other than by making a copy We are not aware of the underlying rationale of the Scratch team that lead to this decision however it seems that a large part of the Scratch users would use the functionality to call procedures between sprites 514 Sharing of scripts and procedures Investigating the use of clones between projects we ob- serve that there are 1700 scripts that are used in multiple projects sometimes as often as in 1600 different projects This seems to indicate that there are common patterns in Scratch projects which means it might be very beneficial to Scratch programmers if they could not only share their projects but also share some of their functionality for others to use like a library An example of such a library could be functions for platforming games including the movement of sprites collision detection and the implementation of ‘lives’ This might empower new Scratch users to get started faster 52 Insights for computing education Our findings confirm that Scratch is mainly used for its intended purpose as a first-exposure programming environ- ment for creating simple programs and interactive anima- tions the majority of programs are small and more than half are interactive and contain no conditional statements The analysis also indicates that computational concepts like conditionals and variables are being applied —conditional statements are found in 40% of the projects and variables in 32% The same does not hold for loops even though 77% of the projects contain loops only 14% contains conditional loops We attribute the increased use of the forever loop RQ3 Code clones are found in 26% of the projects with almost half of the clones copied three or more times in the same or across sprites 28% of the projects contain code that is never invoked and thus exhibit the dead code smell In some cases these scripts are large The large script smell is found in 30% of the projects and the large sprite one in 14% 59 to the Scratch language design and we are skeptical over whether it indicates an understanding of loop concepts Only 8% of the projects contain procedures and those use them a lot and for more complex code which is an indication of use by more experienced programmers This very essential programming concept is therefore not suffi- ciently applied which can be attributed both to limitations imposed by the Scratch environment like the local scope of procedures and to the difficulty for internalizing certain computational thinking concepts before a certain age [21] The high occurrence of cloned scripts (in 26% of the proj- ects) could be the result of the limited use of procedures Other code smells are also frequently found 28% of the projects include dead code and 30% have large scripts Know- ing from prior research that long scripts and code duplica- tion decreases ability to understand and modify Scratch pro- grams [10] and that Scratch programmers tend to exhibit certain bad programming habits [14] we believe educating novice programmers on code quality concepts is an issue that should be further researched It must be noted that the scope of this study includes the programming artifacts alone Our findings are limited by the lack of (1) process data and (2) data on the age and other characteristics related to the programmers However the project data that is available in our dataset can facili- tate further studies on computing education and this is the reason that we are publishing it 53 Threats to validity A threat to the validity of this study is the fact that we did not scrape a random sample but the most recent 250000 projects It could be the case that the programming habits of Scratch users are changing over time However we coun- terbalanced that by using a large dataset which comprises around 2% of all 14 million shared Scratch projects6 Furthermore we use the number of blocks in the Scratch projects as a measure for the length of a program while this does not exactly correspond to the ‘length’ of a program in lines and there can be multiple Scratch blocks on one line We however believe that the number of blocks is a good proxy for size and we plan a future experiment in which we will compare ‘lines of Scratch code’ to ‘number of blocks’ 6 RELATED WORK The evaluation of block-based languages in general and Scratch in particular as tools for programming education has received significant research attention during the past years A number of studies have been carried out on the understanding of programming concepts and the program- ming practices of novice programmers in block-based envi- ronments on the programming skills they develop and on the quality of Scratch programs For example a study on the internalization of program- ming concepts with Scratch with 46 students was presented in [15] Concepts like loops conditional loops message pass- ing initialization variables and concurency were examined and it was found that students had problems with the last three In a later study with an equal set of subjects [14] the same authors identified two bad programming habits in Scratch namely bottom-up development and extremely fine-grained programming They connected the later to the 6 https//scratchmitedu/statistics/ reduced use of if-blocks and finite loops and the increased use of infinite loops a finding that is verified by our study In [22] 29 projects created by 60 students working in groups were evaluated based on a list of criteria related to program- ming concepts code organization and usability design Large-scale analyses of Scratch projects have been per- formed using the dataset made available by the Lifelong Kindergarten Group at the MIT Media Lab which contains data for Scratch projects created until 2012 when the web- based programming environment was introduced In [24] this dataset was used for exploring the learning patterns of programmers in terms of block use over their first 50 pro jects Dasgupta et al investigated how pro ject remixing relates to the adoption of computational thinking concepts [6] In [7] the use of programming concepts was examined in relation to the level of participation (commenting remix- ing etc) the gender and the account age of 5000 Scratch programmers Most related to our study for the second research question of programming abstractions and concepts is the work by Maloney et al [12] who analyzed 536 Scratch projects for blocks that relate to programming concepts including loops conditional statements variables user interaction synchro- nization and random numbers Compared to their findings our investigation reveals increased use of the first three con- cepts and especially variables The Scratch automated quality analysis tools Hairball [2] and Dr Scratch [17] are also related to our work on smell detection The Hairball Scratch extension is a lint-like static analysis tool for Scratch that can detect initialization prob- lems and unmatched broadcast and receive blocks In their work [16] Moreno and Robles extended Hairball to detect two bad programming habits in Scratch not changing the default object names and duplicating scripts and apply them for evaluating 100 projects from the Scratch repository The results on script duplication are substantially different from ours—we find projects with script clones to appear half as frequently The Dr Scratch tool [17] includes bad naming code duplication and dead code identification functionality and also evaluates Scratch projects in terms of abstraction parallelism logical thinking synchronization flow control user interactivity and data representation 7 CONCLUSIONS In this paper we presented a large-scale study on 247798 projects we scraped from the Scratch repository We ana- lyze these projects in terms of size complexity application of programming abstractions and utilization of programming concepts including procedures variables conditional state- ments loops and broadcast-receive functionality We find that procedures and conditional loops are not commonly used We further investigate the presence of code smells in- cluding code duplication dead code long method and large class smells Our findings indicate that Scratch programs suffer from code smells and especially from dead code and code duplication In addition to the findings presented in this paper we provide as contributions the dataset that we used for our study as well as the project identifiers and information on the edge cases that we found in the dataset in terms of size and number of procedures variables cyclomatic complexity clones and dead code4 60 8 REFERENCES [1] T L Alves C Ypma and J Visser Deriving metric thresholds from benchmark data In 26th IEEE International Conference on Software Maintenance (ICSM 2010) pages 1–10 IEEE Computer Society 2010 [2] B Boe C Hill M Len G Dreschler P Conrad and D Franklin Hairball Lint-inspired Static Analysis of Scratch Projects In Proceeding of the 44th ACM Technical Symposium on Computer Science Education SIGCSE ’13 pages 215–220 New York NY USA 2013 ACM [3] K Brennan C Balch and M Chung Creative Computing Harvard Graduate School of Education 2014 [4] M Conway R Pausch R Gossweiler and T Burnette Alice A Rapid Prototyping System for Building Virtual Environments In Conference Companion on Human Factors in Computing Systems CHI ’94 pages 295–296 New York NY USA 1994 ACM [5] S Cooper W Dann and R Pausch Teaching Objects-first in Introductory Computer Science In Proceedings of the 34th SIGCSE Technical Symposium on Computer Science Education SIGCSE ’03 pages 191–195 New York NY USA 2003 ACM [6] S Dasgupta W Hale A Monroy-Hern ́andez and B M Hill Remixing as a pathway to computational thinking In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work & Social Computing CSCW ’16 pages 1438–1449 New York NY USA 2016 ACM [7] D A Fields M Giang and Y Kafai Programming in the wild Trends in youth computational participation in the online scratch community In Proceedings of the 9th Workshop in Primary and Secondary Computing Education WiPSCE ’14 pages 2–11 New York NY USA 2014 ACM [8] M Fowler Refactoring improving the design of existing code Addison-Wesley Longman Publishing Co Inc Boston MA USA 1999 [9] E Glinert Towards ”Second Generation” Interactive Graphical Programming Environments In Proceedings of the IEEE Workshop on Visual Languages pages 61—70 1986 [10] F Hermans and E Aivaloglou Do code smells hamper novice programming? In Proceedings of the International Conference on Program Comprehension 2016 to appear [11] F Hermans M Pinzger and A van Deursen Detecting and refactoring code smells in spreadsheet formulas Empirical Software Engineering 20(2)549–575 2015 [12] J H Maloney K Peppler Y Kafai M Resnick and N Rusk Programming by choice Urban youth learning programming with scratch In Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education SIGCSE ’08 pages 367–371 New York NY USA 2008 ACM [13] T J McCabe A complexity measure IEEE Trans Software Eng 2(4)308–320 1976 [14] O Meerbaum-Salant M Armoni and M Ben-Ari [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] Habits of programming in scratch In Proceedings of the 16th Annual Joint Conference on Innovation and Technology in Computer Science Education ITiCSE ’11 pages 168–172 New York NY USA 2011 ACM O Meerbaum-Salant M Armoni and M M Ben-Ari Learning Computer Science Concepts with Scratch In Proceedings of the Sixth International Workshop on Computing Education Research ICER ’10 pages 69–76 New York NY USA 2010 ACM J Moreno and G Robles Automatic detection of bad programming habits in scratch A preliminary study In 2014 IEEE Frontiers in Education Conference (FIE) pages 1–4 Oct 2014 J Moreno-Leo ́n G Robles and M Rom ́an-Gonza ́lez Dr Scratch Automatic Analysis of Scratch Projects to Assess and Foster Computational Thinking RED  Revista de Educacio ́n a Distancia (46)1–23 Jan 2015 B Moskal S Cooper and D Lurie Evaluating the Effectiveness of a New Instructional Approach In Proceedings of the SIGCSE technical symposium on Computer science education 2005 T W Price and T Barnes Comparing Textual and Block Interfaces in a Novice Programming Environment In Proceedings of the Eleventh Annual International Conference on International Computing Education Research ICER ’15 pages 91–99 New York NY USA 2015 ACM M Resnick J Maloney A Monroy-HernA ̃a􏰀ndez N Rusk E Eastmond K Brennan A Millner E Rosenbaum J Silver B Silverman and Y Kafai Scratch Programming for All Commun ACM 52(11)60–67 Nov 2009 L Seiter and B Foreman Modeling the learning progressions of computational thinking of primary grade students In Proceedings of the Ninth Annual International ACM Conference on International Computing Education Research ICER ’13 pages 59–66 New York NY USA 2013 ACM A Wilson T Hainey and T Connolly Evaluation of computer games developed by primary school children to gauge understanding of programming concepts In European Conference on Games Based Learning page 549 Academic Conferences International Limited 2012 D Wolber H Abelson E Spertus and L Looney App Inventor Create Your Own Android Apps O’Reilly Media Sebastopol Calif 1 edition edition May 2011 S Yang C Domeniconi M Revelle M Sweeney B U Gelman C Beckley and A Johri Uncovering trajectories of informal learning in large online communities of creators In Proceedings of the Second (2015) ACM Conference on Learning @ Scale L@S ’15 pages 131–140 New York NY USA 2015 ACM 61 
Introducing Computational Thinking in Education Courses Aman Yadav Dept of Educational Studies Purdue University West Lafayette Indiana USA amanyadav@purdueedu Ninger Zhou Dept of Educational Studies Purdue University West Lafayette Indiana USA zhoun@purdueedu Chris Mayfield Dept of Computer Science Purdue University West Lafayette Indiana USA cmayfiel@cspurdueedu Susanne Hambrusch Dept of Computer Science Purdue University West Lafayette Indiana USA seh@purdueedu John T Korb Dept of Computer Science Purdue University West Lafayette Indiana USA jtk@purdueedu ABSTRACT As computational thinking becomes a fundamental skill for the 21st century K-12 teachers should be exposed to computing principles This paper describes the implementation and evaluation of a computational thinking module in a required course for elementary and secondary education majors We summarize the results from open-ended and multiple-choice questionnaires given both before and after the module to assess the students’ attitudes toward and understanding of computational thinking The results suggest that given relevant information about computational thinking education students’ attitudes toward computer science becomes more favorable and they will be more likely to integrate computing principles in their future teaching Categories and Subject Descriptors K32 [Computer and Information Science Education] Curriculum General Terms Experimentation Measurement Keywords Computational Thinking K-12 Education Non-Majors 1 COMPUTATIONAL THINKING IN K-12 Wing suggested that “computational thinking” (CT) is a fundamental skill of analytical thinking for everyone not just for computer scientists [10] She described computational thinking as “solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science” Wing also pointed out Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page To copy otherwise to republish to post on servers or to redistribute to lists requires prior specific permission and/or a fee SIGCSE’11 March 9–12 2011 Dallas Texas USA Copyright 2011 ACM 978-1-4503-0500-6/11/03 $1000 the untapped potential of computational thinking for K-12 education by stating “To reading writing and arithmetic we should add computational thinking to every child’s analytical ability” A report on computational thinking by the National Research Council (NRC) advanced a similar idea that CT is a cognitive skill which the “average person is expected to possess” [5] Similarly Bundy suggested that computational thinking concepts have been used in other disciplines via problem solving processes and that the ability to think computationally is essential to every discipline [4] The pervasiveness of computational thinking concepts dictates the importance of exposing students to such notions early in their school years and helping them to become conscious about when and how to apply this essential skill The NRC report also highlighted “(1) that students can learn thinking strategies such as computational thinking as they study a discipline (2) that teachers and curricula can model these strategies for students and (3) that appropriate guidance can enable students to learn to use these strategies independently” Teacher education is one discipline where computational thinking will have significant impact As we prepare future educators to present their subject areas using ideas from computational thinking K-12 students will have greater exposure to computing in general In this paper we describe the implementation of a CT module in two sections of a core education course required for all elementary and secondary education majors We present a pre- and post-assessment of the education students’ understanding and attitude of computational thinking which measured the influence the CT module had on them In particular only 20% of the students on the presurvey described computing as “the process of solving problems” as compared to 70% on the post-survey On the presurvey 30% of the students agreed that computing relates to any or all fields and the percentage increased to 62% on the post-survey Overall the CT module helped the students understand that (1) they can teach computing concepts in K-12 classrooms without the use of computers and (2) CT concepts can be incorporated across all disciplines Computational thinking in education has the potential to significantly advance the problem-solving skills of K-12 students However literature on implementing computational thinking in a K-12 setting is still relatively sparse There 465 have been a number of workshops on integrating computational thinking at the high school level [1 6 7] But there is little research that has systematically and comprehensively examined the influence of computational thinking on preservice teachers (ie education students) Exploratory investigations have demonstrated how exposure to computational thinking enhances the way students approach problems For example Lewandowski et al illustrated the idea of “commonsense programming” for students without programming experience [8] Students were asked to propose solutions to avoid selling theater tickets for the same seat twice at multiple box offices The results showed that 69% of the solutions correctly identified a race condition which indicated that the students were indeed equipped with a natural but undeveloped understanding for solving problems computationally Several researchers have made the effort to introduce CT to in-service computer science high school teachers during workshop sessions that promote the awareness of integrating CS across all subject areas [3] The high school teacher participants were reported to have extended their understanding of the scope of CS and considered CS as more than just programming More importantly a comparison of the pre- and post-survey indicated that the realization of the importance of “developing computational thinking skills for all aspects of life” emerged as a result of the workshop An important step for successfully integrating computational thinking into the K-12 curriculum is to prepare future teachers to teach it Section 2 briefly describes our efforts to showcase a variety of CT concepts to pre-service teachers In Section 3 we present a summary of our pre- and post-survey which demonstrates a positive change of attitude among the students We conclude the paper with an overall discussion in Section 4 2 OVERVIEW OF THE CT MODULE We developed a one-week computational thinking module for the course “Learning and Motivation” which is required for all elementary and secondary majors The course introduces future K-12 teachers to basic concepts of classroom management learning styles student motivation and assessment The main content of the course includes theories of learning and motivation the role of formal and informal assessment in fostering learning and motivation and ways to adapt instruction both to individual students and differences in social cultural and contextual factors Since computational thinking naturally includes problem solving and understanding human behavior it fits well with the topics already covered in class such as probabilistic reasoning algorithms and heuristics and hypothesis testing We replaced the originally presented unit on problem solving and critical thinking with new lectures on computational thinking The purpose of the CT module was not only to expose students to ideas in computing but to show how these ideas can be used in their future teaching careers as well Faculty and students from educational studies and computer science jointly developed the lecture material Special emphasis was placed on highlighting the core concepts of computational thinking while presenting material the students could relate to and easily apply in a K-12 classroom The module was presented around the middle of the semester and students had not been exposed to CT material in earlier lectures Before the CT module was introduced students had primarily studied educational theories on how people learn The CT lectures provided students with an overview of computational thinking and engaged them in activities that showcased CT principles Students worked in pairs and each pair was given a “clicker” to provide responses See the appendix for an outline of the lectures and clicker questions The original slides are available on our website1 The first lecture introduced students to the definition of computational thinking and five basic CT concepts problem identification and decomposition abstraction logical thinking algorithms and debugging The concepts were introduced through examples activities and clicker questions For example debugging was discussed by asking students to troubleshoot the scenario of a lamp not working when they get home from school but was working in the morning Students used clickers to respond to a sequence of questions to locate the problem in order to make the lamp work again The second lecture focused on the role of computational thinking in day-to-day life and emphasized the importance and application of CT in K-12 education We discussed how problem-solving abstraction and critical thinking can be introduced in a classroom setting The lecture highlighted how computational thinking is a useful tool for dealing with ill-defined problems where there might not be a clear-cut solution and information needed to solve the problem may be missing The lecture also presented information on how to teach algorithms through kinesthetic activities and gave an example of recursion Several members of our project acted out the Towers of Hanoi (for n = 5) Finally we provided examples of computational thinking in core content areas such as science and humanities 3 ATTITUDE SURVEY RESULTS We assessed the students’ attitudes toward computing and their understanding of computational thinking through a pre- and post-survey surrounding the CT module All 155 students from the two sections of the course were emailed a link to the survey 100 students — 78 female and 22 male — completed both the pre-survey the week before the CT module and the post-survey during the week after the CT module As a motivation to participate extra credit was given to students who completed both surveys (the pre- and post-surveys were anonymous but linked together via answers to security questions) The surveys consisted of sixteen multiple-choice questions (on a Likert scale from strongly agree to strongly disagree) and four open-ended questions — see the appendix for the complete post-survey An external evaluator was responsible for collecting and validating the data We analyzed the responses for patterns and significant differences between preand post-surveys The most interesting results came from the participants’ open-ended responses which we present in this section Just over half of the students who responded (55) were preparing to teach at the elementary level; the remainder (45) at the secondary level Approximately 80% of the elementary education participants were female (44 vs 11) while at the secondary level over 75% were female (34 vs 11) About 65% of the students enrolled responded to the survey 1http//cs4educspurdueedu/comp_think 466 A1 A2 A3 A4 0 20 40 60 80 100 69% 24% 20% 70% 7% 1% 4% 3% Pre−Survey Post−Survey A1 To use computers and/or technology to solve a problem and make tasks easier A2 The process of solving problems (use of computer or technology not mentioned) A3 The study of computers A4 Other Figure 1 Participants’ view of computing 31 Participants’ View of Computing Survey participants were asked to describe their view of computing and its purpose The basic trends of the participants’ responses differed greatly from the pre- to postsurvey as shown in Figure 1 (Not all percentages add up to 100% due to blank responses) On the pre-survey a majority (69%) of the participants’ responses contained themes that viewed computing as solving problems or making tasks easier through the use of computers and/or technology For example one student stated “Computing is the use of computers or some other form of technology to solve a problem Its purpose is to help solve problems that might be more difficult to solve without some form of technology” Only 20% of participants’ responded viewing computing and its purpose as the process of solving problems (use of computer or technology not mentioned) The following comment highlights computing as a process of solving problems without the use of computers or technology “Computing is the science of solving a problem using some pre-set method that has been established Its purpose is to assist us in solving everyday problems we might be faced with” Finally 7% of the students reported computing as the study of computers For example “Being able to use and apply computer skills to daily life These skills can run from typing to using different applications and software in many different areas” In the post-survey a majority of the participants’ responses (70%) reflected the basic trend that viewed computing as the ability/knowledge/process used to solve problems and make tasks easier (use of computer or technology not mentioned) For example a student highlighted this view of computing stating “Computing is where you logically think something through Its purpose is so that students can explore to find an answer to a problem” Another student reported “I believe that computing does not necessarily involve working with computers but working to solve any type of problem Its purpose is to calculate equations and problems to formulate a correct result” On the other hand 24% viewed computing as solving problems or making tasks easA1 A2 A3 A4 A5 0 20 40 60 80 100 33% 86% 32% 0% 8% 7% 7% 7% 20% 0% Pre−Survey Post−Survey A1 The process of solving problems A2 To use computers and/or technology to solve a problem or make tasks easier A3 The study of computers; solving problems like a computer A4 Other A5 Not sure Figure 2 Participants’ view of CT ier through the use of computers and/or technology This view is highlighted by the following comments “Computing is using technology or computer software to aid in solving problems Its purpose is to make difficult tasks easier and simpler” Only one participant reported computing as the study of computers By de-emphasizing technology and encouraging algorithmic thinking the lectures helped the education students understand that computational thinking doesn’t always require the use of computers to solve problems 32 Participants’ View of CT In both the pre- and post-survey participants were asked to define computational thinking from their point of view Figure 2 summarizes the basic trends in the participants’ responses between the pre- and post-surveys Although answers varied we found basic trends among them One third (33%) of participants’ responses in the pre-survey reflected trends that viewed computational thinking as “the process of problem-solving” which increased to 86% on the postsurvey In addition responses used more specific terminology and examples (eg pre-survey response process of solving problems post-survey response process of solving problems using algorithms etc) On the pre-survey 20% of participants responded that they “didn’t know” what their view on computational thinking was and on the post-survey none of the participants responded that they “didn’t know” Additionally on the pre-survey where almost one third (33%) of participants’ responses reflected trends regarding computational thinking as “the use of computers or technology to solve a problem or make tasks easier” none of the participants’ responses on the post survey reflected the idea that computers and technology absolutely must be involved in the definition of computational thinking In short many more students identified the relationship between problem solving and computational thinking after receiving the CT module 467 A1 A2 A3 A4 0 20 40 60 80 100 31% 86% 49% 7% 8% 6% 12% 1% Pre−Survey Post−Survey A1 Promote problem solving skills / critical thinking in the classroom A2 Utilizing computers and technology in the classroom A3 Other A4 Don't Know Figure 3 Integrating CT into the classroom 33 Integrating CT into the Classroom Survey participants were also asked how computational thinking can be integrated into the K-12 classroom Figure 3 summarizes their responses On the pre-survey almost half of the participants’ responses reflected the view that in order to integrate computational thinking into the classroom computers and technology were needed In contrast only 7% of participants’ responses reflected that trend on the post-survey During the one week module many students realized the benefits of understanding CT principles and being able to apply them more systematically as a problem solving technique This change in attitude is also reflected in the question on whether CT promotes problem solving and critical thinking skills The responses switched from 31% agreeing to 86% of the participants agreeing Also it seems every student had some concept about computational thinking after the module as reflected by the “don’t know” category In summary we saw almost a three-fold increase in the number of education majors who now hold the opinion that computational thinking could be used to enhance problem solving activities in a K-12 classroom 34 Relationship to Other Fields We also asked the students about the relationship of computational thinking to other disciplines While 30% indicated that “Computational thinking relates to any or all fields” in the pre-survey that number rose to 62% in the post-survey In addition over 95% of the survey participants either agreed or strongly agreed with the following statements “Computational thinking can be integrated into classroom education in other fields”“Computational thinking should be integrated into classroom education for other disciplines” and “Having background knowledge and understanding of computer science is valuable in and of itself” As future work we plan to embed computational thinking modules in content area courses and teaching methods courses including hands-on training in how to implement kinesthetic activities like Computer Science Unplugged [2] 4 DISCUSSION Results from the two surveys suggest that the CT module was effective overall in increasing the students’ awareness of computational thinking Specifically the post-survey responses were more sophisticated and showcased students’ understanding that computational thinking was more than using computers and technology Students also had a better grasp of how computational thinking can be integrated into their future teaching by promoting problem solving and critical thinking skills (ie not by merely using computers) These findings have important implications for incorporating computational thinking in education as well as other subject areas Given that computational thinking is becoming a fundamental skill for the 21st century it is important to introduce it in disciplines outside of computer science and at the K-12 level Specifically computational thinking concepts must appear as early as the primary grades and then continue through the secondary grades and beyond [9] One way to do this is to incorporate computational thinking modules into core education courses to expose future teachers to this idea Results from the current work suggest that such an approach has the potential to change future teachers’ understanding of computational thinking and how it can be integrated in their classrooms In summary we have shown that given relevant information in computing education students’ attitude toward computing becomes more favorable They also see applications of computing principles in their careers more readily We plan to repeat the CT module in “Learning and Motivation” and are also developing an online version of the module for “Introduction to Educational Technology” another course required of all education majors We hope that our approach to CT modules will attract education students into computing courses that emphasize computer science principles as well as traditional programming courses 5 ACKNOWLEDGEMENTS This work was supported by the NSF CPATH program under grant CNS-0938999 and through a gift from State Farm We especially thank Courtney Brown for her help with the administration of the two surveys We also appreciate the CS4EDU team and the anonymous reviewers for their thoughtful feedback on the paper 6 REFERENCES [1] V Allan V Barr D Brylow and S Hambrusch Computational thinking in high school courses In SIGCSE 2010 [2] T Bell I H Witten and M Fellows Computer science unplugged http//csunpluggedorg/ December 2006 [3] L Blum and T J Cortina CS4HS An outreach program for high school CS teachers In SIGCSE 2007 [4] A Bundy Computational thinking is pervasive Journal of Scientific and Practical Computing 167–69 2007 [5] Committee for the Workshops on Computational Thinking Report of a Workshop on The Scope and Nature of Computational Thinking The National Academies Press 2010 [6] D D Garcia C M Lewis J P Dougherty and M C Jadud If  you might be a computational thinker In SIGCSE 2010 468 [7] P B Henderson T J Cortina and J M Wing Computational thinking In SIGCSE 2007 [8] G Lewandowski D Bouvier R McCartney K Sanders and B Simon Commonsense computing (episode 3) Concurrency and concert tickets In ICER ’07 Proceedings of the Third International Workshop on Computing Education Research 2007 [9] J A Qualls and L B Sherrell Why computational thinking should be integrated into the curriculum Journal of Comp Sci in Colleges 2566–71 2010 [10] J Wing Computational thinking Communications of the ACM 4933–35 2006 APPENDIX A OUTLINE OF THE CT MODULE Lecture 1 Computational Thinking and 21st Century Problem Solving 1 Object lesson driving directions • “How do you get from school to the mall?” Clicker questions 1–2 • “How did you think about the problem?” CT concepts Algorithm Efficiency • “What if the main road was closed?” CT concepts Debugging • ”How do computers solve this problem?” CT concepts Abstraction Automation 2 What is computational thinking? • An approach to problem solving which uses abstraction to create algorithmic solutions which can be automated with computation • A fundamental skill used by everyone by the middle of the 21st century (ie just like reading writing and arithmetic) 3 Daily examples of CT • Looking up names in a phone book • Buying movie tickets (multiple lines) • Clicker question 3 • CT is     CT is not  4 Concept #1 Abstraction • “CT is reformulating a seemingly difficult problem into one we know how to solve” • People standing in line → Queue • Cafeteria plates → Stack 5 Concept #2 Logical Thinking • Inductive reasoning observation → pattern → hypothesis → theory • Deductive reasoning theory → hypothesis → observation → confirm 6 Concept #3 Algorithms • Activity “peanut butter and jelly sandwich” • Explain “write it/ do it” (Science Olympiad) • Homework “swap puzzle” on cs4fnorg 7 Concept #4 Debugging • Clicker questions 4–5 • Discuss reasoning behind each answer Lecture 2 Computational Thinking in K-12 1 Review of previous lecture • Clicker questions 1–3 • CT Concepts decomposition abstraction logical thinking algorithms debugging automation • More definitions for CT 2 Why is CT important for K-12? • Enhances problem solving techniques • Moves students beyond technology literacy • CT is a higher-level cognitive process 3 CT and problem solving strategies • Heuristic an experience-based strategy that facilitates problem solving • Algorithm a specific sequence of steps that guarantees a solution 4 How do you teach algorithms? • Demonstrate specific procedures; apply examples • Help students explain their thinking and debug • Role play Towers of Hanoi 5 Using technology to motivate CT • Facebook friend network visualization • Google’s public data explorer • Amazon/Netflix/etc recommendations • “What other tools have you seen?” 6 Applying CT to any content area • Science Social Studies Economics    • Social Sciences Medicine Humanities    7 The big picture • CT is a fundamental skill for everybody • State of computing in secondary education • Highlight “CS Principles” proposed AP course B CLICKER QUESTIONS Lecture 1 (Intro to CT) 1 How extensive were your directions? [A] One step (eg type “mall” into GPS or Google Maps) [B] Two steps (eg from downtown take bus #4) [C] Several steps (eg head east on SR-15 to 3rd Street) [D] A detailed turn-by-turn route (eg from the union) [E] None of the above (eg “Man I was way off”) 2 How did you figure out the driving directions? [A] Knew them already; simply “recalled” the route [B] Sketched out a high-level map on paper [C] Thought about several ways picked one [D] Texted a friend when no one was looking [E] Modeled the entire city as an undirected graph solved the “single-pair shortest path problem” and applied it to the source and destination 469 3 What is the quickest way to serve 20 pizzas to 60 hungry students? [A] One table with pizzas (the usual case) [B] Five tables with four pizzas each [C] People stay put and pizzas are passed around [D] Four servers bringing the pizza around Scenario You come home and the desk lamp in your apartment stopped working (it worked in the morning) 4 What is your first step to solve the problem? [A] Check if the lamp is turned on [B] Check if the light bulb is working [C] Check if the lamp is plugged in [D] Check if the outlet is working [E] Check if there is power in the room Scenario You checked A-E and it is still not working 5 What do you do next? [A] Buy a new lamp [B] Call your mother/friend/landlord/etc [C] Use your roommate’s lamp [D] Repeat steps A-E from before [E] Forget about the problem for the day Lecture 2 (Review of CT) 1 What are the two main ideas of computational thinking? [A] Abstraction and Automation [B] Algorithm and Analysis [C] Debugging and Logical Thinking [D] All of the above 2 Computational thinking relies on the use of computer programs [A] True [B] False 3 Computational thinking mainly involves computer science and has little impact on other subject areas [A] True [B] False C POST-SURVEY Indicate whether you (1) strongly agree (2) agree (3) disagree or (4) strongly disagree 1 Knowledge of computing will allow me to secure a better job 2 My career goals do not require that I learn computing skills 3 I doubt that I can solve problems by using computer applications 4 I expect to use software in my future educational and career work 5 I can achieve good grades (C or better) in computing courses 6 The challenge of solving problems using computer science appeals to me 7 I expect to use computer applications for future projects involving teamwork 8 I can learn to understand computing concepts 9 I am not comfortable with learning computing concepts 10 I expect to use computing skills in my daily life 11 I hope that my future career will require the use of computing concepts 12 I think that computer science is interesting 13 I will voluntarily take computing courses if I were given the opportunity 14 Computational thinking can be integrated into classroom education in other fields 15 Computational thinking should be integrated into classroom education for other disciplines 16 Having background knowledge and understanding of computer science is valuable in and of itself Open-ended questions 1 In your view what is computing? What is its purpose? 2 In your view what is computational thinking? 3 How can we integrate computational thinking in the classroom? 4 How does computational thinking relate to other disciplines and fields? Please provide specific examples 470 
Vviewpoints august 2008 | vol 51 | no 8 | communications of the acm 25 doi101145/13787041378713 Mark Guzdial Education Paving the Way for Computational Thinking Drawing on methods from diverse disciplines—including computer science education sociology and psychology—to improve computing education T eaching everyone on campus to program is a noble goal put forth by Alan Perlis in 1962 Perlis who was awarded the first ACM AM Turing Award said that everyone should learn to program as part of a liberal education He argued that programming was an exploration of process a topic that concerned everyone and that the automated execution of process by machine was going to change everything He saw programming as a step toward understanding a “theory of computation” which would lead to students recasting their understanding of a wide variety of topics (such as calculus and economics) in terms of computation4 Today we know that Perlis was prescient—the automated execution of process is changing how professionals of all disciplines think about their work As Jeanette Wing has pointed out the metaphors and structures of computing are influencing all areas of science and engineering6 Computing professionals and educators have the responsibility to make computation available to thinkers of all disciplines Part of that responsibility will be met through formal education While a professional in another field may be able to use an application with little training the metaphors and ways of thinking about computing must be explicitly taught To teach computational thinking to everyone on campus may require different approaches than those we use when we can assume our students want to become computing professionals Developing approaches that will work for all students will require us to answer difficult questions like what do non-computing students understand about computing what will they find challenging what kinds of tools can make computational thinking most easily accessible to them and how should we organize and structure our classes to make computing accessible to the broad range of students Through a few brief examples I will show in this column how these ILLUSTRATION BY CHRISTOPHER SILAS NEAL 1_CACM_V518indb 25 7/21/08 101249 AM 26 communications of the acm | august 2008 | vol 51 | no 8 viewpoints questions are being addressed by researchers in the field of computing education research Researchers in computing education draw on both computer science and education— neither field alone is sufficient While we computer scientists understand computing from a practical rational and theoretical perspective questions about education are inherently human questions Humans are often impractical irrational and difficult to make predictions or proofs about Computing education researchers are using experimentation and design to demonstrate we can address important questions about how humans come to understand computing and how we can make it better Research in computing education will pave the way to make “computational thinking” a 21st century literacy that we can share across the campus Understanding Computing Before Programming A research theme in the early 1980s was how to design programming languages so they would be more like natural languages An obvious question then is how people specify processes in natural language Lance A Miller asked his study participants to specify file manipulation tasks for another person A task might be “Make a list of employees who have a job title of photographer and who are rated superior given these paper files” Miller studied the language used in his participants’ descriptions2 One of Miller’s surprises was how rarely his participants explicitly specified any kind of control flow There was almost no explicit looping in any of their task descriptions While some tested conditions (“IF”) none ever specified an “ELSE” He found this so surprising that he gave a second set of participants an example task description without looping and no ELSE specification The second set of participants easily executed the task description When asked what they were doing if the condition was not met or if data was exhausted they replied (almost unanimously Miller reports) “Of course you just check the next person or if there are no more you just go on” Miller’s results predict some of the challenges in learning to program— challenges that are well-known to teachers of introductory classes today While process descriptions by novices tend not to specify what to do under every condition computers require that specificity Miller’s results suggest what kinds of programming languages might be easier for novices Programming languages like APL and MATLAB and programming tools for children like Squeak’s eToys use implicit looping as did the participants in Miller’s studies Twenty years later John Pane and his colleagues at Carnegie Mellon University revisited Miller’s questions in new contexts3 In one experiment Pane showed his subjects situations and processes that occur in a Pacman game then asked how they would specify them The subjects responded with explanations like “When Pacman gets all the dots he goes to the next level” Like Miller Pane found that participants rarely used explicit looping and always used one-sided conditionals Pane went further to characterize the style of programming that the participants used He found that over half of the participants’ task statements were in the form of production rules as in the example He also saw the use of constraints and imperative statements but little evidence of object-oriented thinking Participants did talk about accessing behaviors built into an entity but rarely from the perspective of that entity; instead it was from the perspective of the player or the programmer He found no evidence of participants describing categories of entities (defining classes) inheritance or polymorphism Pane’s results suggest that objectoriented thinking is not “natural” in the sense of being characteristic of novices’ task descriptions Since obFigure 1 Traditional conditional structure if (value < 10) then value = value + 10; else sum = sum + value; end if Figure 2 New conditional structure if (value < 10) value = value + 10; not (value < 10) sum = sum + value; end (value < 10) wwwacmorg/dl ACM Digital Library TheUltimateOnline INFORMATIONTECHNOLOGY Resource • NEW Author Profile Pages • Improved Search Capabilities • Over 40 ACM publications plus conference proceedings • 50+ years of archives • Advanced searching capabilities • Over 2 million pages of downloadable text Plus over one million bibliographic citations are available in the ACM Guide to Computing Literature To join ACM and/or subscribe to the Digital Library contact ACM Phone 18003426626 (US & Canada) +12126260500 (Global) Fax +12129441318 Hours 830 am-430 pm EST Email acmhelp@acmorg Join URLwwwacmorg/joinacm Mail ACM Member Services General Post Office PO Box 30777 New York NY 10087-0777 USA DL_one-third_page_4CLayout 1 6/26/08 405 PM Page 1 1_CACM_V518indb 26 7/21/08 101249 AM viewpoints august 2008 | vol 51 | no 8 | communications of the acm 27 jects are the foundation of most modern software today his results point out where we can expect to find challenges in explaining objects to students Both Miller’s and Pane’s results encourage us to think how we might design languages for novices that play to their natural ways of thinking about specifying computation like the use of eventbased programming in MIT’s Scratch In the last four years a multinational group of researchers has explored “Commonsense Computing” what do our students know before we teach them? Given a complex task how do people without programming knowledge specify an algorithm for that task? In one paper Lewandowski et al1 explore concurrency—in a complex task of multiple box offices selling tickets for a theater how well do non-programming students avoid selling the same seat twice? The results showed that 97 solutions (69% of the total drawn from five institutions) were correct; only 31% of the solutions (45% of the correct solutions) were distributed so teachers of algorithms classes need not worry about being put out of business Noncomputing students do not naturally come up with the elegant solutions that computer scientists have devised However these results suggest that students can “naturally” think about concurrency correctly Problems with implementing concurrent programs might stem more from the challenges in specifying those algorithms in current programming languages rather than from the complexity of the algorithms themselves Redesigning Programming Languages Both Pane’s and Miller’s results make suggestions about the design of programming languages if the goal is to make computational ideas more accessible to novices Testing new forms of programming languages was an area of active exploration by Thomas RG Green Elliot Soloway and others In one paper Green and his colleagues explored alternatives to the traditional conditional structure5 A typical structure might look like the structure shown in Figure 1 They tested a new structure where this would be written as shown in Figure 2 This new structure makes explicit the condition for the execution of each clause of the condition Green and his colleagues found that novices were able to correct mistakes using the second form 10 times faster than programs using the first form Miller and Pane found that their participants simply never used an else clause Instead it seemed obvious (“of course”) what to do when the tested condition wasn’t true Miller’s and Pane’s subjects were doing something different than Green’s Writing a task description is different than reading and fixing a task description Green’s results complement Miller’s and Pane’s Novices do not naturally write the else clause—they think it’s obvious what to do if the test fails However conditionals in programs are not always obvious and it’s easier for the novices trying to read those programs if the conditions for each clause’s execution are explicit Paving the Way for “Computational Thinking” For All To make “computational thinking” accessible to students across the entire campus we need to understand how to teach computing better Computing education researchers explore how humans come to understand computing and how to improve that understanding Computing education research is a close cousin to human-computer interaction since HCI researchers explore how humans interact with computing and how to improve that interaction Computing education researchers have found a home in the International Computing Education Research (ICER) workshop (whose fourth annual meeting will be held this September in Sydney Australia; see wwwnewcastleedu au/conference/icer2008/) and in journals like Computer Science Education and Journal on Educational Resources in Computing Computing education research draws on a variety of disciplines to make computing education better Social scientists like Jane Margolis Lecia Barker and Carsten Schulte help us to understand how students experience our classes (which often differs from what we might expect as teachers) and how we can change our classes to make them more successful for all students Computing education researchers draw on methods from education sociology and psychology in order to measure learning about computing and understand the factors that influence that learning By making computing education better we can broaden access to computing ideas and capabilities When we can teach every student programming and the theory of computation in a way that makes sense to them for their discipline we will see how ubiquitous understanding of computing will advance the entire academy just as Perlis predicted over 45 years ago References 1 Lewandowski G et al Commonsense computing (episode 3) Concurrency and concert tickets In Proceedings of theThird International Workshop on Computing Education Research (2007) 133–144 2 Miller LA Natural language programming Styles strategies and contrasts IBM Systems Journal 29 2 (1981) 184–215 3 Pane JF Ratanamahatana C and Myers BA Studying the language and structure in nonprogrammers’ solutions to programming problems International Journal of Human-Computer Studies 54 (2001) 237–264 4 Perlis A The computer in the university In M Greenberger Ed Computers and the World of the Future MIT Press Cambridge MA 1962 180–219 5 Sime ME Arblaster AT and Green TRG Structuring the programmer’s task Journal of Occupational Psychology 50 (1977) 205–216 6 Wing J Computational thinking Commun ACM 49 3 (Mar 2006) 33–35 Mark Guzdial (guzdial@ccgatechedu) is a professor in the College of Computing at Georgia Institute of Technology in Atlanta GA The Communications “Education” column will feature commentary on education issues presenting research results and opinions that inform how the challenges of computing education can be best addressed © 2008 ACM 0001-0782/08/0800 $500 Research in computing education will pave the way to make “computational thinking” a 21st century literacy that we can share across the campus 1_CACM_V518indb 27 7/21/08 101249 AM 
Computers & Education 72 (2014) 145–157 Contents lists available at ScienceDirect Computers & Education journal homepage wwwelseviercom/locate/compedu Computational thinking and tinkering Exploration of an early childhood robotics curriculum Marina Umaschi Bers Louise Flannery Elizabeth R Kazakoff Amanda Sullivan Tufts University Medford MA USA articleinfo abstract Article history Received 30 January 2013 Received in revised form 22 October 2013 Accepted 29 October 2013 Keywords Elementary education Interactive learning environments Pedagogical issues Teaching/learning strategies robotics Programming Early childhood 1 Introduction By engaging in construction-based robotics activities children as young as four can play to learn a range of concepts The TangibleK Robotics Program paired developmentally appropriate computer program- ming and robotics tools with a constructionist curriculum designed to engage kindergarten children in learning computational thinking robotics programming and problem-solving This paper documents three kindergarten classrooms’ exposure to computer programming concepts and explores learning outcomes Results point to strengths of the curriculum and areas where further redesign of the curric- ulum and technologies would be appropriate Overall the study demonstrates that kindergartners were both interested in and able to learn many aspects of robotics programming and computational thinking with the TangibleK curriculum design  2013 Elsevier Ltd All rights reserved For decades early childhood (preschool to grade two) curricula have focused primarily on literacy and math especially with the educational reforms of No Child Left Behind (Zigler & Bishop-Josef 2006) However there has been some recent attention to science technology engineering and math (STEM) learning for young children (Gelman & Brenneman 2004; Sesame Workshop 2009; White House 2011) Furthermore new technology learning standards and best practices for integrating technology into early childhood educa- tion have been developed (Barron et al 2011; International Society for Technology in Education (ISTE) 2007; NAEYC & Fred Rogers Center for Early Learning and Children’s Media 2012; US Department of Education 2010) Of note the technology policy statement from NAEYC & Fred Rogers Center for Early Learning and Children’s Media (2012) provides a guide for early childhood education professionals in using interactive digital technologies in balanced and developmentally appropriate ways It addresses important issues related to using digital technology with children ages three–eight years including the needs for technology use to serve the needs of the children and for educators to be able to understand evaluate and integrate developmentally appropriate technologies in their classrooms However there is little research on computer programming specifically for early childhood the subject this paper explores As new devices from smartphones and tablet computers to electronic learning toys find new audiences with increasingly young children challenging question arise about how to define developmentally appropriate activities and content for children of different ages While the majority of research on robotics and programming in education focuses on later schooling teaching these subjects during foundational early childhood years can be an engaging and rewarding experience for young learners (Bers 2008) Previous research has shown that children as young as four–six years old can build and program simple robotics projects (Bers Ponte Juelich Viera & Schenker 2002 pp 123–145; Cejka Rogers & Portsmore 2006; Kazakoff Sullivan & Bers 2012; Perlman 1976 p 260; Wyeth 2008) as well as learn powerful ideas from engineering technology and computer programming while also building their computational thinking skills (Bers 2008) Robotic manipulatives allow children to develop fine-motor skills and hand–eye coordination while also engaging in collabora- tion and teamwork Additionally robotics can provide a fun and playful way for teachers to integrate academic content with the creation of  Corresponding author DevTech Research Group Eliot Pearson Department of Child Development 105 College Ave Medford MA 02155 USA Tel þ1 617 347 5746 E-mail address ElizabethKazakoff@Tuftsedu (ER Kazakoff) 0360-1315/$ – see front matter  2013 Elsevier Ltd All rights reserved http//dxdoiorg/101016/jcompedu201310020 146 MU Bers et al / Computers & Education 72 (2014) 145–157 meaningful projects Through robotics young children can experiment with concepts of engineering as well as storytelling by creating narrative contexts for their projects (Bers 2008) By engaging in these types of robotics projects young children play to learn while learning to play in a creative context (Resnick 2003) Computers offer new ways of representing and interacting with information and an entirely new category of “objects to think with” (Papert 1980) In the form of programmable and interactive robots computers can become powerful learning tools Robotics offers children the opportunity to engage with content from the domain of computer science practice problem-solving skills and work on fine-motor skills and eye–hand coordination The TangibleK Robotics Program a design-based research initiative now in its fifth year has paired develop- mentally appropriate programming and robotics tools with a curriculum to engage kindergartners in learning computational thinking robotics and programming concepts as well as problem-solving and reasoning The goal of this paper is to present young children’s learning outcomes on computer programming concepts as taught through the TangibleK curriculum in order to highlight the potential for learning of integrating computer programming and robotics into the early childhood classroom 11 Theoretical framework constructionism and positive technological development The theoretical approach used for designing the educational intervention and curriculum and for integrating the TangibleK Robotics Program into early childhood classrooms incorporates elements from Papert’s (1980) constructionist framework which states that children can learn deeply when they build their own meaningful projects in a community of learners and reflect carefully on the process Papert’s (1980) constructionism is rooted in Piaget’s (1954) constructivism – which conveys the idea that the child actively builds knowledge through experience – and the related “learn-by-doing” approach to education While Piaget’s (1954) theory was developed to explain how knowledge is constructed in an individual’s mind Papert (1980) expands on it to focus on the ways that internal constructions are supported by constructions in the world including through the use of computers and robotics A constructionist teaching approach provides children the freedom to explore their own interests through technologies (Bers 2008) while investigating domain-specific content learning and also exercising meta-cognitive problem-solving and reasoning skills (eg Clements & Gullo 1984; Clements & Meredith 1992) Papert (1980) discussed that well-designed constructionist activities have embedded in them ‘powerful ideas’ central concepts within a domain that are both epistemological and personally useful interconnected with other disciplines and have roots in intuitive knowledge that a child has internalized over a long period of time (Bers et al 2002; Papert 1980) An idea may be considered powerful to the degree that it is useful in building and extending further knowledge (Papert 2000) The robotics curriculum described in this paper is composed of powerful ideas from the domains of computer science and engineering (eg the engineering design process debugging robotic motion and sensing using programming instructions control flow by sequence control flow by specific instructions) Classroom activities designed to impact learning outcomes and cognitive growth also have an impact on (and are influenced by) children’s social emotional and moral development As a framework to guide the design and implementation of a robotics curriculum that also focuses on these dimensions of the child Bers’ (2010 2012) Positive Technological Development (PTD) was utilized PTD takes into consideration the learning environment and pedagogical practices as well as cultural values and rituals which mediate teaching and learning (Bers 2008; Rogoff Goodman Turkanis & Bartlett 2001) The educational experience proposed by the presented robotics cur- riculum was structured using the PTD framework to encourage six behaviors which in turn foster the development of beneficial core cognitive and social traits Specifically engaging in content generation creative design and problem-solving collaboration communication choices of conduct and community-building may lead to a sense of competence and confidence the ability to connect with and care about others contribution to entities outside the self and moral character (Bers 2010 2012) For instance by iteratively planning and revising a robotics project in a supportive environment children may gain confidence in their abilities to learn and solve problems Alternatively discussions of how to share limited resources fairly amongst the class are opportunities for positive moral development 12 Learning through computer programming Embedded in the exploration of computer programming and robotics the TangibleK curriculum also fosters computational thinking This term has been defined in many ways and encompasses a broad and somewhat debated range of analytic and problem-solving skills dis- positions habits and approaches used in computer science (Barr & Stephenson 2011; International Society for Technology Education and The Computer Science Teachers Association 2011; Lee et al 2011) The TangibleK curriculum specifically fosters computational thinking skills such as problem representation; systematicity in generating and implementing solutions; exploring multiple possible solutions; problem-solving on multiple levels – from approaching the overall challenge to “debugging” or trouble-shooting specific difficulties with a given solution’s implementation; productive attitudes toward “failure” and misconceptions uncovered along the route to a successful project; and strategies for approaching open-ended and often difficult problems Such skills are of general applicability beyond robotics and computational thinking 13 The TangibleK Robotics Program The TangibleK Robotics Program whose design is informed by the theoretical frameworks of constructionism and PTD has iteratively implemented and assessed a set of programming and robotics tools curricula and pedagogical approaches in close collaboration with hundreds of children and dozens of teachers over the course of five years The research goals of the TangibleK Robotics Program are to 1) Provide an evidence-based description of young children’s learning trajectories in computational thinking and capacity to under- standing computer programming and robotics concepts when given developmentally appropriate materials 2) Develop and test an early childhood curriculum to teach developmentally appropriate concepts from computer programming and robotics to children in kindergarten through second grade 3) Investigate the design features of the programming interface and the mediating role interface design plays in learning to program MU Bers et al / Computers & Education 72 (2014) 145–157 147 This paper addresses the first of these goals to describe young children’s learning trajectories in computational thinking and capacity to understand computer programming and robotics concepts This understanding will allow further revision to the TangibleK curriculum The TangibleK Robotics Project makes use of commercially available robotics construction kits and the CHERP (Creative Hybrid Envi- ronment for Robotics Programming) language to give behaviors to the robotic constructions (Bers 2008; Bers & Horn 2010; Horn et al 2011; Kazakoff & Bers 2012; Kazakoff Sullivan & Bers 2012) CHERP is a hybrid tangible and graphical computer language designed to provide young children with an engaging introduction to computer programming in a developmentally appropriate way The software allows children to create programs to control their robots from tangible wooden blocks and/or graphical on-screen icons The design of CHERP avoids the technical and syntax-related challenges of text-based programming languages Furthermore the hybrid interface allows children to choose the interface that best suits their changing preferences as physical abilities perceived social appeal and the level of challenge of the activity at hand evolve (Horn et al 2011) because both tangible and graphical interfaces can represent the same concepts The TangibleK curriculum introduces increasingly complex powerful ideas from computer science in a robotics context in a structured developmentally appropriate way The powerful ideas from computer science addressed in this curriculum include the engineering design process and debugging (trouble-shooting) robotic motion and sensing and three aspects of programming choosing the correct pro- gramming instructions controlling the flow of actions by sequencing the action instructions accordingly and controlling the flow of actions by using special control flow instructions Section 23 contains more detailed definitions of each powerful idea In addition to the concrete robotics and programming concepts and skills introduced in each activity skills such as observation reflection and decomposition of complex processes are interwoven throughout the curriculum The curriculum which takes approximately 20 h of classroom work includes six structured 60- to 90-min activities and a culminating interdisciplinary project All the activities focus on building and programming a robotic vehicle to accomplish a particular goal Each lesson addresses one or more powerful idea(s) within the context of a narrative theme The six lesson activities and their embedded content are as follows  Lesson 1 The Engineering Design Process Children build sturdy non-robotic vehicles to transport toy people on a floor map Children apply the stages of the Engineering Design Process to plan test and improve their vehicles  Lesson 2 Robotics Children share and learn ideas about what robots are and are not They explore robotic parts by designing and building their own robots They learn to appropriately connect robotic parts (eg snap-together wires and motors) to make a robot that moves  Lesson 3 Choosing and Sequencing Programming Instructions In this activity children program their robots to dance the “Hokey-Pokey” by choosing relevant instructions and putting them in the correct order or sequence  Lesson 4 Looping Programs (Control Flow Instructions 1) Children use “repeat” instructions to program their robots to move forward forever Next they program their robot to move forward only a particular number of times to reach a fixed location  Lesson 5 Sensors Children use light sensors to program their robots to turn its light on when it is dark out and vice versa They draw comparisons between robotic sensors and the five human senses  Lesson 6 Branching Programs (Control Flow Instructions 2) Children are introduced to a pair of conditional control flow instructions “If” and “If Not” which are also used with a sensor to make programs that incorporate environmental conditions into the robot’s behavior In addition to the structured activities described above the TangibleK curriculum includes songs games and free-play with the robotics and programming materials in order to foster a playful learning environment for children For example in Lesson 3 children sing and dance the “Robot Hokey-Pokey” and play Simon Says with the CHERP programming commands to recall and apply the programming instructions Throughout the 20 h curriculum children have ample opportunity to freely build and design with the robotics materials and to create their own CHERP programs beyond those that are set forth in each of the structured lessons After completing the six lessons described above each classroom embarks on a culminating interdisciplinary project which invite children to apply the now familiar powerful ideas to a particular theme or context The teacher decides on a theme drawn from other subjects studied during the year and each child chooses a challenge within this theme Past classrooms have selected topics such as animal behaviors vehicles that help the community or “Who Am I?” Children created projects representing snakes that slither recycling trucks that collect refuse and sewing needles that travel back and forth through fabric among many others The projects allow children to demonstrate the powerful ideas they learned over the six activities as well as to apply them and continue learning about them in a new context Having introduced an overview of the TangibleK Robotics Program including its technological curricular and theoretical components we now present a study of three kindergarten classrooms in which the TangibleK Robotics Program was implemented The following sections report the distribution of achievement scores children attained on selected computer programming concepts and skills tied to the 148 MU Bers et al / Computers & Education 72 (2014) 145–157 powerful ideas listed above Achievement scores form the basis on which to discuss the curriculum structure and content and consider the implications for understanding children’s early learning trajectories of computational concepts and for further adaptation of the curriculum 2 Study design Within the design-based research tradition of iterative testing analysis and refinement of an intervention (see eg Cobb Confrey diSessa Lehrer & Schauble 2003) the TangibleK Robotics Program has spent five years exploring what children are capable of learning and accomplishing in the domains of robotics and programming The study described in this paper examines how successfully children learned the core concepts (powerful ideas) of robotics and programming in the TangibleK curriculum The study took place during the fourth year of the overall project following piloting and refinement of the software and curriculum in a range of settings from classrooms and after-school/summer programs to the research lab The extensive testing exploration and refinement of the preceding study iterations also laid a foundation for understanding how young children learn and think about core concepts of programming and robotics For instance several of the curricular activities were simplified to enable better focus on the target concepts; movement games and songs were added to the curriculum to engage children in multiple modes of understanding concepts and to provide reinforcement for basic knowledge In addition some of the programming icons were revised to use more familiar imagery for children 21 Participants Each of the three teachers involved in this study volunteered to participate following email notification of the opportunity to principals of a limited number of schools in the Greater Boston area All children in each classroom participated in the curriculum but each family had the option to allow or decline data collection According to school community needs consent materials were available in English Portuguese and Spanish Children in the study attended one of three Greater Boston area kindergarten classrooms two of which were at a public urban school and one at a private suburban school From a total of 63 children enrolled in the three classes during the study 53 are included in data analysis Children were included in data analysis unless they missed more than one activity or if data was not collectible for more than one activity Attrition was due to typical classroom absences as well as the difficulty of collecting data with limited researchers in a bustling classroom environment Classroom 1 a kindergarten in an independent K-8 religious-based private school in a suburb of Boston MA had 23 children 18 of whom are included in data analysis The student population at this school was 97% White 1% as Asian 1% as Black 1% Hispanic (http//nces edgov/globallocator/) Of the children in the kindergarten class 50% were male and 50% were female They ranged from ages 49 to 62 years at the start of the study with a median age of 56 years The only kindergarten classroom at this school this class was taught by a male teacher with seven years of teaching experience who on a scale from 1 (none) to 5 (expert) rated his computer experience as 5 pro- gramming experience as 3 and robotics experience as 1 Classrooms 2 and 3 were located at the same urban K-8 school (NCLB Level 3) located just outside of Boston MA The makeup of this school during the 2010–2011 school year was 389% White 363% Hispanic 162% African American 70% Asian American and 17% multi- race The school was comprised of 411% English-Language Learners and 644% of students were classified as low income (Massachusetts Department of Education 2006) A female teacher with six years of teaching experience taught Classroom 2 She rated her computer experience as a 4 robotics experience as a 2 and programming experience as a 2 This classroom had 19 children enrolled 17 of whom are included in the data analysis Of those 17 children 59% were male and 41% were female At the start of the curriculum the children in this classroom ranged in age from 49 to 62 years old with a median age of 56 years A female teacher with 15 years of teaching experience taught Classroom 3 She also rated her computer experience as a 4 robotics experience as a 2 and programming experience as a 2 The data analysis includes 18 of 21 children enrolled in this classroom Of the 18 participants 44% were female and 56% were male The children’s ages at the start of the curriculum in Classroom 3 ranged from 56 to 65 years with a median age of 60 years old The overall age range for the 53 children included in data analysis was 49–65 years and their average age at the start of the curriculum was 57 years old Over the three classrooms as a whole 45% of the children were female and 55% male The participants in this study are thought to be generally representative of the general kindergartners population as the sample includes both public and private school students both male and female teachers a fairly even proportion of male and female students and as described above a diverse range of ethnic and socioeconomic backgrounds particularly at to the participating public school 22 Procedure Each classroom’s head teacher and all research assistants (nearly 20 research collaborators in total) received training to prepare them for teaching or assisting the robotics curriculum and participating in the research and data collection The high number of assistants was needed for two reasons First a low student-to-adult ratio in each lesson ensured adequate observation and documentation of students’ work Secondly most research assistants had limited availability across the full set of study sessions Therefore attention was given to all col- laborators’ to ensure they received careful and detailed training The 3-h introductory training covered technical curricular and pedagogical aspects of the program including how to use the CHERP programming language and LEGO robotics kits as well as activity content and training on the structure and the teaching approach framed by the PTD model presented earlier The training also included explanation and examples of how to score children’s work in each activity according to a scale of understanding levels described below The teachers then implemented the TangibleK curriculum in their own classrooms with technical support from trained research as- sistants Two teachers used the curriculum with the whole class working together The third teacher worked with half of the class at a time finishing the entire curriculum with one group before starting it with the other Each curricular activity took one to two 60–90 min ses- sion(s) The teacher introduced key concepts and the day’s activity in a whole-group setting along with a short song or game to reinforce the MU Bers et al / Computers & Education 72 (2014) 145–157 149 concepts As mentioned earlier in Lesson 3 each class sang and danced the “Hokey-Pokey” before programming their robots to do this dance Additionally the game “Simon Says” was often used in Lessons 3–6 to reinforce the CHERP programming instructions and their corresponding robotic actions After the whole-group activities children built and/or programmed their own robotic vehicles The children worked independently on their projects but sat in groups of four and received support as needed from the research assistant or classroom teacher at their group while also interacting with their peers With the variety of coders evaluating children’s work we systematically accounted for potential intercoder differences by varying which adult worked with which children during each lesson Each session’s work ended with a group discussion for children to share progress questions and successful strategies and for the teacher to help reinforce the core robotics and programming concepts and the engineering design process To assess learning outcomes after each activity research assistants evaluated the robot and/or program made by each child They assessed the child’s level of understanding of selected core concepts as seen by successful application of the concepts in the robot or program If needed they also talked with children to gain more information about their work and understandings By examining for instance the child’s program for correct selection and sequencing of action instructions or proper use of the “repeat” instruction research assistants scored each child’s achievement of the core goals of the lesson using the following 6-point Likert scale designed to document the thoroughness of the child’s understanding and application of activity-specific concepts and skills as well as their use of general problem- solving skills A score of 4 or higher was defined as the target level of achievement 5 Complete achievement of the goal task or understanding 4 Mostly complete achievement of the goal task or understanding; 3 Partially complete achievement of the goal task or understanding; 2 Very incomplete achievement of the goal task or understanding; 1 Did not complete the goal task or understanding; 0 Did not attempt/Other In each lesson children were scored on multiple concepts using this Likert scale For example in Lesson 3 children programmed their robots to dance the “Hokey-Pokey” by 1) choosing the correct instructions (a skill referred to here as correspondence) and 2) putting the instructions in the correct order (sequencing) The concepts of sequencing and correspondence are described in more detail in Sections 232 and 233 As an illustration of the general scale children received one point on the correspondence scale for each programming instruction that correctly matched a line of the song Below are examples of children’s programs that were scored at each level of correspondence in Lesson 3 5 Begin Forward Backward Forward Shake Spin End (all correct); 4 Begin Forward Forward Forward Shake Spin End (second Forward should be Backward); 3 Begin Forward Backward Shake End (missing Forward and Spin); 2 Begin Shake Spin End (missing Forward Backward Forward) 1 Begin Shake End (missing Forward Backward Forward and Spin) 0 Despite assistance and prompting the child did not attempt Hokey-Pokey task These same programs also received a 0–5 score for sequencing in Lesson 3 23 Variables examined To examine children’s growing computational thinking ability throughout implementation of the TangibleK curriculum four key vari- ables were observed and assessed debugging correspondence sequencing and control flow 231 Debugging When faced with a difficult problem or task children (and adults) are often unable to determine a suitable solution on the first attempt In these situations “debugging” skills can be helpful Debugging or trouble-shooting is a form of problem-solving used in the fields of engineering and computer science It encompasses four steps 1) To debug a problem the child must first recognize that something is not working or not meeting the stated goal For example a child programming her robot to dance the Hokey-Pokey in Lesson 3 watches her program running and realizes that the robot does not “shake it all about” 2) In step 2 of the debugging process children either decide to keep their original goal or switch to an appropriate alternative This child might continue to pursue the original plan of making the robot dance all the parts of the Hokey-Pokey or as is common at this age she might come up with an alternative such as having their robot do a different dance 3) The third stage of debugging is generating a hypothesis as to the cause of the problem The child in our example may hypothesize that the program is missing an instruction that would make their robot shake 4) Finally the last aspect of debugging is attempting to solve the problem The child might put a “Shake” block in different positions in the program until the program fully matches the song Debugging skills are not limited to the arena of engineering and computer science Previous research has found that children can acquire and transfer debugging skills to activities outside of the programming context with appropriate support including explicit in- struction (Klahr & Carver 1988; Salomon & Perkins 1987) The steps of the debugging process are a critical component of the Engineering Design Process which refers to the cyclical or iterative process engineers use to design an artifact in order to meet a need (Massachusetts Department of Education 2006) As defined by the MA curriculum frameworks its steps include identifying a problem looking for ideas for solutions and choosing one devel- oping a prototype testing improving and sharing solutions with others (see Fig 4) The steps of testing and improving which require debugging are particularly important in establishing a learning environment where failure – rather than immediate success – is expected and seen as necessary for learning With the Engineering Design Process children are not expected to “get it right” the first time 150 MU Bers et al / Computers & Education 72 (2014) 145–157 In the TangibleK curriculum debugging and the Engineering Design process were first introduced in Lesson 1 and the concepts and skills were applied throughout the rest of the curriculum Children were assessed on their ability to apply the four core aspects of debugging (described above) in each lesson and final project 232 Correspondences between actions and instructions A program is a sequence of instructions that a computer (in this case a robot) acts out in an order specified by the programmer (Stair & Reynolds 2003) Each instruction has a specific meaning and the order of the instructions leads to the robot’s overall actions Making correspondences between actions and instructions encompasses the understanding that each programming instruction represents a specific action carried out by the robot Another way to understand the process of correspondence is to frame it with the notion of symbols a core concept that children are learning in kindergarten in both math and literacy Each programming instruction is a symbol for the action the robot will carry out In order to program a robot’s behavior children must understand in general that people use symbolic language to communicate with computers and they must select specific instructions to accurately represent their intended outcome for the robot’s behavior Correspondence was first introduced in Lesson 3 of the curriculum when students choose and sequence programming instructions to make a robot dance the Hokey-Pokey Accomplishing this task requires children to identify the corresponding programming instruction for each line of the “Robot Hokey-Pokey” verse/dance For example a child who understands the correspondence between actions and in- structions would find the programming instruction block with the “shake” symbol to recreate the line in which the robot “shakes it all about” To measure correspondence children were assessed on how many of the correct instructions they chose 233 Sequencing instructions Sequencing is a component of planning and involves putting objects or actions in the correct order (Zelazo Carter Reznick & Frye 1997) To create a successful program children must use procedural thinking and plan their programs in terms of a sequence of what happens next before or until another action (Pea & Kurland 1984) In both literacy and mathematics sequencing is essential for putting phonemes letters words or elements of a formula in the appropriate order (Neuman & Dickinson 2002) Prior research with the TangibleK project showed that children who participated in the program earned significantly higher scores on a test of story sequencing than children who did not (Kazakoff & Bers 2012; Kazakoff Sullivan & Bers 2012) In this curriculum children were first introduced to the idea of sequencing instructions in Lesson 3’s “Hokey-Pokey” challenge (described above) Sequencing was also a core component of Lessons 4–6 in which children had to properly arrange action instructions and increasingly complex control flow instructions in the correct order to achieve particular outcomes in the robot’s behavior 234 Use of control flow instructions “Control flow” refers to the concept that programmers can control the order in which a robot follows the instructions in its program through various programmatic methods This curriculum introduced children to control flow instructions and parameters Control flow instructions allow the robot to carry out instructions non-sequentially eg in a loop or only under certain conditions For example a CHERP program can include a “Repeat” control flow instruction in the following way “Begin Forward Repeat 3 Shake End-Repeat Sing End” to make the robot shake three times and then sing once With the attachment of a light or touch sensor to the robot sensor parameters can also be used to qualify the control flow instructions based on environmental stimuli For instance a child can program a robot to carry out an action or set of actions only “If (the environment is) Dark” or “If Light” and another set of actions “If Not (Light/Dark)” While there are currently no curriculum frameworks explicitly addressing control flow these activities connect to mathematics by reinforcing number sense and estimation or to natural science by comparing human and animal sensory functions with robot sensors Children are also able to compare and contrast repeating or looping programs to patterns cyclical events in the natural world and calendar time Children were assessed on their correct use of control flow structures in Lessons 4–6 and the final project 3 Results This section presents and compares children’s achievement on programming and debugging concepts and other skills taught using the TangibleK robotics curriculum Since the focus of this work is on computational thinking in a robotic context the assessments presented here evaluate programming concepts instead of robotics knowledge Children’s work in each introductory lesson was assessed for two relevant programming concepts These concepts seven in total were reassessed in the final project Additionally four debugging skills were assessed in all lessons and the final project Each measure uses the Likert scale shown above which ranges from 0 (did not attempt the task) or 1 (did not complete the goal task or understanding) to 5 (completely achieved the goal task or understanding) Analysis was conducted by aggregating scores from all classrooms and using paired-sample t-tests to compare scores on each concept from one lesson to the next Findings are grouped by the powerful idea to which they relate Note that the teacher in Classroom 1 chose not to formally teach Activity 6 so data for that Activity’s items come only from two classrooms A discussion about this choice is provided later in the paper 31 Debugging Average scores on the various debugging measures fell in the range of partial to mostly complete understanding and application of the skill (see Table 1) There was little variation in debugging scores between consecutive activities (see Fig 1) with the exception that the average score on keeping the original goal was higher in Activity 4 than in Activity 5 (marked in Table 1) In other words children’s ability to keep working on the original goal (or choose an acceptable alternative) was higher in activities that did not require the use of sensors and sensor parameters Scores on the other three components of debugging remained steady in the mid-to-upper range of the achievement scale across lessons Table 1 Student scores on debugging Debugging step 1 Debugging step 2 Debugging step 3 N Mean SD 42 400 108 46 376 097 33 367 127 43 346 132 27 322 119 26 296 128 27 393 092 Debugging step 4 N Mean 43 416 46 391 34 377 43 372 30 350 27 341 26 408 MU Bers et al / Computers & Education 72 (2014) 145–157 151 Activity 1 Activity 2 Activity 3 Activity 4 Activity 5 Activity 6 Project N Mean 43 419 48 435 31 397 43 393 30 353 27 344 28 397 SD N 098 45 076 49 111 39 126 44 117 36 125 28 092 29 Mean SD 422 080 416 087 421 095 387 123 350 123 389 123 442 064 SD 105 100 128 130 123 142 069 Note Classroom 1 did not do Activity 6 Denotes significant differences in the mean scores Debugging Step 2 between Activity 5 (the last activity completed by all classes) and the project t(19) 1⁄4 312 and p 1⁄4 001 For Debugging Step 4 from Activity 5 to the project t(15) 1⁄4 255 and p 1⁄4 002 Repeated measures ANOVA analyses (see Table 2) were run for the four debugging skill variables across activities The analyses were run across all seven activities (or in the case of Debugging Skill 1 across the four activities where this skill was assessed) In addition a separate repeated measures ANOVA was run for each debugging skill variable for just Activities 1–5 since once classroom did not participate in Lesson 6 and the project lesson was unstructured Average debugging score did not vary significantly across activities when all lessons were considered However when removing the challenge activity and Lesson 6 where one class did not participate a repeated measures ANOVA for each debugging variable did show a change across time meaning there was perhaps variation in debugging score across the more structure lessons but this variation averaged out when children worked on their own projects 32 Powerful ideas of programming In Activities 3 through 6 and in the culminating project students completed specific programming challenges and were assessed on their ability to select instructions and put them in the order that would result in the goal behavior for the robot Activities 4–6 also used special “control flow” instructions which can tell the robot to loop through a set of actions repeatedly or to follow one “branch” of instructions or another based on sensor data 321 Choosing the correct programming instructions The overall mean score on students’ abilities to choose the correct instructions started off high in Activity 3 Scores then dropped on average over Activities 4 through 6 and returned to starting levels in the project (see Table 3 for detailed means) As mean scores fell to statistically significantly lower levels in Activity 4 and again in Activity 5 the percent of students reaching the target level of achievement also dropped Seventy-six percent of students achieved in the target range on choosing programming instructions in Activity 3 which used only action instructions In Activity 4 which introduced the first of the control flow instructions 70% of children achieved the target level as did only 46% in Activity 5 which added the use of sensors and sensor parameters and 62% in Activity 6 which used a second more challenging type of control flow instruction However 77% of children reached the target level of achievement on their projects – a similar rate to that in Lesson 3 the first activity to require choosing programming instructions (see Fig 2) 322 Control flow by sequencing Sequencing ability was also introduced in Activity 3 along with making correspondences between intended robotic actions and pro- gramming instructions when children made their robots dance the “Hokey-Pokey” Three-quarters of all students achieved in the target range in this first programming activity Sequencing was also a core component of Activities 4–6 in which children had to properly arrange Fig 1 Mean achievement on debugging across Activities Average debugging scores for each activity and project All four debugging components appear to follow a similar trend but only the scores for keeping the original goal and attempting to solve the problem had statistically significant changes of the paired items at the p < 005 level For Debugging Step 2 between Activities 4 and 5 t(28) 1⁄4 204 and p 1⁄4 005 For 152 MU Bers et al / Computers & Education 72 (2014) 145–157 Table 2 Repeated measures ANOVAs by debugging steps A repeated measures ANOVA was conducted to see if there was a significant difference in means of debugging level over time All possible activities df (4 16) (2 4) (2 4) F p 1559 023 5740 007 4586 010 Without Lesson 6 or project df F p 001 000 000 000 Debugging Step 1 Sphericity Assumed Debugging Step 2 Greenhouse-Geisser Debugging Step 3 Greenhouse-Geisser Sphericity Assumed Debugging Step 4 Denotes significance at the p < 001 level (2 50) (3 68) (4 84) (4 88) 5122 5157 9192 6404 Correction Correction Correction Notes Classroom 1 did not do Activity 6 The Project was open-ended (children could choose to use less difficult blocks) Greenhouse-Geisser Sphericity Assumed (1 3) 2682 023 both actions and increasingly complex control flow instructions in the correct order In these activities 59% 53% and 68% of children respectively achieved at the target level Fewer children were able to reach the target level of achievement for sequencing in these activities than in Activity 3 A comparison of mean scores on sequencing from one activity to the next revealed a statistically significant drop between Activities 3 and 4 differentiating programs with actions only from those requiring two-part control instructions as well (see Table 4) As was seen with correspondence scores the average sequencing score on children’s projects was statistically significantly higher than the average score in Activity 5 (see Fig 2) 323 Control flow by special instructions Activities 4–6 each introduced a new control flow instruction for creating looping or branching programs Students on average achieved a “partially” complete understanding of the concepts (see Table 5 for detailed means) Less than 60% of students reached the target (“mostly” complete) level of understanding on all but one of these measures (This degree of understanding was reached by 53% for looping 60% for numeric parameters 54% for sensor parameters 68% for the first half of the conditional statement and 41% for the second half of the conditional statement) There were no differences in average scores found between looping and conditional instructions or comparing the different types of parameters (see Fig 3) The only statistically significant difference in scores was between the two parts of the conditional statement (“If” versus “If Not”) That is children were on average more comfortable making the programming equivalent of the statement “If it’s dark out turn the light on” and less comfortable appending “If not turn the light off” to that first statement 33 Comparison of concepts between activities and projects Differences in children’s achievement on each of the above concepts from the introductory activities to the culminating projects were examined in two ways First children’s scores from Activity 5 (the last activity completed by all classes) were compared to children’s scores on the final project This continued the comparison of scores on consecutive activities Secondly scores from the first activity that introduced a particular concept were compared to corresponding scores from the final project For example sequencing scores from Activity 3 (the first activity using that concept) were compared to sequencing scores on the final project This comparison was done to address how children’s scores on the same concepts might change with time and exposure We should note that due to the self-selected nature of the final projects not all children employed every concept to complete them so n is relatively lower on these comparisons There were some statistically significant increases in scores from the final introductory activity completed by all classrooms to the culminating projects were seen on two overarching programming concepts choosing the correct instructions (see Table 3) and sequencing the instructions to accomplish the goal (see Table 4) as well as on two elements of debugging (see Table 1) sticking with the original goal or choosing an acceptable alternative and taking steps to attempt to solve the problem In fact after these scores had dropped over the course of the activities they returned to starting levels in the final projects (as described in the relevant sections above) Table 3 Student scores on selecting programming instructions Selecting instructions N Mean Comparison to subsequent activity Activity 3 Activity 4 Activity 5 Activity 6 Project 48 415 SD Activity 107 – 104 3 120 4 130 5 092 6 df tp – –– 42 247 02 38 277 01 25 073 047 29 119 025 45 424 50 388 41 334 34 365 5a 35 a This comparison was made as an alternative to the Activity 6-to-Project comparison as it was the last activity completed by all three classrooms prior to the project 312 00 Note Classroom 1 did not do Activity 6 Denotes significance at the p < 001 level; Denotes significance at the p < 005 level Table 4 Student scores on using sequencing for control flow Sequencing instructions Comparison to subsequent activity MU Bers et al / Computers & Education 72 (2014) 145–157 153 Fig 2 Mean achievement on choosing and sequencing instructions average scores for choosing and sequencing programming instructions according to the goal The dip on both choosing instructions (marked with ) and sequencing them (marked with þ) at Activity 5 represents significantly lower scores as compared to Activity 4 and the Project The drop in score for choosing instructions at Activity 4 is also statistically significant It was anticipated that the children’s scores on the same concepts might increase with exposure so comparisons were made between children’s score on a concept in the activity that introduced it and the score on that same concept in the final project However there were no statistically significant differences seen in any such comparisons (see Table 6) In summary many children in each class reached the target level of achievement on the programming tasks over the course of the curriculum’s six activities and culminating project In the first three activities which introduced the engineering design process robotics and programming children’s levels of achievement were particularly high (75% on average reaching target level of achievement) In Ac- tivities 4–6 which introduced more sophisticated concepts and programming instructions fewer children (56% on average) attained the same level of understanding Many children achieved high scores on properly selecting and sequencing instructions when the programming activities involved only action instructions (w75% for both skills) and in the final projects Achievement was comparatively lower in activities which involved the conceptually and functionally more complicated control flow instructions and/or sensors (59% for both skills) Programs that use special control flow instructions visually appear linear but the robot does not carry out one action per programming block as it does with a program containing only actions instructions; the logical flow of the program may be a loop or forked path rather than a line This introduces a conceptual complexity to programming with control flow instructions that does not exist with action instructions alone Similarly it appears based on relative scores that using the “If” instruction was simpler than using the “If Not” instruction (68% versus 41% target achievement) The complexity of each programming concept appears to be reflected in the portion of students who reached target levels of understanding 4 Discussion The results provide critical information on the accessibility of selected concepts from the fields of robotics and computer science for kindergarten children adding clarity to developmentally appropriate learning expectations in order to revise and improve both the curricular activities and design features for early childhood robotics and programming technologies The results also shed light on some of the challenges of conducting design-based research in a classroom setting One interesting feature of the results is the trend of decreasing achievement scores across Lessons 3–6 This is possibly related to the amount of time spent on each topic Each activity in the curriculum introduced a progressively more challenging concept than the activity before it In the later lessons children were asked to build on concepts they had only recently learned While each lesson was carefully designed to teach a particular topic and provide a space for exploration of it these concepts may not have been fully ingrained or mastered yet while new material was introduced This could also help explain lower scores in the later lessons Another interesting result relates to the several concepts for which children’s average achievement scores increased from the final introductory lesson to the culminating project With statistical significance children averaged higher scores on choosing and sequencing Activity 3 Activity 4 Activity 5 Activity 6 Project N Mean 49 423 40 369 40 350 34 374 49 408 SD Activity 116 – 114 3 120 4 119 5 104 6 df t – – 41 279 38 107 25 053 30 025 p – 01 030 060 080 5a 35 214 a This comparison was made as an alternative to the Activity 6-to-Project comparison as it was the last activity completed by all three classrooms prior to the project 04 Note Classroom 1 did not do Activity 6 Denotes significance at the p < 001 level; Denotes significance at the p < 005 level 154 MU Bers et al / Computers & Education 72 (2014) 145–157 Table 5 Student scores on using special instructions for control flow Control flow instructions Comparison to analogous concept Concept N Mean SD 49 361 117 50 376 117 41 359 112 34 374 124 22 332 121 df t p – – 042 100 04 053 Looping instruction Numeric parameters Sensor parameters Conditional (If) Conditional (If Not) – – – – – – Numeric parameters 38 087 Looping instruction 31 000 Conditional (If) 20 217 Looping instruction 19 065 Note Classroom 1 did not use conditional statements Denotes a statistically significant difference at the p < 005 level instructions during the final project than in any introductory activity except the first (and simplest) programming activity While assistant from adults remained stable throughout all aspects of the curriculum and final projects some other circumstances were different in the project compared to the lessons The improved scores might be attributed to the fact that children had more enthusiasm for these personally-selected projects that would soon be part of a show-and-tell celebration as well as more time to experiment at their own pace than in the lessons Alternatively assuming children chose projects well-matched to their level of expertise it would be reasonable to expect higher demonstrated levels of achievement as their projects likely focused on concepts children already felt more comfortable using However there were no statistically significant differences seen in comparisons of control flow instruction and sensor-related measures between the activity that introduced each concept and the culminating project It is possible that even more time exploring these concepts was needed for significant learning gains to occur Surprisingly children did not always perform better on simpler concepts than on more complex ones For example the lack of statistically significant differences between children’s understanding of looping versus conditional programs and between numeric versus sensor parameters is unexpected both theoretically and based on anecdotal observations of these activities by researchers present during the activities The concepts associated with looping and numeric parameters should in principle be more straight- forward than those involved in programming with conditional statements and sensor parameters Thus at least somewhat higher levels of achievement on looping and numeric parameters had been expected compared to conditional statements and sensor parameters In some of the comparisons described above the low n (less than half the overall study sample size) may have impacted the results The statistically significant findings may have varied if for instance the students for whom researchers could not collect data tended to have above- or below-average achievement levels As the activities in the curriculum increased in difficulty the research assistants tended to provide increased support for children with questions leaving less time to equally observe and assess all children In fact it was also observed that some children who perceived an activity to be difficult refrained from attempting it resulting in no achievement scores for that activity and a lower n on those measures 41 Curriculum discussion While it is beyond the scope of this paper to fully evaluate the TangibleK robotics curriculum results indicate that the curriculum was generally engaging and developmentally appropriate for kindergarten students Results point to kindergarten teachers being able to effectively implement the curriculum and to kindergartners being both interested in and able to learn and apply many aspects of robotics programming and computational thinking However the fact that fewer children achieved the target level of understanding on more complex topics than on the introductory concepts might indicate that the curriculum should devote more time for children to build up to and fully explore the complex material in order to fully understand it In order to test this a new iteration of the curriculum is currently Fig 3 Mean achievement on control flow concepts A comparison of average scores for the different types of control flow instructions and parameters The only significant dif- ference in scores was between the two conditional instructions (marked with ) Table 6 Students scores on concepts in culmination project Project scores Comparison to introductory activity MU Bers et al / Computers & Education 72 (2014) 145–157 155 Fig 4 An illustration of the engineering design process being developed that will divide the prior curriculum based on action and sensing and expand the number of lessons and amount of time spent exploring each topic (particularly the more complex ones) in both structured and free-play-based formats to provide further op- portunities for students’ investigation of concepts and to reinforce their learning Additional supporting activities will also be added Kindergarteners vary widely in their levels of cognitive development and learning abilities and such adaptations to the TangibleK cur- riculum may address this range even more than the current format already does The results also demonstrate the complexity of assessing sophisticated learning processes in a classroom setting There was a necessary trade-off built into the study design gathering an adequately detailed picture of children’s learning had to be balanced with keeping data collection feasible given that each adult was working with several children in the context of a full classroom In some cases (particularly the later activities) a different setting such as individual-child sessions may have provided a better context for some students to demonstrate their abilities However the goal of the study was to examine the TangibleK program in a typical kindergarten classroom and this endeavor was successful Although ultimately some data could not be collected from every student on every measure information was gathered about the reality of implementing the curriculum in classroom settings and the supports necessary to meet the needs of all students 42 Limitations of the study and future directions The TangibleK curriculum was taught during regular school hours in three schools in the Greater Boston area There were both benefits and drawbacks to conducting research in a school setting rather than an experimental setting By testing the curriculum as taught by kindergarten teachers in both public and private schools we have demonstrated that given professional development in robotics edu- cation a dedicated teacher can successfully teach this content in her or his own classroom However as with any study that takes place in a school setting the present study faced several environmental limitations While each of the participating teachers taught the same cur- riculum it is impossible to control for all teacher classroom and school variations that may have influenced results For example the three teachers in this study were very different from one another While some teachers allowed their class to work through difficult concepts on their own others gave more step-by-step instructions Teachers were given leeway to teach the curriculum in whatever way they believed best suited the needs of their classrooms however this causes methodological issues for data analysis Further research should be con- ducted with a focus on how teaching styles and classroom culture serve to enhance or hinder a robotics curriculum Choosing instructions Sequencing Repeats Numeric parameters Sensors Sensor parameters Ifsa N Mean 48 415 49 408 40 375 32 394 18 405 20 390 14 357 SD % Scoring 4þ 092 770 104 735 126 625 122 656 073 834 085 700 080 786 Activity 3 3 4 4 5 5 6 (If) df t p 40 070 049 40 078 044 36 077 045 30 077 045 15 094 036 17 036 073 13 027 079 Note Classroom 1 did not do Activity 6 a There was no separate measure for using “If Not” instructions in the projects 156 MU Bers et al / Computers & Education 72 (2014) 145–157 Another drawback the study encountered was a fluctuating number of daily participants Children were fairly regularly absent temporarily out of the classroom or otherwise unable to participate in the class Other times the busy classroom and divided adult attention prevented assessments from being collected for all children particularly if an assessment required long and sustained periods of obser- vation Teacher differences also impacted the low number of participants in some activities For example one teacher chose not to teach Lesson 6 in order to have more time to review previous concepts before the final project drastically lowering the n for that lesson Further research should be done expanding the scope of this study by gathering more participants and if possible ensuring more consistent completion of each activity The present study inspires additional research agendas While the focus of this work is on kindergartners further investigations should look at the way younger (PreK-K) and older (1st–2nd grade) students are able to learn and apply the same powerful ideas It would be important to determine whether some of the concepts that were particularly challenging to the kindergartners in this study pose less of a challenge with longer exposure or if introduced when children are older Further research will also expand the overall sample size as well as the age and experience range of the sample Other work should attempt to assess the feasibility of implementing this curriculum for a classroom teacher with typical support staff that is with minimal involvement of research assistants except for training teachers and conducting data collection In the present research participating teachers each had about three trained assistants in the classroom to help troubleshoot technology issues assess the children’s progress and provide one-on-one help as needed For this curriculum to become widespread it will be necessary to know more about what supports teachers need (modifications to the curriculum classroom management alternatives additional adult support etc) to successfully implement the curriculum Finally it is beyond the scope of this current study but a follow-up study could look at longitudinal or transfer effects of the TangibleK curriculum What concepts do the students retain? How is computational thinking having an impact in other areas of their academic and extra-curricular lives? Are children able to apply the en- gineering design process to other subject areas after completing this curriculum? Further research should look at the long-term benefits of incorporating programming and robotics into early childhood education It is important to note that many of the challenges that arose as part of the present study were posed by the robotics hardware itself and not the curricular activities This highlights the importance of making developmentally appropriate hardware and software specifically designed for young children Results show that for the children in this study correctly connecting robotic parts proved more challenging than understanding the function of each part or the underlying computational concept This result is not surprising since the CHERP programming interface and the curricular activities introducing the robot’s parts and their purposes were specifically developed for kin- dergartners as part of this research project while the robotics kit hardware was designed for older children as part of a commercially available LEGO product Furthermore children spent a significant amount of time fixing their robots which came apart frequently It was challenging for many children to assemble some of the pieces on their own and they needed adult help If children had spent the robot repair time working on their computer programs instead (and if teachers were able to spend that time providing support for learning the central concepts rather than helping re-build robots) perhaps children would have attained higher levels of achievement in their under- standing of complex powerful ideas involved in computational thinking The findings from this study have informed the TangibleK Project in which early childhood teachers (pre-kindergarten through 2nd grade) will systematically implement a robotics curriculum revised according to several of the points outlined above The teachers will document their experiences and their students’ learning outcomes over the course of a school year using KIWI a developmentally appropriate robotics hardware that will replace the LEGO hardware used in this current study Despite the limitations of the study described in this paper post-study data collected from the teachers speaks to the success of the TangibleK Robotics program All the teachers said they would participate in TangibleK again if given the chance Along with the general success and enthusiasm of the children this feedback highlights the overall positive and educational nature of the experience 5 Conclusion The early childhood classroom is not typically a place where we expect to find students programming robots Yet with the availability of developmentally appropriate technologies this is increasingly possible and the result may be the advancement of technological fluency in our nation’s youth This paper explored the TangibleK Robotics Program as a viable option for classroom teachers to integrate develop- mentally appropriate technology education into the early childhood classroom With CHERP children spend their time building a robot planning its actions using physical wooden block or the computer screen to construct programs and iteratively improving the robot and programs according to initial goals and subsequent discoveries Because the tangible programs and robots exist off-screen children are drawn to investigate the work of other children work collaboratively and negotiate sharing materials as well as develop their fine-motor skills These artifacts serve as points of discussion and reminders of the activity content even after the computer has been turned off As the analysis presented in this paper has explored in this rich process of creation in both the physical and digital worlds children actively engage in problem-solving and learn powerful ideas from computer science and robotics including core concepts of computational thinking Research is essential to understanding the impact of new technologies on the development of children and how children are using and could be using these tools As parents educators policymakers and researchers it is our responsibility to ensure our children receive the technological education needed for healthy development and a successful future The TangibleK Robotics Program introduced in this paper shows that when given age-appropriate technologies curriculum and pedagogies young children can actively engage in learning from computer programming as applied to the field of robotics They can then take their first steps into developing computational thinking Acknowledgments The TangibleK project was supported by National Science Foundation (NSF) DRL-0735657 Any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation The authors would like to thank participating schools and teachers for their commitment to and participation in this project References MU Bers et al / Computers & Education 72 (2014) 145–157 157 Barron B Cayton-Hodges G Bofferding L Copple C Darling-Hammond L & Levine M (2011) Take a giant step A blueprint for teaching children in a digital age New York The Joan Ganz Cooney Center at Sesame Workshop Barr V & Stephenson C (2011) Bringing computational thinking to K-12 what is involved and what is the role of the computer science education community? ACM Inroads 2(1) 48–54 http//dxdoiorg/101145/19298871929905 Bers M U (2008) Blocks robots and computers Learning about technology in early childhood New York Teacher’s College Press Bers M U (2010) Beyond computer literacy supporting youth’s positive development through technology New Directions for Youth Development 128 13–23 Bers M U (2012) Designing digital experiences for positive youth development From playpen to playground Oxford University Press Bers M U & Horn M S (2010) Tangible programming in early childhood revisiting developmental assumptions through new technologies In I R Berson & M J Berson (Eds) High-tech tots Childhood in a digital world (pp 49–70) Greenwich CT Information Age Publishing Bers M U Ponte I Juelich K Viera A & Schenker J (2002) Teachers as designers Integrating robotics into early childhood education Information Technology in Childhood Education Cejka E Rogers C & Portsmore M (2006) Kindergarten robotics using robotics to motivate math science and engineering literacy in elementary school International Journal of Engineering Education 22(4) 711–722 Clements D H & Gullo D F (1984) Effects of computer programming on young children’s cognition Journal of Educational Psychology 76(6) 1051–1058 http//dxdoiorg/ 101037/0022-06637661051 Clements D H & Meredith J S (1992) Research on logo effects and efficacy Retrieved from http//elmediamitedu/logo-foundation/pubs/papers/research_logohtml Cobb P Confrey J diSessa A Lehrer R & Schauble L (2003) Design experiments in educational research Educational Researcher 32(1) 9–13 Gelman R & Brenneman K (2004) Science learning pathways for young children Early Childhood Research Quarterly (Special Issue on Early Learning in Math and Science) 19(1) 150–158 Horn M S Davis P Hubbard A Keifert D Leong Z A & Olson I C (June 2011) Learning sustainability children learning and the next generation eco-feedback technology In Proc 10th international conference on interaction design and children (short paper) Ann Arbor MI International Society for Technology in Education (2007) NETS for students 2007 profiles Washington DC ISTE Retrieved from wwwisteorg/standards/nets-for-students/ nets-for-students-2007-profilesaspx#PK-2 International Society for Technology in Education and The Computer Science Teachers Association (2011) Operational definition of computational thinking for K-12 thinking- operational-definition-flyerpdf International Society for Technology in Education and The Computer Science Teachers Association Kazakoff E & Bers M (2012) Programming in a robotics context in the kindergarten classroom the impact on sequencing skills Journal of Educational Multimedia and Hypermedia 21(4) 371–391 Kazakoff E Sullivan A & Bers M (2012) The effect of a classroom-based intensive robotics and programming workshop on sequencing ability in early childhood Early Childhood Education Journal 41(4) 245–255 Klahr D & Carver S (1988) Cognitive objectives in a LOGO debugging curriculum instruction learning and transfer Cognitive Psychology 20 362–404 Lee I Martin F Denner J Coulter B Allan W Erickson J et al (2011) Computational thinking for youth in practice ACM Inroads 2(1) 32–37 Massachusetts Department of Education (2006) Massachusetts science and technology/engineering curriculum framework Retrieved from Massachusetts Department of Education http//wwwdoemassedu/frameworks/scitech/1006pdf NAEYC & Fred Rogers Center for Early Learning and Children’s Media (2012) Technology and interactive media as tools in early childhood programs serving children from birth through age 8 Joint position statement Washington DC NAEYC Latrobe PA Fred Rogers Center for Early Learning at Saint Vincent College Retrieved from wwwnaeyc org/files/naeyc/file/positions/PS_technology_WEB2pdf Neuman S B & Dickinson D K (Eds) (2002) Handbook of early literacy research New York Guilford Press Papert S (1980) Mindstorms Children computers and powerful ideas New York Basic Books Papert S (2000) What’s the big idea? Toward a pedagogy of idea power IBM Systems Journal 39(3 & 4) 720–729 http//dxdoiorg/101147/sj3930720 Pea R D & Kurland D M (1984) On the cognitive effects of learning computer programming New Ideas in Psychology 2(2) 137–168 http//dxdoiorg/101016/0732- 118X(84)90018-7 Perlman R (1976) Using computer technology to provide a creative learning environment for preschool children Logo memo no 24 Cambridge MA MIT Artificial Intelligence Laboratory Publications Piaget J (1954) The construction of reality in the child New York Basic Books Resnick M (2003) Playful learning and creative societies Education Update 8(6) Retrieved from http//webmediamitedu/wmres/papers/education-updatepdf Rogoff B Goodman Turkanis C & Bartlett L (2001) Learning together Children and adults in a school community New York NY Oxford University Press Salomon G & Perkins D N (1987) Transfer of cognitive skills from programming when and how? Journal of Educational Computing Research 3 149–169 Sesame Workshop (2009) Sesame workshop and the PNC Foundation join White House effort on STEM education Retrieved from http//wwwsesameworkshoporg/ newsandevents/pressreleases/stemeducation_11212009 Stair R M & Reynolds G W (2003) Principles of information systems (6th ed) Boston MA Course Technology – ITP US Department of Education Office of Educational Technology (2010) Transforming American education Learning powered by technology Washington DC US Department of Education Office of Educational Technology Retrieved from http//wwwedgov/technology/netp-2010 White House (2011) Educate to innovate Retrieved from http//wwwwhitehousegov/issues/education/educate-innovate Wyeth P (2008) How young children learn to program with sensor action and logic blocks International Journal of the Learning Sciences 17(4) 517–550 Zelazo P D Carter A Reznick J S & Frye D (1997) Early development of executive function a problem-solving framework Review of General Psychology 1(2) 198–226 Zigler E F & Bishop-Josef S J (2006) The cognitive child vs the whole child lessons form 40 years of Head Start In D G Singer R M Golinkoff & K Hirsh-Pasek (Eds) Play 1⁄4 learning How play motivates and enhances children’s cognitive and social-emotional growth (pp 15–35) New York NY Oxford University Press 
(IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 620 | P a g e wwwijacsathesaiorg Thinging for Computational Thinking Sabah Al-Fedaghi1  Ali Abdullah Alkhaldi2 Computer Engineering Department Kuwait University Kuwait Abstract—This paper examines conceptual models and their application to computational thinking Computational thinking is a fundamental skill for everybody not just for computer scientists It has been promoted as skills that are as fundamental for all as numeracy and literacy According to authorities in the field the best way to characterize computational thinking is the way in which computer scientists think and the manner in which they reason how computer scientists think for the rest of us Core concepts in computational thinking include such notions as algorithmic thinking abstraction decomposition and generalization This raises several issues and challenges that still need to be addressed including the fundamental characteristics of computational thinking and its relationship with modeling patterns (eg object-oriented) that lead to programming/coding Thinking pattern refers to recurring templates used by designers in thinking In this paper we propose a representation of thinking activity by adopting a thinking pattern called thinging that utilizes a diagrammatic technique called thinging machine (TM) We claim that thinging is a valuable process as a fundamental skill for everybody in computational thinking The viability of such a proclamation is illustrated through examples and a case study Keywords—Computational thinking; conceptual modeling; abstract machine; thinging; abstraction I INTRODUCTION The cognitive faculty of thinking [1] involves processes by which we reason and solve problems ―Computational thinking is a fundamental skill for everybody not just for computer scientists To reading writing and arithmetic we should add computational thinking to every child’s analytic ability‖ [2] Computational thinking is distanced from digital literacy/competence as it focuses on problem-solving processes and methods and on creating computable solutions [3] It has been promoted as skills that are as ―fundamental for all as numeracy and literacy‖ [3] It goes beyond introductory knowledge of computing to treat computer science as an essential part of education today and presents a distinct form of thought separate from these other academic disciplines where diagrammatic techniques are used in analysis and strategic planning [2] In this perspective of computational thinking computer science modeling techniques are essential in many aspects of modern-day research and in understanding things for all people who expect to live and work in a world where information is stored accessed and manipulated via computer software [2] Wing [4] defined computational thinking as something that ―involves solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science‖ It includes [3]  A thought process thus independent of technology  A specific type of problem-solving that entails distinct abilities (eg being able to design solutions that can be executed by a computer human or both) However Bocconi et al [3] raised several issues and challenges that must be addressed for the effective integration of information technology in compulsory education including What are the core characteristics of computational thinking and its relationship with programming/coding in compulsory education? Coding (programming) is regarded as a key 21st century skill ―Coding is the literacy of today and it helps practice 21st century skills such as problem-solving modeling and analytical thinking‖ [3] The authors of European e-Skills Manifesto [5] declared that ―Skills like coding are the new literacy Whether you want to be an engineer or a designer a teacher nurse or web entrepreneur you’ll need digital skills‖ In this paper we seek to contribute to the current debate on computational thinking with particular focus on the following A Conceptualization In computer science conceptualization is the first stage of the model-building process to arrive at a representation capable of addressing the relevant problem A conceptual model is mainly formed upon concepts such as components of thinking It can provide a framework for thinking that structures notions into patterns according to categories to provide a basis to represent internal thinking in an external form Here we use this modeling in the sense of patterned thinking [6] (eg object-oriented modeling) where pattern refers to recurring templates used by persons in the thinking process This paper promotes conceptual modeling that is based on the Heideggerian [7] notion of thinging as a framework for computational thinking Heideggerian thinging is generalized as an abstract thinging machine (TM) [8-13] B Core Concepts As will be described in this paper we propose five basic concepts to model computational thinking  The notion of thing;  The notion of TM;  Five flow operations of things create process release transfer and receive; and  Triggering (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 621 | P a g e wwwijacsathesaiorg C Programming/Coding A diagram can be coded and the code and diagram approximate the conceptual form of the programmer behind both A TM is expressed as a diagram that can be mapped to programming/coding in the same way as flowcharts It is important to mention this property of the TM even though it will not be explored in this paper To achieve a self-contained paper Section II reviews the TM that was adopted in this paper and was used previously in several published papers as mentioned previously Section III presents examples of applying TM in computational thinking Section IV applies the TM in an actual case study II THINGING MACHINE (TM) Drawing on Deleuze and Guattari [14] who declared— admittedly from a different prospect—―All objects can be understood as machines‖ TM-based conceptual modeling utilizes an abstract thinging machine (hereafter machine) with five stages of thinging as shown diagrammatically in Fig 1 In philosophy thinging refers to ―defining a boundary around some portion of reality separating it from everything else and then labeling that portion of reality with a name‖ [15] However according to our understanding thinging is when a thing manifests or unfolds itself in our conceptual space An architect realizes the thing house which in turn things (verb) [7]; that is it presents its total thingness which includes living space shelter from natural elements family symbol etc This issue will be explained later in this paper Our TM modifies Heidegger’s [7] notion of thinging by applying it to the life cycle of a thing and not just to its ontological phase (producing) A thing things; in other words a bridge is not a mere object; rather it establishes itself in a conceptual realm as unified whole involving riverbanks streams and the landscapes When representing it we can view thinging as akin to an abstraction but it differs in being expansive instead of being reductive in detail In the TM we capture thinging as a dynamic machine of things that are created processed received released and transferred—the operations of Fig 1 Heidegger [7] offered an example of thinging through the thing jug When the clay is shaped into a jug the jug manifests itself—in Heidegger’s words—into ―what stands forth‖ Its thingness conquests and entraps the void that holds and takes over its task of embracing and shielding the penetrating wine thus connecting itself to a setting of vine nature etc This conceptualization of the thing jug comes as a reaction to the physical formation of the clay According to Heidegger ―We are apprehending it-so it seemsas a thing‖ [7] (italics added) The TM expands this thinging by conceptualizing the jug not only through its existence but also through its activities as a machine (an assemblage) that creates (eg certain shape of void) releases transfers (eg air) receives and processes other things It is not only a thing that things but also a machine that machines (verb) Heidegger [7] distinguished between objects and things ―The handmade jug can be a thing while the industrially made can of Coke remains an object‖ [16] The industrially made can of Coke has minimal thinging and maximal abstracting (see later discussion) Note that this does not apply to other industrial devices that are not cut off from their ―roots‖ The thermostat for example is an industrial product that manifests itself in its environment as will be represented later in this paper For Heidegger [7] things have unique ―thingy Qualities‖ [16] that are related to reality and therefore are not typically found in industrially generated objects According to Heidegger [7] a thing is self-sustained self-supporting or independent—something that stands on its own The condition of being self-supporting transpires by means of producing the thing According to Heidegger [7] to understand the thingness of a thing one needs to reflect on how thinging expresses the way a ―thing things‖ (ie ―gathering‖ or tying together its constituents into a whole) According to Thomas et al [17] Heidegger’s view can however be seen as a tentative way of examining the nature of entities a way that can make sense An artefact that is manufactured instrumentally without social objectives or considering material/spatial agency may have different qualities than a space or artefact produced under the opposite circumstances The TM handles things and is itself a thing that is handled by other machines The stages in the machine can be briefly described as follows Arrive A thing flows to a new machine (eg packets arrive at a buffer in a router) Accept A thing enters a machine; for simplification purposes we assume that all arriving things are accepted; hence we can combine Arrive and Accept into the Receive stage Release A thing is marked as ready to be transferred outside the machine (eg in an airport passengers wait to board after passport clearance) Process (change) A thing changes its form but not its identity (eg a number changes from binary to hexadecimal) Create A new thing is born in a machine (eg a logic deduction system deduces a conclusion) Transfer A thing is inputted or outputted in/out of a machine A TM also utilizes the notion of triggering Triggering is the activation of a flow denoted in TM diagrams by a dashed arrow It represents a dependency among flows and parts of flows A flow is said to be triggered if it is created or activated by another flow (eg a flow of electricity triggers a flow of heat) or activated by another point in the flow Triggering can also be used to initiate events such as starting up a machine (eg remote signal to turn on) Multiple machines can interact by triggering events related to other machines in those machines’ stages Fig 1 Thinging Machine Create Receive Release Transfer Process Output Input Accept Arrive (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 622 | P a g e wwwijacsathesaiorg III EXAMPLE According to Riley and Hunt [2] in their book Computational Thinking for the Modern Problem Solver an abstraction is anything that allows us to concentrate on important characteristics while deemphasizing less important perhaps distracting details Abstraction is a core concept in computational thinking in addition to such notions as algorithmic thinking decomposition and generalization [3] Riley and Hunt [2] stated that programmers are really a kind of problem solver and that computer programmers are arguably the most important of all modern problem solvers The best way to characterize computational thinking is through the way computer scientists think as well as the manner in which computer scientists think for the rest of us As a digital camera uses a handful of focus points computer scientists learn to focus on the most important issues through abstraction [2] The notion of abstraction goes all the way back to Plato who proposed to distinguish abstract ideas as ideal entities that capture the essence of things They are abstraction that is ideas that do not exist in the world We can note two basic aspects of abstraction  Not being in reality  Being reductive in details Abstraction is an important way of thinking nevertheless We claim that thinging is also a valuable process as a fundamental skill for everybody in computational thinking Thinging takes a holistic view by in contrast to abstraction being expansive in detail as shown in Fig 2 Thinging is an abstraction-like process that deemphasizes reduction and hence facilitates seeing the ―bigger picture‖ Note that thinging and abstraction can be performed at several levels of expansion and in reduction of details Fig 3 illustrates the nature of thinging as an inverse of realization in reality Note the reductive nature of object-oriented modeling (eg UML) in the following example As shown in Fig 4 Riley and Hunt [2] abstractly described the thermostat which involves a class diagram rectangle consisting of three parts diagrammed in three compartments The middle compartment lists attributes of the thermostat The operations in a class diagram are listed in the bottom compartment where operations are abstract references to the behavior of the object The following model presents an alternative conceptualization of the thermostat A Static TM of the Thermostat The thermostat can be represented as in Fig 5 In line with the previous discussion on the thermostat its thingness includes Switch (1) Fan (2) and Temperature (3) The switch includes three signals COOL (4) OFF (5) and HEAT (6) which flow to change the State (7) of the cooling/heating machine (8) Similarly signals set the temperature (9) and change the state of the fan (10) B Behavior of the Thermostat Behavior in a TM is represented by events An event is a thing that can be created processed released transferred and received It is also a machine that consists of (at least) three submachines region time and the event itself As a side note we may conceptualize the TMs as fourfold—that is consisting of space time event and things Fig 2 Thinging is an Expansive Reverse of Realization in Reality Fig 3 The Thing Jug things through its Total Thingness Fig 4 Description of the Class Temperature (Adapted from [2]) Fig 5 The TM Representation of the Thermostat Thing Reality Abstraction Thinging Object Reality Abstraction Thinging … Thermostat HeatSwitchSetting(COOL/OFF/HEAT) FanSetting (ON/AUTO) TemperatureSetting integer SetMinFunction(f COOL/OFF/HEAT) SetFan (b ON/AUTO) SetTemperature (t integer) Create Create Create Switch Thermostat State Create Cooling/heating machine COOL OFF HEAT Receive Receive Process Process Create Process Transfer Release Transfer Release Transfer Create Transfer Release Transfer Temperat ure Fan Receive Process Receive Transfer Transfer Transfer Receive State Create ON AUTO Fan Release Transfer Release Transfer 1 3 5 6 4 7 8 9 10 Create Transfer Release Transfer Process Receive 2 (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 623 | P a g e wwwijacsathesaiorg Consider the event The switch turns OFF (see Fig 6) It includes the event itself (Circle 1 in Fig 6) the region of programmers the things currently being dealt with in the event (2) and the time machine (3) The region is a subgraph of the static representation diagram of Fig 5 For simplicity’s sake we will represent an event by its region only Accordingly we can identify four basic events in the static description of Fig 5 as shown in Fig 7  Event 1 (E1) The switch is COOL  Event 2 (E2) The switch is OFF  Event 3 (E3) The switch is HEAT  Event 4 (E4) The temperature is SET  Event 5 (E5) The fan is ON  Event 6 (E6) The fan is AUTO These events can be written as statements of any programming language C Control of the Thermostat A possible events chronology is shown in Fig 8 which represents the permitted sequence of events For example switching directly from COOL to HEAT and vice versa without first turning the cool/heat machine OFF is not permitted These sequences are shown in Fig 9 (a-e) as follows 1) The cool/heat machine is OFF a) Select {COOL or HEAT} then fan {ON fan set the temperature} b) Select HEAT {select the state of the fan set the temperature} 2) The cool/heat machine is on {COOL or HEAT} and the fan is {ON or AUTO} switch fan to {ON or AUTO} 3) The cool/heat machine is on {COOL or HEAT} set the cool/heat machine OFF 4) The cool/heat machine is on {COOL or HEAT} set the temperature 5) The cool/heat machine is OFF switch fan to {ON or AUTO} Fig 6 He Event the Switch Turns OFF Fig 7 The Events of the Thermostat Fig 8 Chronology of Events Fig 9 Permitted Sequence of Control Operations D Mapping to Class Notations Selecting the events is a design decision TM representation shows that Riley and Hunt [2] declared only three events (Fig 10)  Event 1 (E1) The switch is COOL/OFF/HEAT  Event 2 (E2) The fan is OFF/AUTO  Event 3 (E3) The temperature is set Fig 10 The Events of the Thermostat Create Switch Thermostat Create State Machine OFF Receive Process Transfer Release Transfer Region (Subdiagram) Create Process takes course Transfer Receive Process Consume Release Transfer Time Event itself E1 E2 E4 E3 E6 E5 Create Create Create Switch Thermostat State Create Cooling/heating machine COOL OFF HEAT Receive Receive Process Process Create Process Transfer Release Transfer Release Transfer Create Transfer Release Transfer Temperat ure Fan Receive Process Receive Transfer Transfer Transfer Receive State Create ON AUTO Fan Release Transfer Release Transfer Create Transfer Release Transfer Process Receive E1 E2 E3 E4 E5 E6 E1 E2 E3 E5 E6 (a) E1 E3 E5 E6 (b) E1 E3 E4 (c) E1 E2 E3 (d) E5 E6 E2 (e) Create Switch Thermostat State Create Machine COOL OFF HEAT Receive Process Create Transfer Release Transfer Create Transfer Release Transfer Fan Temperature Receive Process Receive Transfer State Create ON AUTO Fan Release Transfer E1 E2 E3 (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 624 | P a g e wwwijacsathesaiorg Fig 11 The Switch Representation in the 3-Events (Left) and 6-Events (Right) Designs of the Thermostat Fig 11 contrasts the switch representation in the 3 and 6 designs The class notation given by Riley and Hunt [2] can be viewed as mere names for data items and methods (processes) that can be mapped to the TM as shown in Fig 12 Thus we can produce the class description from the TM representation The important point is that the object-oriented thinking style the class description is produced before describing the methods whereas in the TM the TM machines are developed right from the beginning of the analysis Designing the thermostat in terms of three events is the result of this object orientation which captures the three events because it does not see all the possibilities of design Fig 12 TM and Class Entries Consider the 3-events and 6-events designs The 3-events uses one wire between the thermostat and the cool/heat machine whereas the 6-events design uses three Each implementation has its merits The 3-events design is cheaper and the 6-events is more reliable For example in the 6-events design if heating does not work the cooling feature will still work when the link to the cool/heat machine is cut The point here is that the object-orientation as discussed by Riley and Hunt [2] does not seem to be aware of available alternative designs This is an important observation in the context of thinking According to Do and Gross [18] in design ―Drawing is intimately bound with thinking‖ IV CASE STUDY The thermostat’s TM modeling is a small artificial example of problem-solving by describing it conceptually Our case study involves a large real problem how to model a help desk in a government ministry In its actual environment (the workplace of the second author) the maintenance process starts when a user contacts the IT department for help The department calls such a process the help desk process It is a problematic system that involves implicit contacts and interactions in the alignment between IT and business [19] In this case study the IT department solved the help desk problems using an ad-hoc technique that involves thinking of it as a semi-automated system that is built piece by piece over several years There is no current documentation even though the manager of the help desk drew flowcharts that show the full description of the processes behind how the help desk works for different tasks as shown in Fig 13 In projecting this system on Heidegger’s jug in such an approach this can be viewed as failure to give thought to ―what the jug holds and how it holds‖ Help desk operations are causing many types of managerial supervision technical and legal problems A possible solution is a holistic approach that involves all related elements in the help desk system It is a system that exists in reality and needs a better understanding of its thinging It is misthinged or in Heideggerian language a broken tool that marks the annihilation of the ―equipmental thing‖ (IT help desk) in that helping cannot be gathered around it Fig 13 Sample Current Documentation Create ―COOL‖ Process If COOL If OFF If HEAT Release Transfer Transfer Receive Create Create Create Process Process Process Release Transfer Transfer Release Transfer Transfer Release Transfer Transfer Receive Receive Receive COOL OFF HEAT COOL OFF HEAT Create ―OFF‖ Create ―HEAT‖ Create Thermostat State Create Machine COOL OFF HEAT Receive Process Create Transfer Release Transfer Create Transfer Release Transfer Receive Process Receive Transfer State Create ON AUTO Fan Release Transfer E3 E2 Tempreture Setting integer SetMinFunction(f COOLOFF/HEAT) SetTempreture (t integer) SetFan (b ON/AUTO) FanSetting (ON/AUTO) HeatSwitchSetting(COOL/OFF/HEA T) E1 (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 625 | P a g e wwwijacsathesaiorg Accordingly we consider the question ―How does the IT help desk operate?‖ We conceptualize it as a TM that creates processes releases transfers and receives things The helping system includes things that are machines and machines that are things unfolding an integrated wholeness that is itself part of the ministry’s machinery We focus next on thinging the IT help desk A Static Model Accordingly we model the help desk system as shown in Fig 14 In the figure the user sends a request to the secretary of the workshop (Circle 1) The request is checked to decide whether it is for repair (A) or for spare parts (B) B Request for Repair The repair request flows to the workshop administrator (2) where it is processed to do the following 1) Selecting a specific technician for this request To accomplish that the list of technicians is processed (4) to generate the name of a technician (5) 2) Creating a task (ticket) Additionally the administrator creates a new task form (6) that includes the request description (7) and the technician’s name (8) The task then flows (9) to the technician who later examines the task to decide on the following 1) Given that it is possible to call the user and solve the problem by phone (10) the technician places a phone call (11) to the user and guide the user step by step to solve the problem through the phone (12) 2) The technician is required to go to the user’s workplace (13) to solve the problem by him-/herself (14) The technician moves from the workshop to the user’s location (15) The user brings the computer to the technician to work on it and repair it (16) After processing the computer (17) the technician has one of the two following outcomes 1) The computer is not repaired (18) and the technician takes it back to the workshop There it is fixed (19) and the workshop admin (20) transfers the fixed computer back to the user (21) 2) The computer is repaired (22) and transferred back to the user (23 and 24) Both previous outcomes lead to (25) where the user gets the computer and processes it to see whether it is repaired 1) The computer works fine (26); as a result the user creates a report (27) to close the request and sends this report to the workshop admin (28) 2) The computer repair is not satisfactory (29) and the user creates a follow-up request (30) for repair and sends it to the secretary (A) Request for spare parts The spare parts request flows to the inventory department (31) where it is processed (32) to extract the quantity of current spare parts in the inventory (33) and to transfer it to a program that checks this quantity of spare parts (34) 1) If the number is zero the number of the pending requests would be incremented by one (35) Moreover the request would be released (36) and added to a queue of pending requests (37) 2) If the number is greater than zero the request is processed again (38 and 39) to extract the requested quantity of spare parts (40) Note that we renovated an existing system and did not design the best model for this application For example it is possible to define the minimum value of inventory instead of permitting it to reach zero Thus our thinging of the system is tailored to the existing requirements Both the numbers of the requested items (41) and current quantity (42) are transferred to a program that calculates the available quantity (43) that can be delivered to the requester A simple formula calculates what is called remaining quantity as follows Remaining Quantity = Current Quantity – Requested Quantity (44) Accordingly two possibilities arise 1) The remaining quantity is greater than or is equal to zero (45); in other words the full requested quantity can be provided to the user In that case the request is released (46) and transferred to the storage where it is received and processed (47) and the stored spare parts are sent to the requester (48) 2) The remaining quantity is less than zero (49); as a result a new quantity called pending is created and calculated as the following Pending = Requested Quantity – Current Quantity Accordingly a new request that specifies the quantity that is currently in the possession of the inventory department is created (50) and forwarded to the storage and then steps (46- 48) are repeated Also a new request that specifies the number of pending quantities is created and considered as a new request (51) In parallel according to a certain schedule (52) the list of pending requests is processed and each request (the loop is specified in the dynamic TM model) is taken out and processed to create a pending request (53) that in turn is processed thus leading to the creation of an ordered quantity (54) The ordered quantity is added to the total number of ordered items (55) Later the total number of ordered items (56) along with the current quantity (57) flows to a committee for examination and the evaluation of the need for new spare parts is processed (58) Hence a decision is created (59) and processed for making orders (60) which flow to the workshop admin (61) In the workshop admin the orders are processed to (62) create orders to the suppliers (63) and transfer these orders to the purchase department (64) There each order is processed (65) and put on hold while waiting to assign a budget (66) A request for a budget is created (67) by the purchase department and is transferred to the budget department (68) The budget (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 626 | P a g e wwwijacsathesaiorg department processes the budget request (69) approves it and then sends the approval to the purchase department (70) In the purchase department (71) the approval is processed thus leading to placing an order to the supplier (72) Fig 14 The TM Representation of the IT Department Help Desk System Workshop Admin 5 Receive Transfer Process 3 Report to close request Computer Receive Process Transfer Transfer Release Receive Release Transfer If Not Repaired If repaired Technician with computer If acceptable Else User Process Technician (in user place) STORAGE Budget Department Order Budget Approval Workshop Inventory Department Orders Requester Process Remaining Quantity = Current quantity – Requested Quantity If Remaining < 0 Pending = Requested Quantity – Current Available = Current If Remaining >= 0 Process If current quantity is 0 If current quantity is greater than 0 Checking Current Quantity Requested Quantity Current Quantity List of Pending Requests No of requests in pending Add 1 Checking Available Quantity Release Create Stored Spare Parts - Release Create Receive Release Transfer Transfe r Receive Transfer Requested Quantity or Available Quantity Release Transfer Create Total ordered Items Transfer Transfer Pending Request Create Process Create Process Ordered Quantity Process Request Budget Purchase Department Transfer Release Create Receive Transfe Receive r Committee Transfer Receive Transfer Current quantity Receive Transfer Process Create Process Decision Supplier Release Process Transfer Process Workshop Admin Receive Transfer Process Release Transfer Transfer Receive Transfer Release Create Transfer Receive Process Transfer Release Create Transfe r Receive Process Release Transfe r Transfer Process Technician Receive Transfer Transfer Phone Call Process Him/Herself Task Technician name Release Transfer Receive Transfer Transfer Computer Receive Transfer Transfer Transfer Receive Create Release Transfer Create Process If requires going to user Else Technicians List Release Release Secretary Transfer Receive Process Release Transfer 4 22 23 33 24 2 5 34 35 38 41 19 Process Receive Transfer Transfer Release Create Create Transfe r Transfer 1 15 20 26 27 30 28 31 Request Release Create Create 2 6 Release Release Process 16 17 18 Create 29 32 36 37 39 40 43 42 44 4 5 46 47 48 4 9 50 51 52 53 A B Release Transfer Transfer 9 10 11 Transfer Receive 7 Transfer Receive Process 12 13 14 Process 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 21 8 Transfer Receive Receive Supplier Request for parts Request for repair Release (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 627 | P a g e wwwijacsathesaiorg Fig 15 Events of the TM Representation of the IT Department Help Desk System (Partial) C Behavior Model As mentioned previously in the thermostat example behavior in a TM is represented by events Accordingly we can identify the following events in the static description of Fig 14 as shown in Fig 15 To save space we identify only the upper part of Fig 14 (requesting parts)  Event 1 (E1) The secretary receives a request for purchasing spare parts  Event 2 (E2) The inventory department receives and processes the request  Event 3 (E3) The current quantity is retrieved and processed  Event 4 (E4) If the current quantity is 0 add the request to the pending requests list and update the number of pending requests  Event 5 (E5) If the current quantity is greater than 0 extract the requested quantity  Event 6 (E6) Find Remaining (Quantity = Current quantity – Requested Quantity) and process it  Event 7 (E7) Given that Remaining > = 0 retrieve the requested items from the Storage  Event 8 (E8) Send the requested items to the requester  Event 9 (E9) If Remaining < 0 calculate Pending = Requested (Quantity–Current) create a request for pending items and add the request to the list of pending requests  Event 10 (E10) If Remaining < 0 calculate Available = Current and retrieve the requested items from the storage E4 A Request Secretary E1 B STORAGE Requested Quantity Receive Process Transfer Release Request for parts Transfer Pending Request Create Process Process List of Pending Requests No of requests in pending Transfer E2 Inventory Department Orders Release Create Transfer Budget Department Budget Approval Workshop Request Budget Purchase Department Transfer ReceiveTransfer Process Process Transfer Release Create Transfe r Receive Process Release Transfe r Create Transfer Workshop Admin Transfer Release Process Transfer Receive E15 Transfer Release Release Create Order Receive Process Transfer Current quantity Transfer Release Current Quantity Release Transfer Transfe Receive r Process If current quantity is 0 If current quantity is greater than 0 E3 Process Process Remaining Quantity = Current quantity – Requested Quantity If Remaining < 0 Pending = Requested Quantity – Current Available = Current If Remaining >= 0 Checking Available Quantity Create Transfer Receive Release Transfer Create E5 E6 Release Create Transfer E7 E9 E10 E E12 11 Process Create Process Decision Receive Committee Transfe Er12 E13 Total ordered Items Checking Current Quantity Add 1 Ordered Quantity Create Process E14 Create E8 Requester Stored Spare Parts - Requested Quantity or Available Quantity Receive Transfer Release Process E16 E17 E18 E19 E20 E21 Receive Receive Receive Transfer (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 628 | P a g e wwwijacsathesaiorg  Event 11 (E11) Retrieve the pending requests and extract the requested quantities  Event 12 (E12) Both requested pending quantities and current quantities are sent to the ordering committee  Event 13 (E13) The committee creates orders and sends them to the workshop  Event 14 (E14) Orders are received by the workshop and orders to the supplier are created  Event 15 (E15) The purchase department receives orders for the supplier  Event 16 (E16) A request for budget is created  Event 17 (E17) The request for budget flows to the budget department  Event 18 (E18) The budget is approved  Event 19 (E19) Orders for the supplier are sent  Event 20 (E20) Ordered items are received from the supplier  Event 21 (E21) Items as sent to the storage Fig 16 shows the chronology of these events D Control Control can be superimposed onto the events of the TM system In the case study suppose that we want to declare the following warning messages related to the management of the system 1) If the time to order from the supplier in the workshop exceeds t1 then create a warning message 2) If the time to deliver items received from the supplier to the requester exceeds t1 then create a warning message Fig 17 shows the declaration of these rules over the chronology of events In Fig 18 when the workshop receives an order the time of the order arrival is created This time is processed repeatedly If the time exceeds t1—the time period since the receiving of the order—then a warning is created A similar process is followed for the second rule Fig 16 The Chronology of Events of the Case Study Fig 17 Examples of Control in the Case Study E1 E2 E3 E4 E5 E6 E7 E8 E9 E10 E11 E12 E13 E14 E15 E16 E17 E18 E19 E20 E21 E13 Budget Department Budget Approval Workshop Request Budget Purchase Department Receive Receive Transfer Transfer Process Process Release Transfer Transfer Release Create Transfe r Receiv e Process Release Transfe r Create Transfer Release Create Workshop Admin Transfer Receive Process Transfer Release Process Supplier Order Supplier Transfer Receive E13 Storage E14 E15 E16 E17 E18 E19 E20 Transfer Receive Release Transfer Requester Transfer Receive E21 E8 E14 E15 E16 E17 E18 E19 E20 E21 E8 Create Process Create Process If time is greater than t1 Send warning Cancel Time Cancel If time is greater than t2 Time Send warning (IJACSA) International Journal of Advanced Computer Science and Applications Vol 10 No 2 2019 629 | P a g e wwwijacsathesaiorg Fig 18 Simplification of the TM Representation of the IT Department Help Desk System by Removing the Stages Transfer Release and Receive V CONCLUSION We proposed using a new modeling technique TM as a foundation in computational thinking According to the TM approach a person’s ―thought machine‖ forms a train of thought that excludes other modes such as procedural and object-oriented modes of thinking The paper emphasizes this thinking style as a unifying method that could have diverse applications The TM is an underlying tool for expressing the unified totality of a system’s things and machines analogous to carpeting techniques where a ground fabric beneath the design binds pieces and sews the patterns of fabric To substantiate our claim we contrast the TM side by side with diagrams of other approaches (eg the thermostat) Although we provided comprehensive evidence of our claim its inaccuracy or its partial value needs efforts beyond a single researcher However the thermostat example and the case study seem to point to some merits that deserve more development Fig 14 of the case study may raise the issue of the TM diagram’s complexity The TM model can be specified at various levels of granularity For example Fig 18 is a simplified version of the lower part of Fig 14 The stages transfer release and receive are deleted under the assumption that the direction of the flow arrow is sufficient to represent them REFERENCES [1] R Langacker Foundations of Cognitive Grammar Theoretical Prerequisites vol 1 Palo Alto CA Stanford University Press 1987 [2] D Riley and K Hunt Computational Thinking for the Modern Problem Solver Second Edition Boca Raton FL Taylor & Francis Group LLC 2014 [3] S Bocconi A Chioccariello G Dettori A Ferrari and K Engelhardt Developing Computational Thinking in Compulsory Education Luxembourg Publications Office of the European Union doi102791/792158 2016 [4] J M Wing ―Computational thinking and thinking about computing Phil Trans R Soc A Mathematical Physical And Engineering Sciences vol 366 pp 3717–3725 2008 [5] A McCormack The e-Skills Manifesto European Schoolnet DIGITALEUROPE  Brussels 2014 [6] R C Anderson ―The notion of schemata and educational enterprise General discussion of the conference‖ in Schooling and the Acquisition of Knowledge R C Anderson R J Spiro and W E Montague Eds Hillsdale Erlbaum pp 415-431  1977 [7] M Heidegger ―The thing‖ in Poetry Language Thought A Hofstadter Trans New York Harper & Row 1975 pp 161–184 [8] S Al-Fedaghi ―Thinging for software engineers‖ International Journal of Computer Science and Information Security vol 16 No 7 pp 21- 29 2018 [9] S Al-Fedaghi ―Thinging vs objectifying in software engineering‖ International Journal of Computer Science and Information Security vol 16 No 10 pp 87-94 2018 [10] S Al-Fedaghi and H Aljenfawi ―A small company as a thinging machine‖ 10th Int Conf on Info Mgmt and Eng (ICIME) University of Salford Manchester England September 22–24 2018 [11] S Al-Fedaghi and N Al-Huwais ―Enterprise asset management as a flow machine‖ International Journal of Modeling and Optimization vol 8 pp 290–300 2018 [12] S Al-Fedaghi ―Software Engineering Interpretation of Information Processing Regulations‖ IEEE 32nd Annual International Computer Software and Applications Conference (IEEE COMPSAC 2008) Turku Finland pp 271-274 July 28 - August 1 2008 [13] S Al-Fedaghi Flow-based Enterprise Process modeling International Journal of Database Theory and Application Vol 6 No 3 pp 59-70 2013 [14] G Deleuze and F Guattari Anti-Oedipus Capitalism and Schizophrenia Minneapolis MN University of Minnesota Press 1983 [15] J Carreira Philosophy Is Not a Luxury https//philosophyisnotaluxurycom/2011/03/02/to-thing-a-new-verb/ last accessed 12/12/2018 [16] B Latour ―Why has critique run out of steam? From Matters of Fact to Matters of Concern‖ in Critical Inquiry Vol 30 No 2 pp151-174 Winter 2004 [17] L Thomas M Ratcliffe and B J Thomasson ―Can object (instance) diagrams help first year students understand program behaviour?‖ Diagrams International Conference on Theory and Application of Diagrams pp 368–371 2004 [18] E Y-L Do and M D Gross ―Thinking with diagrams in architectural design‖ Artif Intell Rev vol 15 pp 135–149 2001 [19] O Ivarsson ―Quality management for IT support services - A case study of an IT helpdesk service‖ Master Thesis Department of Technology Management and Economics Chalmers University of Technology Gothenburg Sweden 2013 Report to close request Computer Process If Not Repaired If repaired Technician with computer If acceptable Else User Process Technician (in user place) Workshop Admin Technician Phone Call Process Him/Herself Task Technician name Computer Create Create Process If requires going to user Else Secretary Create Create Process Request Process Create A Process Process Request for repair Technicians List 
Full length article Which cognitive abilities underlie computational thinking? Criterion validity of the Computational Thinking Test Marcos Roman-Gonz  alez    Juan-Carlos Perez-Gonz  alez Carmen Jim  enez-Fern  andez  Universidad Nacional de Educacion a Distancia (UNED) Faculty of Education C/ Juan del Rosal n   14 CP 28040 Madrid Spain article info Article history Received 17 April 2016 Received in revised form 22 July 2016 Accepted 29 August 2016 Available online 22 September 2016 Keywords Computational thinking Computational Thinking Test Code literacy Computer science education Cognitive abilities Cognitive assessment Educational psychology Primary education Secondary education abstract Computational thinking (CT) is being located at the focus of educational innovation as a set of problemsolving skills that must be acquired by the new generations of students to thrive in a digital world full of objects driven by software However there is still no consensus on a CT definition or how to measure it In response we attempt to address both issues from a psychometric approach On the one hand a Computational Thinking Test (CTt) is administered on a sample of 1251 Spanish students from 5th to 10th grade so its descriptive statistics and reliability are reported in this paper On the second hand the criterion validity of the CTt is studied with respect to other standardized psychological tests the Primary Mental Abilities (PMA) battery and the RP30 problem-solving test Thus it is intended to provide a new instrument for CT measurement and additionally give evidence of the nature of CT through its associations with key related psychological constructs Results show statistically significant correlations at least moderately intense between CT and spatial ability (r ¼ 044) reasoning ability (r ¼ 044) and problemsolving ability (r ¼ 067) These results are consistent with recent theoretical proposals linking CT to some components of the Cattel-Horn-Carroll (CHC) model of intelligence and corroborate the conceptualization of CT as a problem-solving ability © 2016 Elsevier Ltd All rights reserved 1 Introduction We live immersed in a digital ecosystem full of objects driven by software (Manovich 2013) In this context being able to handle the language of computers is emerging as an inescapable skill a new literacy which allows us to participate fully and effectively in the digital reality that surrounds us it is about to ‘program or be programmed’ (Rushkoff 2010); it is about to be ‘app-enabled or appdependent’ (Gardner & Davis 2013) The term ‘code-literacy’ has recently been coined to refer to the process of teaching and learning to read-write with computer programming languages (Prensky 2008; Rushkoff 2012) Thus it is considered that a person is code-literate when is able to read and write in the language of computers and other machines and to think computationally (Rom an-Gonzalez 2014  ) If code-literacy refers ultimately to a new read-write practice computational thinking (CT) refers to the underlying problem-solving cognitive process that allows it In other words computer programming is the fundamental way that enables CT come alive (Lye & Koh 2014); although CT can be transferred to various types of problems that do not directly involve programming tasks (Wing 2008) Given this current reality overrun by the digital it is not surprising that there is renewed interest in many countries to introduce CT as a set of problem-solving skills to be acquired by the new generations of students; even more CT is becoming viewed at the core of all STEM (Science Technology Engineering & Mathematics) disciplines (Henderson Cortina & Wing 2007; Weintrop et al 2016) Although learn to think computationally has long been recognized as important and positive for the cognitive development of students (Liao & Bright 1991; Mayer 1988; Papert 1980) as computation has become pervasive underpinning communication science culture and business in our society (Howland & Good 2015) CT is increasingly seen as an essential skill to create rather than just consume technology (Resnick et al 2009) Thus many governments around the world are incorporating computer programming into their national educational curricula The recent decision to introduce computer science teaching from primary school onwards in the UK (Brown et al 2013) and others European countries (European Schoolnet 2015) reflects the growing recognition of the importance of CT  Corresponding author E-mail addresses mroman@eduunedes (M Roman-Gonz  alez)  jcperez@edu unedes (J-C Perez-Gonz  alez)  mjimenez@eduunedes (C Jimenez-Fern  andez)  Contents lists available at ScienceDirect Computers in Human Behavior journal homepage wwwelseviercom/locate/comphumbeh http//dxdoiorg/101016/jchb201608047 0747-5632/© 2016 Elsevier Ltd All rights reserved Computers in Human Behavior 72 (2017) 678e691 However there is still little consensus on a formal definition of CT (Gouws Bradshaw & Wentworth 2013; Kalelioglu Gülbahar & Kukul 2016) and disagreements over how it should be integrated in educational curricula (Lye & Koh 2014) Similarly there is a worrying vacuum about how to measure and assess CT fact that must be addressed Without attention to assessment CT can have little hope of making its way successfully into any curriculum Furthermore in order to judge the effectiveness of any curriculum incorporating CT measures that would enable educators to assess what the student has learned need to be validated (Grover & Pea 2013) In response we attempt to address these issues from a psychometric approach On the one hand how our Computational Thinking Test (CTt) has been designed and developed is reported as well as its descriptive statistics and reliability derived from an administration on a sample exceeding a thousand Spanish students On the other hand the criterion validity (Cronbach & Meehl 1955) of the CTt is studied with respect to already standardized psychological tests of core cognitive abilities Thus this paper is aimed at providing a new instrument for measuring CT and additionally giving evidence of the correlations between CT and other well-established psychological constructs in the study of cognitive abilities 11 Computational thinking definitions We can distinguish between a) generic definitions; b) operational definitions; c) educational and curricular definitions 111 Generic definitions One decade ago in 2006 Jeanette Wing's foundational paper defined that CT “involves solving problems designing systems and understanding human behavior by drawing on the concepts fundamental to computer science” (Wing 2006 p 33) Thus CT's essence is thinking like a computer scientist when confronted with a problem But this first generic definition has been revisited and specified in successive attempts over the last few years still not reaching an agreement (Grover & Pea 2013; Kalelioglu et al 2016 ) So in 2011 Wing clarified CT “is the thought processes involved in formulating problems and their solutions so that the solutions are represented in a form that can be effectively carried out by an information-processing agent” (Wing 2011; on-line) One year later this definition is simplified by Aho who conceptualizes CT as the thought processes involved in formulating problems so “their solutions can be represented as computational steps and algorithms” (Aho 2012 p 832) 112 Operational definitions In 2011 the Computer Science Teachers Association (CSTA) and the International Society for Technology in Education (ISTE) developed an operational definition of computational thinking that provides a framework and common vocabulary for Computer Science K-12 educators CT is a “problem-solving process that includes (but is not limited to) the following characteristics formulating problems in a way that enables us to use a computer and other tools to help solve them; logically organizing and analyzing data; representing data through abstractions such as models and simulations; automating solutions through algorithmic thinking (a series of ordered steps); identifying analyzing and implementing possible solutions with the goal of achieving the most efficient and effective combination of steps and resources; generalizing and transferring this problem solving process to a wide variety of problems” (CSTA & ISTE 2011; on-line) 113 Educational-curricular definitions More than definitions in the strict sense frameworks for developing CT in the classroom and other educational settings are mentioned next So from the UK the organization Computing At School (CAS) states that CT involves six different concepts (logic algorithms decomposition patterns abstraction and evaluation) and five approaches to working (tinkering creating debugging persevering and collaborating) in the classroom (CAS Barefoot 2014) Moreover from the United States Brennan and Resnick (2012) describe a CT framework that involves three key dimensions ‘computational concepts’ (sequences loops events parallelism conditionals operators and data); ‘computational practices’ (experimenting and iterating testing and debugging reusing and remixing abstracting and modularizing); and ‘computational perspectives’ (expressing connecting and questioning) Table 1 shows a crosstab intersecting the CT framework dimensions (Brennan & Resnick 2012) with the sampling domain of our Computational Thinking Test (CTt) which will be detailed in Sub-section 14 12 Computational thinking from the CHC model of intelligence While CT involves thinking skills to solve problems algorithmically (eg Brennan & Resnick 2012; Grover & Pea 2013) intelligence (ie general mental ability or general cognitive ability) involves primarily the ability to reason plan and solve problems (Gottfredson 1997) Even authors with alternative approaches to the conceptualization of intelligence recognize intelligence as a “computational capacity” or “the ability to process certain kinds of information in the process of solving problems of fashioning products” (Gardner 2006 p 503) Within a cognitive approach it has been recently suggested (Ambrosio Xavier & Georges 2014) that computational thinking is related to the following three abilities-factors from the CattellHorn-Carroll (CHC) model of intelligence (McGrew 2009; Schneider & McGrew 2012) Fluid reasoning (Gf) defined as “the use of deliberate and controlled mental operations to solve novel problems that cannot be performed automatically Mental operations often include drawing inferences concept formation classification generating and testing hypothesis identifying relations comprehending implications problem solving extrapolating and transforming information Inductive and deductive reasoning are generally considered the hallmark indicators of Gf” (McGrew 2009 p 5) Visual processing (Gv) defined as “the ability to generate store retrieve and transform visual images and sensations Gv abilities are typically measured by tasks (figural or geometric stimuli) that require the perception and transformation of visual shapes forms or images and/or tasks that require maintaining spatial orientation with regard to objects that may change or move through space” (McGrew 2009 p 5) Short-term memory (Gsm) defined as “the ability to apprehend and maintain awareness of a limited number of elements of information in the immediate situation (events that occurred in the last minute or so) A limited-capacity system that loses information quickly through the decay of memory traces unless an individual activates other cognitive resources to maintain the information in immediate awareness” (McGrew 2009 p 5) Therefore it is expected that a computational thinking test should correlate with other already validated tests aimed at measuring cognitive abilities cited above M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 679 13 Computational thinking assessment Count on validated measurement instruments is something necessary and valuable in any research area However for the moment there is still a large gap of tests relating to CT that have undergone a comprehensive psychometric validation process (Mühling Ruf & Hubwieser 2015) As Buffum et al (2015) say “developing assessments of student learning is an urgent area of need for the relatively young computer science education community as it advances toward the ranks of more mature disciplines such as physics that have established standardized assessments over time” (Buffum et al 2015 p 622) Anyway we find in recent years some remarkable attempts to measure and assess CT in students from 5th to 10th grade which are the ones of this paper's interest From the University of California comes the instrument Fairy Assessment in Alice (Werner Denner Campe & Kawamoto 2012) which tries to measure the understanding and use of abstraction conditional logic algorithmic thinking and other CT concepts that middle school students utilize to solve problems However this instrument is designed ad hoc to be used in the context of programming learning environment Alice1 (Graczynska 2010  ) and it has not been undergone to a psychometric validation process The research group from Clemson University (South Carolina) provides a complementary perspective (Daily Leonard Jorg Babu € & Gundersen 2014; Leonard et al 2015) These authors propose a kinesthetic approach to learning (‘embodied learning’) and assessment of CT with 5th and 6th grade students To do so they alternate activities for programming motion sequences (choreographies) in the Alice environment with the representation of those same sequences in a physical-kinesthetic environment The assessment tool also combines both settings but its psychometric properties have not been reported Another interesting research line with middle school students is provided by the group from the University of Colorado They work with students in the video-game programming environment AgentSheets2 Within a first group of studies (Koh Basawapatna Bennett & Repenning 2010) these authors identify several Computational Thinking Patterns (CTP) that young programmers abstract and develop during the creation of their video-games; in this context they design the Computational Thinking Patterns Graph an automated tool that analyzes the games programmed by the students and represents graphically how far each game has involved the different CTP when compared with a model Within a second group of studies (Basawapatna Koh Repenning Webb & Marshall 2011) the authors try to assess whether students are able to transfer the CTP acquired during video-game programming to a new context of scientific simulations programming For this assessment they develop CTP-Quiz instrument whose reliability or validity have not been reported Similarly from the Universidad Rey Juan Carlos (Madrid Spain) Dr Scratch3 is presented (Moreno-Leon & Robles 2015a 2015b 2014) Dr Scratch is a free and open source web application designed to analyze simply and automatically projects programmed with Scratch4 (Resnick et al 2009) as well as it provides feedback that can be used to improve programming skills and to develop CT in middle school students (Moreno-Leon Robles  & Roman-Gonz  alez 2015  ) In order to assign an overall CT score to the project Dr Scratch infers the programmer competence along the following seven CT dimensions Abstraction and problem decomposition; Parallelism; Logical thinking; Synchronization; Flow control; User Interactivity; and Data representation Therefore Dr Scratch is not strictly a cognitive test but a tool for the formative assessment of Scratch projects Dr Scratch is currently under validation process although its convergent validity with respect to other traditional metrics of software quality and complexity has been already reported (Moreno-Leon Robles  & Roman-Gonz  alez 2016  ) Furthermore we consider the Bebras International Contest5 a competition born in Lithuania in 2003 which aims to promote the interest and excellence of primary and secondary students around the world in the field of Computer Science from a CT perspective (Cartelli Dagiene & Futschek 2012; Dagiene & Futschek 2008; Dagiene & Stupuriene 2014) Each year the contest proposes a set of Bebras Tasks whose overall approach is the resolution of real problems significant for the students through the transfer and projection of their CT over those These Bebras Tasks are independent from any particular software or hardware and can be administered to individuals without any prior programming experience Table 1 Crosstab intersecting CT framework (Brennan & Resnick 2012) with the sampling domain of our CTt CT framework CTt Dimension Description Components Sampling domain Computational concepts Concepts students employ as they program Sequences  Computational concept addressed Loops  Events e Parallelism e Conditionals  Operators  Data e Computational practices Problem-solving practices that occurs in the process of programming Experimenting and iterating e Required task Testing and debugging / Reusing and remixing / Abstracting and modularizing / Computational perspectives Students' understandings of themselves their relationships to others and the digital world around them Expressing e e Connecting e Questioning e   Yes / Partly - No 1 http//wwwaliceorg/indexphp 2 http//wwwagentsheetscom/ 3 http//drscratchorg/ 4 https//scratchmitedu/ 5 http//wwwbebrasorg/ 680 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 For all these features the Bebras Tasks have been pointed out as more than likely embryo for a future PISA (Programme for International Student Assessment) test in the field of Computer Science (Hubwieser & Mühling 2014; Jaskova & Kovacova 2015  ) Anyway the Bebras International Contest is at the moment an event for promoting CT not a measuring instrument; among other considerations because it is not composed by a stable and determined set of task-items but a set that varies from year to year with slight modifications along the countries However its growing expansion has aroused the interest of psychometry researchers who have begun to investigate its possible virtues as a CT measurement instrument Thus descriptive studies about the student's performance on Bebras Tasks have been recently published referred to the corresponding editions of the Bebras International Contest held in Germany (Hubwieser & Mühling 2014 2015) Italy (Bellettini et al 2015) Taiwan (Lee Lin & Lin 2014) or Turkey (Kalelioglu Gülbahar & Madran 2015) In all of them and in most of the tasks studied significantly higher performances in the male group in comparison with the female group were reported But strictly speaking we only have knowledge of two tests aimed to middle/high school students which are being fully subjected to the psychometric requirements; both instruments are currently undergoing a validation process a Test for Measuring Basic Programming Abilities (Mühling et al 2015) it is designed for Bavarian students from 7th to 10th grade This test is aimed at measuring the students' ability to execute a given program based on the so-called ‘flow control structures’; which are considered at the core of the CT for this age group Sequencing (doing one step after another); Selection (doing either one thing or another); Repetition (doing one thing once and again) These control structures lead to the following CT concepts that are covered by the test sequence of operations; conditional statement with (if/else) and without (if) alternative; loop with fixed number of iterations (repeat times); loop with exit condition (conditional loop while or repeat until); and the nesting of these structures to create more complex programs b Commutative Assessment (Weintrop & Wilensky 2015) it is designed for high-school students from 9th to 12th grade This test is aimed at measuring students' understanding of different computational concepts depending on whether they occur through scripts written in visual (block-based) or textual programming languages; which is a key transition to reach higher levels of code-literacy The test has a length of 28 items and it addresses the following CT concepts conditionals; defined/fixed loops; undefined/unfixed loops; simple functions; functions with parameters/variables 14 Computational Thinking Test Overall our Computational Thinking Test (CTt) has been developed following the practical guide to validating computer science knowledge assessments with application to middle school from Buffum et al (2015) which is aligned with the international standards for psychological and educational testing (AERA APA & NCME 2014) In addition the CTt is consistent with other computational thinking tests under validation aimed to middle/high school such as the Test for Measuring Basic Programming Abilities (Mühling et al 2015) or the Commutative Assessment (Weintrop & Wilensky 2015) just described in Sub-section 13 The CTt was initially designed with a length of 40 multiple choice items (version 10 October 2014) After a content validation process through twenty experts' judgement this first version was refined to the final one (version 20 December 2014) of 28 items length (Roman-Gonz   alez 2015); which is built on the following principles Aim CTt aims to measure the development level of CT in the subject Operational definition of measured construct CT involves the ability to formulate and solve problems by relying on the fundamental concepts of computing and using logic-syntax of programming languages basic sequences loops iteration conditionals functions and variables Target population CTt is mainly designed and intended for Spanish students between 12 and 14 years old (7th and 8th grade); although it can be also used in lower grades (5th and 6th grade) and upper grades (9th and 10th grade) Instrument Type multiple choice test with 4 answer options (only one correct) Length and estimated completion time 28 items; 45 min Each item of the CTt6 is designed and characterized according to the following five dimensions of the sampling domain Computational concept addressed each item addresses one or more of the following seven computational concepts ordered in increasing difficulty Basic directions and sequences (4 items); Loopserepeat times (4 items); Loopserepeat until (4 items); Ifesimple conditional (4 items); If/elseecomplex conditional (4 items); While conditional (4 items); Simple functions (4 items) These ‘computational concepts’ are aligned with some of the CT framework (Brennan & Resnick 2012; see Table 1) and with the CSTA Computer Science Standards for 7th and 8th grade (CSTA 2011) Environment-Interface of the item CTt items are presented in any of the following two environments-interfaces ‘The Maze’ (23 items) or ‘The Canvas’ (5 items) Both interfaces are common in popular sites for learning programming such as Codeorg (Kalelioglu 2015 ) Answer alternatives style in each item the response alternatives may be presented in any of these two styles Visual arrows (8 items) or Visual blocks (20 items) Both styles are also common in popular sites for learning programming such as Codeorg (Kalelioglu 2015 ) Existence or non-existence of nesting depending on whether the item solution involves a script with (19 items) or without (9 items) nesting computational concepts (a concept embedded in another to a higher hierarchy level) (Mühling et al 2015) Required task depending on which of the following cognitive tasks is required for solving the item Sequencing the student must sequence stating in an orderly manner a set of commands (14 items); Completion the student must complete an incomplete given set of commands (9 items); Debugging the student must debug an incorrect given set of commands (5 items) This dimension is partially aligned with the aforementioned ‘computational practices’ from the CT framework (Brennan & Resnick 2012; see Table 1) The CTt is administered collectively and on-line and it can be performed both via non-mobile or mobile electronic devices Preliminary results about the CTt psychometric properties after its administration on a sample of 400 Spanish students (7th and 8th grade) have been already reported (Roman-Gonz  alez P  erez-  6 Available at http//googl/IYEKMB (Spanish version) Other forms and versions of CTt are available free of charge only for research purposes from the first author 7 https//studiocodeorg/s/20-hour 8 https//studiocodeorg/s/course2 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 681 Gonz alez & Jimenez-Fern   andez 2015) Examples of definitive CTt items translated into English are shown in Figs 1e4; with their specifications detailed below 2 Method 21 Participants The CTt was administered on a total sample of 1251 Spanish students boys and girls from 24 different schools enrolled from 5th to 10th grade The distribution of the subjects by gender grade and age is shown in Table 2 From the total sample 825 (659%) students belong to public schools and 426 (341%) belong to private schools Considering the device on which the CTt was administered 1001 students did it on a personal computer (800%) and 250 students (200%) did it so on a tablet None of the subjects had prior programming formal experience when the CTt was administered The sampling procedure is not probabilistic and intentional Depending on the reasons that led to sample the different subjects these can be divided into four sub-samples Sub-sample A (n ¼ 418) it is composed of individuals belonging to classrooms that subsequently enrolled in the Accelerated Intro to CS Course from Codeorg7 Sub-sample B (n ¼ 48) it is composed of individuals belonging to classrooms that subsequently enrolled in the CS Fundamentals Course 2 from Codeorg8 Sub-sample C (n ¼ 194) it is composed of individuals belonging to classrooms that subsequently started to learn programming with Scratch Sub-sample D (n ¼ 591) it is composed of individuals belonging to classrooms that although they did not subsequently start to learn programming were interested on measuring the CT of the students In addition to our CTt other standardized tests were administered concurrently to a part of the above subjects Specifically for this paper administrations of Primary Mental Abilities (PMA) battery (141  n  166) and RP30 problem-solving test (n ¼ 56) are considered; all of these additional administrations are performed on subjects belonging to Sub-sample A In the following Subsection 22 both standardized tests PMA and RP30 are described 22 Instruments In order to address the criterion validation of the CTt another two standardized instruments are administered the Primary Mental Abilities (PMA) battery and the RP30 problem-solving test; which are described next 221 Primary Mental Abilities (PMA) battery The PMA battery is aimed at appreciating the basic cognitive abilities through four different subtests which allow an estimate of the main components of intelligence This is a well-known measure of cognitive abilities (eg Hertzog & Bleckley 2001; Quiroga et al 2015) developed by Thurstone (1938) Its maximum administration time is 26 min and it can be used from 10 years old onwards The Spanish technical manual (TEA Ediciones 2007) reports excellent reliability and validity coefficients about the four subtests The PMA provides a precise measurement of the following cognitive abilities Verbal factor (PMA-V) Ability to understand and express ideas with words PMA-V items involve selecting the accurate synonym of a word given Spatial factor (PMA-S) Ability to imagine and devise objects in two and three dimensions PMA-S items involve selecting equal figures to a given model after having been rotated Reasoning factor (PMA-R) Ability to solve logical problems to understand and plan PMA-R items involve selecting the option which continues a logical series given Numerical factor (PMA-N) Ability to handle numbers and quantitative concepts PMA-N items involve checking mentally the sum of four two-digit numbers 222 RP30 problem-solving test RP30 problem-solving test is aimed to assess speed and flexibility in performing logical operations Its maximum administration time is 17 min and it can be used from 12 years old onwards The Spanish technical manual (Seisdedos 2002) reports excellent reliability values for RP30 (rxx > 090; through the split-half method) as well as its criterion validity regarding to Changes Test of Cognitive Flexibility9 (rxy ¼ 038) or to DAT10-Spatial (rxy ¼ 034) Fig 1 CTt item 6 loopserepeat times; ‘The Maze’; visual arrows; no-nesting; completion 9 Test Cambios de Flexibilidad Cognitiva [Changes Test of Cognitive Flexibility] (Seisdedos 1994) 10 DAT Differential Aptitude Tests (Bennett 1952) 682 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 Fig 2 CTt item 7 loopserepeat times; ‘The Canvas’; visual blocks; no-nesting; debugging Fig 3 CTt item 14 loopserepeat until þ Ifesimple conditional; ‘The Maze’; visual blocks; yes-nesting; sequencing Fig 4 CTt item 25 loopserepeat times þ simple functions; ‘The Canvas’; visual blocks; yes-nesting; sequencing M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 683 RP30 appreciates a high-level cognitive ability by which a series of logical relations given are understood by the subject in order to determine whether these relations are met in several simple structures RP30 is closely related to the non-verbal aspects of intelligence it seems to be an important predictor to many school or professional activities and it has been previously used as a proxy of the general mental ability (eg Barros Kausel Cuadra & Díaz 2014; Caceres  & Conejeros 2011) RP30 items involve five structures in which the subject must decide whether the problem conditions are satisfied (Fig 5) RP30 requires enough concentration as errors are penalized It is considered that there are three cognitive abilities underlying RP30 performance (Seisdedos 2002) Reasoning due to the fact that the logical relations which may satisfy the structures must be previously understood by the subject Spatial ability as the subject must process the small circles and squares contained in each structure in order to decide if the condition is satisfied Working memory which allows the subject to retain the given logical relation without need of constantly consulting it 23 Procedure Participating subjects in our research were enrolled in the elective subject of Computer Science which is held twice a week (1 h each) Typically the CTt was administered during the first of the two weekly classes In the groups in which another standardized instrument was further administered it was done during the second weekly class For the CTt collective administration the Computer Science teacher followed the instructions which were sent by email in the week before containing the URL to access the on-line test The student's direct answers to the CTt items were stored in the Google Drive database linked with the instrument which was subsequently downloaded as an Excelxls file For the collective administration of the standardized instrument (PMA or RP30) students were previously signed in the on-line platform from the publishing house11 holder of these tests' commercial rights Come the administration day the subjects logged in the platform and performed the corresponding instrument PMA battery or RP30 test (never both) Afterwards from our administrator profile we could download the subjects' results as an Excelxls file Finally all xls files generated during data collection were exported to a single sav file which constitutes the data matrix under analysis with SPSS software (version 22) From this analysis arise the results exposed below 3 Results and discussion 31 Descriptive statistics Table 3 shows the main descriptive statistics of the CTt score (calculated as the sum of correct answers along the 28 items of the test) for the entire sample (n ¼ 1251) In Fig 6 (left) a histogram showing the distribution of the CTt score along the sample is depicted As it can be seen the aforementioned distribution fits remarkably the normal curve; although given the very large size of the sample the small existing maladjustments are penalized by the Kolmogorov-Smirnov test which rejects the null hypothesis of normality (Zk-s ¼ 0052; p < 001) In Fig 6 (right) we show the success rate per item (expressed in per unit) or item difficulty index that confirms empirically the progressive difficulty of the CTt; which was already anticipated by the experts during the content validation process (Roman-  Gonzalez 2015  ) The average success rate along the 28 items is p ¼ 059 (medium difficulty); ranging from p ¼ 016 (item 23; very high difficulty) to p ¼ 096 (item 1; very low difficulty) Summarizing it can be stated that a) the CTt score is almost normally distributed (ie symmetrically distributed; skewness z0) showing proper variability so that is possible to construct suitable scales (percentiles) for the target population; b) the CTt has an appropriate degree of difficulty (medium) for the target population with an increasing difficulty along its items as recommended in the design of abilities' tests (eg Carpenter Just & Shell 1990; Elithorn & Telford 1969) 311 Differences by grade When the sample is segmented regarding to grade the descriptive statistics shown in Table 4 are obtained Specifically results in Table 4 are split according to the Spanish educational system by the end of Primary Education (5th and 6th grade) the start of Secondary Education (7th and 8th grade) and the end of Secondary Education (9th and 10th grade) Box plots for the CTt score split by aforementioned grades are shown in Fig 7 The outlier belongs to a case from 6th grade which obtained CTt score equal to 26 (ie z3 standard deviations above the mean of its reference group) The ANOVA test shows statistically significant differences in the CTt score regarding to grade (F(2 1248) ¼ 50514; p < 001) The post-hoc Tukey test additionally shows statistically significant differences between all possible pairs of means (p < 001) Hence it can be stated that the performance on the CTt increases as it does the grade; this result is consistent with our assumption that the CT is a problem-solving ability that it should be therefore linked to the cognitive development and maturity of the subjects (Ackerman & Rolfhus 1999; Mayer Caruso & Salovey 1999) 312 Gender differences About the possible differential performance on the CTt regarding to gender we find a statistically significant difference in the CTt score in favor of the male group (t ¼ 5374; p < 001) resulting an effect size measured through Cohen's d (Cohen 1992) equal to 031 (Table 5); that can be considered as a low-moderate effect If the aforementioned difference is analyzed along grades (Table 5) higher means in the CTt score are always found in the Table 2 Distribution of the total sample (n ¼ 1251) by gender grade and age Gender Total Boys Girls Grade 5th Age 10e11 y/o Count 50 53 103 % of Total 40% 42% 82% 6th 11e12 y/o Count 28 45 73 % of Total 22% 36% 58% 7th 12e13 y/o Count 263 170 433 % of Total 210% 136% 346% 8th 13-14 y/o Count 187 115 302 % of Total 149% 92% 241% 9th 14e15 y/o Count 112 87 199 % of Total 90% 70% 159% 10th 15e16 y/o Count 90 51 141 % of Total 72% 41% 113% Total Count 730 521 1251 % of Total 584% 416% 1000% 11 http//wwwe-teaedicionescom/ 684 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 male group although these gender differences are only statistically significant from 7th and 8th grade (t ¼ 2928; p < 001) onwards; being more intense in 9th and 10th grade (t ¼ 3451; p < 001) Hence it seems that there is a progressive gender gap over the CTt performance as we advance along the grades (Fig 8) These gender differences are consistent with those found in previous research with Bebras Tasks on which most of the investigations report higher yields of the male group as described in Sub-section 13 Fig 5 Item example from the RP30 problem-solving test Table 3 Descriptive statistics of the CTt score for the entire sample (n ¼ 1251) Mean 1638 Std Error of Mean 136 Median 1600 Mode 17 Std Deviation 4824 Variance 23271 Skewness 058 Kurtosis 446 Minimum 3 Maximum 28 Percentiles 10 1000 20 1200 25 1300 30 1400 40 1500 50 1600 60 1700 70 1900 75 2000 80 2100 90 2300 Fig 6 Histogram of the CTt score (left); Item Difficulty Index for each item of the CTt (right) M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 685 32 Reliability Reliability as internal consistency of the CTt measured by Cronbach's Alfa is a ¼ 0793 z 080; that can be considered as good reliability (Nunnally & Bernstein 1994) When reliability is studied regarding to grade and administration's device (Table 6) we find that a) reliability increases as it does the grade; which is coherent with the greater accuracy and consistency often shown by the answers coming from the upper grades' students (Anastasi 1968); b) reliability increases when CTt is administered through mobile devices such as tablets perhaps because these devices allow the subject to rotate the screen to one side and another reducing the spatial cognitive load of the items and avoiding that the subjects commit unexpected errors on the same This interpretation is supported by the results obtained when comparing the average yield in the CTt between subjects who performed it on a computer and subjects who did it so on a tablet for instance in 7th and 8th grade Xcomputer ¼ 1601 vs Xtablet ¼ 1824 (t ¼ 4116; p < 001; d ¼ 050) In the future if we achieve a larger sample of subjects who perform the CTt on tablet and if these aforementioned significant differences between devices continue it will be necessary to construct different scales for the CTt depending on the administration device 33 Criterion validity 331 Relative to Primary Mental Abilities (PMA) battery Correlations between the CTt and the various tests of the PMA battery are shown in Table 7 As it can be seen the CTt has a positive statistically significant correlation (p < 001) moderately intense with PMA-R (reasoning factor) and PMA-S (spatial factor) and slightly intense with PMA-V (verbal factor) There is no statistically significant correlation between CTt and PMA-N (numerical factor) Corresponding scatter plots are shown in Fig 9 At this point we perform a multiple linear regression over the CTt score (considered as the dependent variable) based on the PMA-V PMA-S PMA-R and PMA-N scores (considered as predictors) Table 8 summarizes de regression model which is calculated through the ‘enter’ method This regression model based on the PMA battery correlates r ¼ 0540 with the CTt; which means an adjusted R2 ¼ 027 That is the 270% of the CTt scores' variance is explained from a linear combination of the primary mental abilities measured through the PMA battery Normality of the regression model residuals was verified The regression model is able to explain statistically significant the differences in the CTt scores as F(4 131) ¼ 13457 (p < 001) However as shown in following Table 9 which contains the coefficients of the regression model only PMA-S (spatial factor) and PMA-R (reasoning factor) are capable specifically and statistically significant (p < 001) to explain differences in the dependent variable (CTt) The standardized coefficients of the model are from highest to lowest value b(PMA-S) ¼ 0308; b(PMA-R) ¼ 0265; b(PMAV) ¼ 0134; b(PMA-N) ¼ 0051 From our perspective these results point out two important issues Firstly there is still a 730% of the CTt scores' variance that is not explained by the primary mental abilities measured through the PMA battery; which suggests certain independence of CT as a psychological construct distinct from the traditional aptitudes Secondly the cognitive abilities with higher explanatory power about CT are reasoning ability and spatial ability; from both there is abundant evidence in the literature that reports certain male superiority Regarding to the former Kuhn and Holling (2009) recently report gender differences in reasoning ability favoring males in German students from 7th to 10th grade Regarding to the latter there are some meta-analysis that demonstrate higher male spatial ability especially in tasks that involve mentally rotation of figures (Linn & Petersen 1985; Voyer Voyer & Bryden 1995) All the above could explain the higher yield of the boys in the CTt seen in Sub-section 312 332 Relative to RP30 problem-solving test Correlation between CTt and RP30 problem-solving test is shown in Table 10 As it can be seen we find a positive statistically significant and moderately-strongly intense correlation (r ¼ 0669; p < 001) between both instruments Corresponding scatter plot is shown in Fig 10 such as the coefficient of determination R2 ¼ 0447 (ie 447% of shared variance between both scores) Recall that RP30 test appreciates a high-level cognitive ability and it has been previously used as a proxy of the general mental ability Our results Table 4 Descriptive statistics of the CTt score split by grades Grades 5th & 6th 7th & 8th 9th & 10th n 176 735 340 Mean 1376 1624 1805 Std Error of Mean 326 167 274 Median 1400 1600 1800 Mode 15 18 17 Std Deviation 4330 4519 5049 Variance 18746 20419 25496 Skewness 125 018 097 Kurtosis 148 453 577 Minimum 3 3 3 Maximum 26 27 28 Percentiles 10 800 1000 1200 20 1000 1200 1320 25 1100 1300 1400 30 1100 1400 1500 40 1300 1500 1700 50 1400 1600 1800 60 1500 1700 1900 70 1600 1900 2100 75 1675 2000 2200 80 1700 2000 2300 90 2000 2200 2500 Fig 7 Box plots for the CTt score split by grades 686 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 indicate that CTt correlate more intensely with RP30 than with any of the primary mental abilities measured through PMA battery (Table 11) Hence it seems that computational thinking could be fundamentally linked with general mental ability (particularly with fluid intelligence); and to a lesser extent with different cognitive aptitudes such as logical reasoning and spatial ability When results of preceding Sub-sections 331 and 332 are triangulated we find a clear consistency between the magnitude of the correlations CTt PMA and CTt RP30 and the expected composition of computational thinking from the CHC model of intelligence exposed in Sub-section 12 (Table 11) From our point of view this is a powerful evidence of the criterion concurrent validity of our CTt as well as an empirical confirmation of the computational thinking construct's composition proposed by Ambrosio et al (2014) 4 Implications and limitations The CTt has some strengths like it can be administered in pretest conditions to measure the initial development level of CT in students without prior programming experience from 5th to 10th grade; it can be collectively administered so it could be used in massive screenings and early detection of students with high abilities (or special needs) for programming tasks; it can be utilized for collecting quantitative data in pre-post evaluations of the efficacy of curricula or programs aimed at fostering CT which would be a desirable practice versus the qualitative approach that has been mostly used in the literature so far (Lye & Koh 2014); and it could be used along academic and professional guidance processes towards STEM disciplines However the CTt also has obvious limitations and weaknesses The CTt provides a static and decontextualized assessment Therefore we recommend to complement its use with other CT assessment tools designed from a formative perspective such as Dr Scratch (Moreno-Leon et al 2015  ) In terms of CT framework (Brennan & Resnick 2012) the CTt is overly focused on ‘computational concepts’ only covers ‘computational practices’ partly and ignores ‘computational perspectives’ The CTt only demands the projection of computational thinking over logical and visuospatial problems such as solving mazes or designing geometric patterns This implies a clear bias of the CTt as computational thinking can also be projected over problems with different features such as modeling scientific simulations (Weintrop et al 2016); algorithmic composition of computational music (Edwards 2011); or digital interactive storytelling (Burke 2012; Howland & Good 2015) The latter authors report significantly higher values in the computational complexity of scripts written by girls from 7th and 8th grade in comparison with their male peers within narrative tasks; this Table 5 Gender differences in CTt score n Mean Std Deviation Student's t Effect size Cohen's d Entire sample Boys 730 1699 4802 5374 031 Girls 521 1552 4727 Grades 5th & 6th Boys 78 1440 4185 1765 027 Girls 98 1324 4396 7th & 8th Boys 450 1662 4463 2928 022 Girls 285 1563 4547 9th & 10th Boys 202 1882 5115 3451 038 Girls 138 1693 4749 p < 001 Fig 8 Box plots for the CTt score split by gender and along grades Table 6 Reliability as internal consistency of the CTt Cronbach's alpha n Cronbach's Alpha n Entire sample 0793 1251 Computer 0786 1001 Tablet 0817 250 Grades 5th & 6th 0721 176 Computer 0719 66 Tablet 0712 110 7th & 8th 0762 735 Computer 0744 659 Tablet 0836 76 9th & 10th 0824 340 Computer 0824 276 Tablet 0825 64 Table 7 Correlations (Pearson's r) between CTt and PMA battery PMA-V PMA-S PMA-R PMA-N CTt 0273 0439 0442 0157 PMA-V 0225 0334 0020 PMA-S 0356 0164 PMA-R 0030 141  n  166; p < 001;  p < 005 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 687 result is consistent with the (slight) female superiority in tasks involving verbal ability reported in the classical literature (Hyde & Linn 1988) It seems therefore that the direction of gender differences in CT may vary depending on the type of problems on which such ability is projected Finally as the CTt is entirely designed with multiple choice items it might be measuring CT at its lower cognitive complexity levels (‘recognize’ and ‘understand’) (Gouws et al Fig 9 Scatter plots between CTt and PMA battery Table 8 Summary of the regression model of the CTt onto the PMA subtests Model R R square Adjusted R square Std Error of the estimate 1 0540a 0291 0270 3391 a Predictors (Constant) PMA-V PMA-S PMA-R PMA-N Table 9 Standardized coefficientsa of the regression model of the CTt onto the PMA subtests Model b Standardized coefficients Student's t 1 (Constant) 9006 PMA-V 0134 1715 PMA-S 0308 3865 PMA-R 0265 3253 PMA-N 0051 0688 p < 001 a Dependent variable CTt 688 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 2013) An instrument intended to measure CT also at higher levels of complexity (‘Apply’ and ‘Assimilate’) should include items which require not only recognize but also evoke the correct algorithm; as well as open complex problems whose resolution demands students to creatively transfer CT towards different domains 5 Conclusions and further research In this paper we have provided evidences of reliability and criterion validity of a new instrument for the assessment of CT and additionally we expanded our understanding of the CT nature through the theory-driven exploration of its associations with other established psychological constructs in the cognitive sphere We have found expected positive small or moderate significant correlations (027 < r < 044) between CT and three of the four primary mental abilities of the Thurstone (1938) model of intelligence as well as a high correlation (r ¼ 067) between CT and problem-solving ability as a proxy of general mental ability Our findings are consistent with recent theoretical proposals by Ambrosio et al (2014) linking CT with some core elements of the CHC model of intelligence (McGrew 2009) especially with respect to Gf (fluid intelligence) and Gv (visual processing) Furthermore our results support the statement that CT is fundamentally linked with general mental ability; and also though to a lesser extent with specific cognitive aptitudes such as inductive reasoning spatial and verbal abilities This corroborates the conceptualization of CT as a problem-solving ability (eg Brennan & Resnick 2012; Lye & Koh 2014; Wing 2006 2008); and it is consistent with the framework recently described by Kalelioglu et al (2016)  in which CT is defined as a complex and high-order thinking skill involved in problem-solving processes Overall it should be noted that this paper contributes to the establishment of the nomological net (Cronbach & Meehl 1955) of computational thinking as an emergent scientific construct Future research might expand this nomological net exploring how CT is related to other cognitive and computational variables such as working memory executive functions or specific programming skills among others Finally we plan the following further research lines concerning the CTt a) convergent validity studies between CTt and other alternative CT assessment tools such as Dr Scratch (Moreno-Leon & Robles 2015b 2015a) Bebras Tasks (Dagiene & Stupuriene 2014) the Test for Measuring Basic Programming Abilities (Mühling et al 2015) or the Commutative Assessment (Weintrop & Wilensky 2015); b) CTt adaptation and translation into other languages (already underway adaptations-translations into English and Portuguese) and replications of our psychometric studies in other populations; c) enhanced CTt versions including items that require the subject the evocation of algorithms and/or items that demand to project and transfer CT on scientific narrative and musical relevant problems Acknowledgements We thank Professor Dr Kate Howland (University of Sussex) for collaborating in the adaptation and translation of CTt items from the Spanish language to the English language References Ackerman P L & Rolfhus E L (1999) The locus of adult intelligence Knowledge abilities and nonability traits Psychology and Aging 14(2) 314e330 http// dxdoiorg/101037/0882-7974142314 AERA APA & NCME (2014) Standards for educational and psychological testing Washington DC AERA Aho A V (2012) Computation and computational thinking The Computer Journal Table 10 Correlation between CTt and RP30 problem-solving test RP30 CTt Pearson correlation 0669 Sig (2-tailed) 0000 n 56 p < 001 Fig 10 Scatter plot between CTt and RP30 Table 11 Correlations CTt PMA and CTt RP30 and contingency with Gf Gv and Gsm components of CHC model PMA-N PMA-V PMA-S PMA-R RP30 CTt 0157 0273 0439 0442 0669 Selected components of the CHC model of intelligence Gf Is it measured in the following instruments? No No No Yes Yes Gv No No Yes No Yes Gsm No No No No Yes p < 001 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 689 55(7) 832e835 http//dxdoiorg/101093/comjnl/bxs074 Ambrosio A P Xavier C & Georges F (2014) Digital ink for cognitive assessment of computational thinking In Frontiers in education conference (FIE) 2014 IEEE (pp 1e7) http//dxdoiorg/101109/FIE20147044237 Anastasi A (1968) Psychological testing (3rd ed) Oxford England Macmillan Barefoot C A S (2014) Computational thinking [web page] Retrieved from http// barefootcasorguk/barefoot-primary-computing-resources/concepts/ computational-thinking/ Barros E Kausel E E Cuadra F & Díaz D A (2014) Using general mental ability and personality traits to predict job performance in three Chilean organizations International Journal of Selection and Assessment 22(4) 432e438 http// dxdoiorg/101111/ijsa12089 Basawapatna A Koh K H Repenning A Webb D C & Marshall K S (2011) Recognizing computational thinking patterns Proceedings of the 42nd ACM Technical Symposium on Computer Science Education 245e250 http// dxdoiorg/101145/19531631953241 Bellettini C Lonati V Malchiodi D Monga M Morpurgo A & Torelli M (2015) How challenging are Bebras tasks? An IRT analysis based on the performance of Italian students In Proceedings of the 2015 ACM conference on innovation and technology in computer science education (pp 27e32) http//dxdoiorg/101145/ 27290942742603 Bennett G K (1952) Differential aptitude tests [technical manual] New York Psychological Corporation Brennan K & Resnick M (2012) New frameworks for studying and assessing the development of computational thinking In Proceedings of the 2012 annual meeting of the american educational research association (vancouver Canada) Retrieved from http//scratchedgseharvardedu/ct/files/AERA2012pdf Brown N C C Kolling M Crick T Peyton Jones S Humphreys S & Sentance S € (2013) Bringing computer science back into schools Lessons from the UK In Proceeding of the 44th ACM technical symposium on computer science education (pp 269e274) http//dxdoiorg/101145/24451962445277 Buffum P S Lobene E V Frankosky M H Boyer K E Wiebe E N & Lester J C (2015) A practical guide to developing and validating computer science knowledge assessments with application to middle school In Proceedings of the 46th ACM technical symposium on computer science education (pp 622e627) http//dxdoiorg/101145/26767232677295 Burke Q (2012) The markings of a new pencil Introducing programming-aswriting in the middle school classroom The Journal of Media Literacy Education 4(2) 121e135 Retrieved fromhttp//ericedgov/?id¼EJ985683 Caceres P A & Conejeros M L (2011) Efecto de un modelo de metodología  centrada en el aprendizaje sobre el pensamiento crítico el pensamiento creativo y la capacidad de resolucion de problemas en estudiantes con talento  academico  Revista Espanola De Pedagogía 69 ~ (248) 39e55 Retrieved from http//wwwjstororg/stable/23766382 Carpenter P A Just M A & Shell P (1990) What one intelligence test measures A theoretical account of the processing in the raven progressive matrices test Psychological Review 97(3) 404e431 http//dxdoiorg/101037/0033-295X973 404 Cartelli A Dagiene V & Futschek G (2012) Bebras contest and digital competence assessment Analysis of frameworks In A Cartelli (Ed) Current trends and future practices for digital literacy and competence (pp 35e46) Hershey PA IGI Global Cohen J (1992) A power primer Psychological Bulletin 112(1) 155e159 http// dxdoiorg/101037/0033-29091121155 Cronbach L J & Meehl P E (1955) Construct validity in psychological tests Psychological Bulletin 52(4) 281e302 http//dxdoiorg/101037/h0040957 CSTA (2011) Ke12 computer science standards Retrieved from http//cstaacmorg/ Curriculum/sub/CurrFiles/CSTA_K-12_CSSpdf CSTA & ISTE (2011) Operational definition of computational thinking for Ke12 education Retrieved from http//cstaacmorg/Curriculum/sub/CurrFiles/ CompThinkingFlyerpdf Dagiene V & Futschek G (2008) Bebras international contest on informatics and computer literacy Criteria for good tasks In R T Mittermeir & M M Sysło (Eds) Informatics education-supporting computational thinking (pp 19e30) Berlin Springer Dagiene V & Stupuriene G (2014) Informatics education based on solving attractive tasks through a contest In Proceedings of KEYCIT 2014eKey competencies in informatics and ICT (pp 51e62) Retrieved from http//wwwbebras org/sites/default/files/documents/publications/Dagiene%2C%202014pdf Daily S B Leonard A E Jorg S Babu S & Gundersen K (2014) Dancing Alice € Exploring embodied pedagogical strategies for learning computational thinking In Proceedings of the 45th ACM technical symposium on computer science education (pp 91e96) http//dxdoiorg/101145/25388622538917 Ediciones T E A (2007) PMA Aptitudes Mentales Primarias (manual tecnico) [PMA Primary Mental Abilities (Technical manual)] Madrid TEA Ediciones Edwards M (2011) Algorithmic composition Computational thinking in music Communications of the ACM 54(7) 58e67 http//dxdoiorg/101145/ 19657241965742 Elithorn A & Telford A (1969) Computer analysis of intellectual skills International Journal of Man-Machine Studies 1(2) 189e209 http//dxdoiorg/101016/ S0020-7373(69)80021-0 European Schoolnet (2015) Computing our future Computer programming and coding priorities school curricula and initiatives across Europe [Technical report] Retrieved fromhttp//wwweunorg/publications/detail? publicationID¼661 Gardner H (2006) On failing to grasp the core of MI theory A response to Visser et al Intelligence 34(5) 503e505 http//dxdoiorg/101016/jintell200604002 Gardner H & Davis K (2013) The App Generation How today's youth navigate identity intimacy and imagination in a digital world New Haven Yale University Press Gottfredson L S (1997) Why g matters The complexity of everyday life Intelligence 24(1) 79e132 http//dxdoiorg/101016/S0160-2896(97)90014-3 Gouws L A Bradshaw K & Wentworth P (2013) Computational thinking in educational activities An evaluation of the educational game light-bot In Proceedings of the 18th ACM conference on innovation and technology in computer science education (pp 10e15) http//dxdoiorg/101145/24624762466518 Graczynska E (2010) ALICE as a tool for programming at schools  Natural Science 2(2) 124e129 http//dxdoiorg/104236/ns201022021 Grover S & Pea R (2013) Computational thinking in Ke12 A review of the state of the field Educational Researcher 42(1) 38e43 http//dxdoiorg/103102/ 0013189X12463051 Henderson P B Cortina T J & Wing J M (2007) Computational thinking ACM SIGCSE Bulletin 39(1) 195e196 http//dxdoiorg/101145/12275041227378 Hertzog C & Bleckley M K (2001) Age differences in the structure of intelligence Influences of information processing speed Intelligence 29(3) 191e217 http// dxdoiorg/101016/S0160-2896(00)00050-7 Howland K & Good J (2015) Learning to communicate computationally with flip A bi-modal programming language for game creation Computers & Education 80 224e240 http//dxdoiorg/101016/jcompedu201408014 Hubwieser P & Mühling A (2014) Playing PISA with bebras In Proceedings of the 9th workshop in primary and secondary computing education (pp 128e129) http//dxdoiorg/101145/26707572670759 Hubwieser P & Mühling A (2015) Investigating the psychometric structure of Bebras contest Towards measuring computational thinking skills In International conference on learning and teaching in computing and engineering (LaTiCE) (pp 62e69) http//dxdoiorg/101109/LaTiCE201519 Hyde J S & Linn M C (1988) Gender differences in verbal ability A meta-analysis Psychological Bulletin 104(1) 53e69 http//dxdoiorg/101037/0033- 2909104153 Jaskova L & Kov   acov a N (2015) Bebras contest for blind pupils In Proceedings of the 10th workshop in primary and secondary computing education (pp 92e95) http//dxdoiorg/101145/28183142818324 Kalelioglu F (2015) A new way of teaching programming skills to K-12 students Codeorg Computers in Human Behavior 52 200e210 http//dxdoiorg/101016/ jchb201505047 Kalelioglu F Gülbahar Y & Kukul V (2016) A framework for computational thinking based on a systematic research review Baltic Journal of Modern Computing 4(3) 583e596 Retrieved from http//wwwbjmclulv/fileadmin/ user_upload/lu_portal/projekti/bjmc/Contents/4_3_15_Kalelioglupdf Kalelioglu F Gülbahar Y & Madran O (2015) A snapshot of the first implementation of Bebras international informatics contest in Turkey In A Brodnik & J Vahrenhold (Eds) Informatics in schools Curricula competences and competitions (pp 131e140) Berna Springer http//dxdoiorg/101007/978-3-319- 25396-1_12 Koh K H Basawapatna A Bennett V & Repenning A (2010) Towards the automatic recognition of computational thinking for adaptive visual language learning In Visual languages and human-centric computing (VL/HCC) 2010 IEEE symposium (pp 59e66) http//dxdoiorg/101109/VLHCC201017 Kuhn J & Holling H (2009) Gender reasoning ability and scholastic achievement A multilevel mediation analysis Learning and Individual Differences 19(2) 229e233 http//dxdoiorg/101016/jlindif200811007 Lee G Lin Y & Lin J (2014) Assessment of computational thinking skill among high school and vocational school students in Taiwan In World conference on educational multimedia hypermedia and telecommunications (pp 173e180) Retrieved from http//wwweditliborg/p/147499/ Leonard A E Dsouza N Babu S V Daily S B Jorg S Waddell C et al (2015) € Embodying and programming a constellation of multimodal literacy practices Computational thinking creative movement biology & virtual environment interactions Journal of Language and Literacy Education 11(2) 64e93 Retrieved from http//jollecoeugaedu/wp-content/uploads/2015/10/Leonard_TemplateFinal-fixed-linkspdf Liao Y C & Bright G W (1991) Effects of computer programming on cognitive outcomes A meta-analysis Journal of Educational Computing Research 7(3) 251e268 http//dxdoiorg/102190/E53G-HH8K-AJRR-K69M Linn M C & Petersen A C (1985) Emergence and characterization of sex differences in spatial ability A meta-analysis Child Development 56(6) 1479e1498 http//dxdoiorg/102307/1130467 Lye S Y & Koh J H L (2014) Review on teaching and learning of computational thinking through programming What is next for K-12? Computers in Human Behavior 41 51e61 http//dxdoiorg/101016/jchb201409012 Manovich L (2013) Software takes command New York Bloomsbury Mayer R E (1988) Teaching and learning computer programming Multiple research perspectives New York Routledge Mayer J D Caruso D R & Salovey P (1999) Emotional intelligence meets traditional standards for an intelligence Intelligence 27(4) 267e298 http// dxdoiorg/101016/S0160-2896(99)00016-1 McGrew K S (2009) CHC theory and the human cognitive abilities project Standing on the shoulders of the giants of psychometric intelligence research Intelligence 37(1) 1e10 http//dxdoiorg/101016/jintell200808004 Moreno-Leon J & Robles G (2014) Automatic detection of bad programming  690 M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 habits in scratch A preliminary study Frontiers in Education Conference (FIE) 2014 IEEE 1e4 http//dxdoiorg/101109/FIE20147044055 Moreno-Leon J & Robles G (2015a)  Analyze your Scratch projects with Dr Scratch and assess your computational thinking skills Scratch Conference (pp 12e15) Retrieved from http//jemoleme/replication/2015scratch/InferCTpdf Moreno-Leon J & Robles G (2015b) Dr Scratch A web tool to automatically  evaluate scratch projects In Proceedings of the 10th workshop in primary and secondary computing education (pp 132e133) http//dxdoiorg/101145/ 28183142818338 Moreno-Leon J Robles G & Rom  an-Gonz  alez M (2015) Dr Scratch Automatic  analysis of scratch projects to assess and foster computational thinking RED Revista de Educacion a Distancia 46   Retrieved from http//wwwumes/ead/red/ 46/moreno_roblespdf Moreno-Leon J Robles G & Rom  an-Gonz  alez M (2016) Comparing computa-  tional thinking development assessment scores with software complexity metrics In 2016 IEEE global engineering education conference (EDUCON) (pp 1040e1045) http//dxdoiorg/101109/EDUCON20167474681 Mühling A Ruf A & Hubwieser P (2015) Design and first results of a psychometric test for measuring basic programming abilities In Proceedings of the 10th workshop in primary and secondary computing education (pp 2e10) http// dxdoiorg/101145/28183142818320 Nunnally J C & Bernstein I H (1994) Psychometric theory (3rd ed) New York McGraw-Hill Papert S (1980) Mindstorms Children computers and powerful ideas New York Basic Books Prensky M (2008 January 13) Programming is the new literacy [blog post] Retrieved fromhttp//wwwedutopiaorg/literacy-computer-programming Quiroga MA Escorial S Rom   an F J Morillo D Jarabo A Privado J & Colom R (2015) Can we reliably measure the general factor of intelligence (g) through commercial video games? Yes we can Intelligence 53 1e7 http//dxdoiorg/ 101016/jintell201508004 Resnick M Maloney J Monroy-Hern andez A Rusk N Eastmond E Brennan K & Silverman B (2009) Scratch Programming for all Communications of the ACM 52(11) 60e67 http//dxdoiorg/101145/15927611592779 Roman-Gonz  alez M (2014) Aprender a programar  ‘apps’ como enriquecimiento curricular en alumnado de alta capacidad Bordon  Revista de Pedagogía 66(4) 135e155 http//dxdoiorg/1013042/Bordon201466401 Roman-Gonz  alez M (2015) Computational thinking Test Design guidelines and  content validation In 7th annual international conference on education and new learning technologies (Barcelona Spain) http//dxdoiorg/1013140/ RG2142034329 Roman-Gonz  alez M P  erez-Gonz  alez J C & Jim  enez-Fern   andez C (2015) Test de Pensamiento computacional Diseno y psicometría general [computational ~ thinking test Design & general psychometry] In III Congreso Internacional sobre Aprendizaje Innovacion y Competitividad CINAIC2015 (Madrid Spain)   http// dxdoiorg/1013140/RG2130565521 Rushkoff D (2012 November 13) Code literacy A 21st-Century requirement [blog post] Retrieved from http//wwwedutopiaorg/blog/code-literacy-21stcentury-requirement-douglas-rushkoff Rushkoff D (2010) Program or be programmed New York OR Books Schneider W J & McGrew K S (2012) The Cattell-Horn-Carroll model of intelligence In D Flanagan & P Harrison (Eds) Contemporary intellectual assessment Theories tests and issues (3rd ed pp 99e144) New York Guilford Seisdedos N (1994) CAMBIOS Test de flexibilidad cognitiva (Manual tecnico) [CHANGES Cognitive Flexibility Test (Technical manual)] Madrid TEA Ediciones Seisdedos N (2002) RP30 Test de Resolucion de Problemas (Manual t  ecnico) [RP30 Problem-solving Test (Technical manual)] Madrid TEA Ediciones Thurstone L L (1938) Primary mental abilities Chicago University of Chicago Press Voyer D Voyer S & Bryden M P (1995) Magnitude of sex differences in spatial abilities A meta-analysis and consideration of critical variables Psychological Bulletin 117(2) 250e270 http//dxdoiorg/101037/0033-29091172250 Weintrop D Beheshti E Horn M Orton K Jona K Trouille L et al (2016) Defining computational thinking for mathematics and science classrooms Journal of Science Education and Technology 25(1) 127e147 http//dxdoiorg/ 101007/s10956-015-9581-5 Weintrop D & Wilensky U (2015) Using commutative assessments to compare conceptual understanding in blocks-based and text-based programs In Proceedings of the eleventh annual international conference on international computing education research ICER15 (pp 101e110) http//dxdoiorg/101145/ 27876222787721 Werner L Denner J Campe S & Kawamoto D C (2012) The fairy performance assessment Measuring computational thinking in middle school In Proceedings of the 43rd ACM technical symposium on computer science education (pp 215e220) http//dxdoiorg/101145/21571362157200 Wing J M (2006) Computational thinking Communications of the ACM 49(3) 33e35 http//dxdoiorg/101145/11181781118215 Wing J M (2008) Computational thinking and thinking about computing Philosophical Transactions Series A Mathematical Physical and Engineering Sciences 366(1881) 3717e3725 http//dxdoiorg/101098/rsta20080118 Wing J M (2011) Research Notebook Computational thinkingewhat and Why? The link The magazine of the Carnegie Mellon University School of Computer Science Retrieved from http//wwwcscmuedu/link/research-notebookcomputational-thinking-what-and-why M Roman-Gonz  alez et al / Computers in Human Behavior 72 (2017) 678  e691 691 
